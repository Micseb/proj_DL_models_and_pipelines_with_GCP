{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Scaling up ML using Cloud ML Engine </h1>\n",
    "\n",
    "Adapted from [Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/cloudmle/cloudmle.ipynb) of Google Coursera Course [Serverless Machine Learning with Tensorflow on Google Cloud Platform](https://www.coursera.org/learn/serverless-machine-learning-gcp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Tensorflow: 1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: 1.12.0: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TF_VERSION=$(python3 -c 'import tensorflow as tf; print(tf.__version__)')\n",
    "if $TF_VERSION != \"1.12.0\"\n",
    "then\n",
    "    pip install tensorflow==1.12\n",
    "fi\n",
    "    echo \"Found Tensorflow: $TF_VERSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory is kept: /home/enryh/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WORKINGDIR = os.getcwd()\n",
    "folders = WORKINGDIR.split('/')\n",
    "if folders.pop() == 'notebook':  # or a list: in ['notebook', 'src', etc.]\n",
    "  WORKINGDIR = '/'.join(folders)\n",
    "  print(\"New working directory: {}\".format(WORKINGDIR))\n",
    "else:\n",
    "  print(\"Current Working direcotory is kept: {}\".format(WORKINGDIR))\n",
    "os.chdir(WORKINGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Environment variables for project and bucket </h2>\n",
    "\n",
    "Note that:\n",
    "<ol>\n",
    "<li> Your project id is the *unique* string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads:  \n",
    "     \n",
    "     Project ID: ml-productive-pipeline-12345\n",
    "<li> Cloud training often involves saving and restoring model files. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available). A common pattern is to prefix the bucket name by the project id, so that it is unique. Also, for cost reasons, you might want to use a single region bucket. </li>\n",
    "</ol>\n",
    "\n",
    "<b>Add all detail in to [config.yaml](../config.yaml) file in main directory. Missing in public repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project-id': 'ml-productive-pipeline-53122', 'region': 'europe-west1', 'bucket': 'ml-productive-pipeline-53122', 'tf-version': 1.12, 'pkg-name': 'pkg_mnist_fnn'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "    \n",
    "print(config)\n",
    "\n",
    "# # #Create config manually and save as yaml:\n",
    "# config = {}\n",
    "# config['project-id'] = 'PROJECT'  # # REPLACE WITH YOUR PROJECT ID\n",
    "# config['region'] = 'europe-west1' # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "# config['bucket'] = 'Bucket-name'  # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "# \n",
    "# with open(\"../config_from_python.yaml\", 'wb', encoding= 'utf8') as f:\n",
    "#     yaml.dump(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to persistently add variables to the runtime of the datalab kernel, us the build in python function `os.environ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = config['pkg-name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can access the environement variable in the terminal running this datalab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow the Cloud ML Engine service account to read/write to the bucket containing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Service Account of VM: service-552147390438@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "Authorizing the Cloud ML Service account service-552147390438@cloud-ml.google.com.iam.gserviceaccount.com to access files in Bucket: ml-productive-pipeline-53122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   233    0   233    0     0    211      0 --:--:--  0:00:01 --:--:--   211\r",
      "100   233    0   233    0     0    210      0 --:--:--  0:00:01 --:--:--   210\n",
      "No changes to gs://ml-productive-pipeline-53122/\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist.npy\n",
      "No changes to gs://ml-productive-pipeline-53122/test.tfrecords\n",
      "No changes to gs://ml-productive-pipeline-53122/train.tfrecords\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-henry/content/daily-20190124094427\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-henry/content/hourly-20190124094427\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-henry/content/weekly-20190124094427\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-instance-test/content/daily-20190123104613\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-instance-test/content/hourly-20190123104613\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-instance-test/content/weekly-20190123104613\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-test/content/daily-20190123103151\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-test/content/hourly-20190123103151\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-test/content/weekly-20190123103151\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/daily-20190109134925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/hourly-20190109145925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/hourly-20190109134925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/hourly-20190109160925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/weekly-20190109134925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190206144909\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190207093049\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190207133121\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190207183847\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190212092016\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190211085550\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190213080842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190214120536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190215123039\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190214173824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190213113842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190213124842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190213135842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214120536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214131536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214142536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214173824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214184824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214195824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190215123039\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190206144909\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190207093049\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190207133121\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190207183847\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190211085550\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190212092016\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190213080842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190214120536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190214173824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190215123039\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/daily-20190121072344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/daily-20190123114907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121072344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121083344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121094344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121105344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121120344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121131345\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123114907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123125907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123140907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123151907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/weekly-20190121072344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/weekly-20190123114907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/daily-20190206212641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/hourly-20190206212641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/hourly-20190206223641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/hourly-20190206234641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/weekly-20190206212641\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190212_122128/ed5251323934ae8bf21773bd24f0b5dee39a866770daf974045271eeb09410d2/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190212_165517/e5c6f75c4ee2c7409d218fa24f1af6a7db5d9c43c9197e2fde3065e81d4ddb9c/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190213_090323/28fe45aaa21d81e66ce0b2d2434a9c572adc587f9976848299d0228cff3005a1/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190213_091455/ec79430baf1229da2b1ec34bbc90436dfffb2589d7010059c139a327428f3007/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/model_dir_tmp/1549054852/saved_model.pb\n",
      "No changes to gs://ml-productive-pipeline-53122/model_dir_tmp/1549054852/variables/variables.data-00000-of-00001\n",
      "No changes to gs://ml-productive-pipeline-53122/model_dir_tmp/1549054852/variables/variables.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/eval/events.out.tfevents.1550049526.cmle-training-5096003917298122300\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/events.out.tfevents.1550049398.cmle-training-10500309129451260749\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/variables.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/events.out.tfevents.1550049448.cmle-training-5096003917298122300\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/saved_model.pb\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/checkpoint\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/saved_model.pb\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/eval/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/eval/events.out.tfevents.1550049479.cmle-training-10500309129451260749\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/variables.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.meta\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/variables.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/graph.pbtxt\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/variables.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/variables.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/variables.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.meta\n",
      "No changes to gs://ml-productive-pipeline-53122/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "# echo $AUTH_TOKEN\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print(response['serviceAccount'])\")\n",
    "echo \"Current Service Account of VM: $SVC_ACCOUNT\"\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in Bucket: $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Packaging up the code </h2>\n",
    "\n",
    "Take your code and put into a standard Python package structure, see  <a href=\"package_ml_engine/mnist_ml_engine.py\">model.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\r\n",
      "First try to start Cloud ML\r\n",
      "\r\n",
      "References:\r\n",
      "Basic reference for packaging the model so that ml-engine can use it:\r\n",
      "- https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/cloudmle/taxifare\r\n",
      "MNIST-Estimator-Example:\r\n",
      "- https://codeburst.io/use-tensorflow-dnnclassifier-estimator-to-classify-mnist-dataset-a7222bf9f940\r\n",
      "\r\n",
      "ipython -i -m src.models.test_model_estimator_api.mnist_ml_engine -- --data_path=data --output_dir=src\\models\\test_model_estimator_api\\trained --train_steps=100\r\n",
      "\"\"\"\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "import numpy as np\r\n",
      "\r\n",
      "from .utils import load_data\r\n",
      "###############################################################################\r\n",
      "#Factor into config:\r\n",
      "N_PIXEL = 784\r\n",
      "OUTDIR = 'trained'\r\n",
      "USE_TPU = False\r\n",
      "EPOCHS = 5\r\n",
      "\r\n",
      "if USE_TPU:\r\n",
      "    _device_update = 'tpu'\r\n",
      "else:\r\n",
      "    _device_update = 'cpu'\r\n",
      "\r\n",
      "IMAGE_SIZE = 28 * 28\r\n",
      "NUM_LABELS = 10\r\n",
      "BATCH_SIZE = 128\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "\r\n",
      "def parse_images(x):\r\n",
      "    return x.reshape(len(x), -1).astype('float32')\r\n",
      "\r\n",
      "\r\n",
      "def parse_labels(y):\r\n",
      "    return y.astype('int32')\r\n",
      "\r\n",
      "\r\n",
      "def numpy_input_fn(images: np.ndarray, labels: np.ndarray, mode=tf.estimator.ModeKeys.EVAL):\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        _epochs = EPOCHS\r\n",
      "        _shuffle = True\r\n",
      "        _num_threads = 2\r\n",
      "    else:\r\n",
      "        _epochs = 1\r\n",
      "        _shuffle = False\r\n",
      "        _num_threads = 1\r\n",
      "\r\n",
      "    return tf.estimator.inputs.numpy_input_fn(\r\n",
      "        {'x': images},\r\n",
      "        y=labels,\r\n",
      "        batch_size=BATCH_SIZE,\r\n",
      "        num_epochs=_epochs,\r\n",
      "        # Boolean, if True shuffles the queue. Avoid shuffle at prediction time.\r\n",
      "        shuffle=_shuffle,\r\n",
      "        queue_capacity=1000,\r\n",
      "        # Integer, number of threads used for reading and enqueueing. In order to have predicted and repeatable order of reading and enqueueing, such as in prediction and evaluation mode, num_threads should be 1.\r\n",
      "        num_threads=_num_threads\r\n",
      "    )\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_placeholders = {\r\n",
      "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\r\n",
      "    }\r\n",
      "    features = feature_placeholders\r\n",
      "    return tf.estimator.export.ServingInputReceiver(\r\n",
      "         features=features, \r\n",
      "         receiver_tensors=feature_placeholders,\r\n",
      "         receiver_tensors_alternatives=None\r\n",
      "         )\r\n",
      "\r\n",
      "\r\n",
      "def train_and_evaluate(args):\r\n",
      "    \"\"\"\r\n",
      "    Utility function for distributed training on ML-Engine\r\n",
      "    https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \r\n",
      "    \"\"\"\r\n",
      "    ##########################################\r\n",
      "    # Load Data in Memoery\r\n",
      "\r\n",
      "  # #ToDo: replace numpy-arrays\r\n",
      "    (x_train, y_train), (x_test, y_test) = load_data(\r\n",
      "        rel_path=args['data_path'])\r\n",
      "  \r\n",
      "    x_train = parse_images(x_train)\r\n",
      "    x_test = parse_images(x_test)\r\n",
      "\r\n",
      "    y_train = parse_labels(y_train)\r\n",
      "    y_test = parse_labels(y_test)\r\n",
      "\r\n",
      "    model = tf.estimator.DNNClassifier(\r\n",
      "        hidden_units=[256, 128, 64],\r\n",
      "        feature_columns=[tf.feature_column.numeric_column(\r\n",
      "            'x', shape=[N_PIXEL, ])],\r\n",
      "        model_dir=args['output_dir'],\r\n",
      "        n_classes=10,\r\n",
      "        optimizer=tf.train.AdamOptimizer,\r\n",
      "        # activation_fn=,\r\n",
      "        dropout=0.2,\r\n",
      "        batch_norm=False,\r\n",
      "        loss_reduction='weighted_sum',\r\n",
      "        warm_start_from=None\r\n",
      "    )\r\n",
      "   \r\n",
      "    train_spec = tf.estimator.TrainSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN),\r\n",
      "        max_steps=args['train_steps']\r\n",
      "    )\r\n",
      "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\r\n",
      "    eval_spec = tf.estimator.EvalSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\r\n",
      "        steps=None,\r\n",
      "        start_delay_secs=args['eval_delay_secs'],\r\n",
      "        throttle_secs=args['min_eval_frequency'],\r\n",
      "        exporters=exporter\r\n",
      "    )\r\n",
      "    tf.estimator.train_and_evaluate(\r\n",
      "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\r\n",
      "    print((model.get_variable_names()))\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    # model.train(input_fn=numpy_input_fn(\r\n",
      "    #     x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN))\r\n",
      "    # # #######################################\r\n",
      "\r\n",
      "# How to evaluate in the cloud over a whole evaluation set?\r\n",
      "    # # # Evaluate\r\n",
      "    # metrics_train = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(x_train, y_train, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # metrics_test = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(\r\n",
      "    #         x_test, y_test, mode=tf.estimator.ModeKeys.EVAL)\r\n",
      "    # )\r\n",
      "    # import pandas as pd\r\n",
      "    # metrics = pd.DataFrame(\r\n",
      "    #     {'Train': metrics_train, 'Test': metrics_test}).transpose()\r\n",
      "    # print(\"## Metrics DF\\n\", metrics)\r\n",
      "    # # #######################################\r\n",
      "    # # # get individual predictions:\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # for i, pred in enumerate(predictions_iterator):\r\n",
      "    #     if i % 999 == 0:\r\n",
      "    #         print('Image: {}'.format(i))\r\n",
      "    #         print(pred)\r\n",
      "    # #ToDo: 10000 Test-Images yield 20000 predictions?!\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # assert len(list(predictions_iterator)) == len(x_test)\r\n"
     ]
    }
   ],
   "source": [
    "!cat src/$PKG_NAME/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\r\n",
      "Parse arguments and call main function\r\n",
      "\"\"\"\r\n",
      "import os\r\n",
      "import argparse\r\n",
      "import shutil\r\n",
      "\r\n",
      "from .model import train_and_evaluate\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument(\r\n",
      "        '--data_path',\r\n",
      "        help='GCS or local path to training data',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--output_dir',\r\n",
      "        help='GCS location to write checkpoints and export models',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_batch_size',\r\n",
      "        help='Batch size for training steps',\r\n",
      "        type=int,\r\n",
      "        default='128'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_steps',\r\n",
      "        help='Steps to run the training job for',\r\n",
      "        type=int,\r\n",
      "        default='200'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--hidden_units',\r\n",
      "        help='List of hidden layer sizes to use for DNN feature columns',\r\n",
      "        nargs='+',\r\n",
      "        type=int,\r\n",
      "        default=[128, 64, 32]\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--job_dir',\r\n",
      "        help='this model ignores this field, but it is required by gcloud',\r\n",
      "        default='junk'\r\n",
      "    )\r\n",
      "    # Eval arguments\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_delay_secs',\r\n",
      "        help='How long to wait before running first evaluation',\r\n",
      "        default='10',\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--min_eval_frequency',\r\n",
      "        help='Seconds between evaluations',\r\n",
      "        default=300,\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "\r\n",
      "    args = parser.parse_args().__dict__\r\n",
      "\r\n",
      "    OUTDIR = args['output_dir']\r\n",
      "    # #######################################\r\n",
      "    # # Train\r\n",
      "    # ToDo execute outside from skript\r\n",
      "    shutil.rmtree(OUTDIR, ignore_errors=True)  # start fresh each time\r\n",
      "    train_and_evaluate(args)"
     ]
    }
   ],
   "source": [
    "!cat src/$PKG_NAME/task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Find absolute paths to your data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the absolute paths below.\n",
    "`/content` is mapped in Datalab to where the home icon takes you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory /home/enryh/proj_DL_models_and_pipelines_with_GCP\n",
      "Package Directory /home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn\n",
      "Saved Model directory to be erased: /home/enryh/proj_DL_models_and_pipelines_with_GCP/src//trained\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Working Directory $PWD\"\n",
    "echo \"Package Directory $PWD/src/$PKG_NAME\"\n",
    "echo \"Saved Model directory to be erased: $PWD/src/$PKG_Name/trained\"\n",
    "rm -rf $PWD/src/$PKG_NAME/trained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running the Python module from the command-line </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Package Path: src.pkg_mnist_fnn.task\n",
      "['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n",
      "Saved model: /home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn/trained/export/exporter/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-02-18 11:49:15.193946: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-18 11:49:15.198531: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf $PKG_NAME.tar.gz ${PWD}/$PKG_NAME/trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/../\n",
    "\n",
    "echo \"Python Package Path: src.${PKG_NAME}.task\"\n",
    "\n",
    "python -m src.${PKG_NAME}.task \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/${PKG_NAME}/trained \\\n",
    "   --train_steps=1000 \\\n",
    "   --job_dir=tmp\n",
    "   \n",
    "echo \"Saved model: ${PWD}/src/${PKG_NAME}/trained/export/exporter/ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550486967\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls $PWD/src/$PKG_NAME/trained/export/exporter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an test-image in numpy format saved as json (copy from test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /home/enryh/proj_DL_models_and_pipelines_with_GCP/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(rel_path='data')\n",
    "N=4\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eol = \"\\r\\n\"\n",
    "n_lines = len(y_test)\n",
    "with open(\"data/test.json\", \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        _dict = {\"x\": image} #, \"y\": int(label)}\n",
    "        f.write(json.dumps(_dict) + eol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "    images = f.readlines()\n",
    "plt.figure(figsize=(20,4))\n",
    "for i, image in enumerate(images):\n",
    "    if i < 4:\n",
    "        image = json.loads(image)\n",
    "        image = np.array(image['x'])\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with `Python 3`, delete the `*.pyc` files, see [post](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)\n",
    "\n",
    "Default Datalab\n",
    "```\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "Default UNIX:\n",
    "```\n",
    "sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "\n",
    "> Process running Datalab or Jupyter Notebook needs admin rights. This is not always given for locally run notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# #remove any pyc files: Using Python3 you have to recompile\n",
    "# #Note: you need admin rights\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "# sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model:  1550484398\n",
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                        PROBABILITIES\n",
      "[4]        [u'4']   [0.2955600619316101, -1.395798683166504, -1.8033928871154785, -0.07336592674255371, 4.363767623901367, 1.0356162786483765, -3.5050811767578125, 1.4503240585327148, 0.24793429672718048, 3.1991055011749268]  [0.011773805133998394, 0.0021695473697036505, 0.001443288754671812, 0.008141309022903442, 0.6882036924362183, 0.024678530171513557, 0.0002632203104440123, 0.037361521273851395, 0.011226214468479156, 0.2147388756275177]\n",
      "[9]        [u'9']   [-0.6732280850410461, -5.111705780029297, -1.8348519802093506, -0.9554049372673035, 1.238022804260254, 0.11140099167823792, -5.326626777648926, 1.729777216911316, -0.345848023891449, 3.9755911827087402]    [0.007815743796527386, 9.233446326106787e-05, 0.002446153201162815, 0.005894169677048922, 0.05284649133682251, 0.017128940671682358, 7.447752432199195e-05, 0.0864136591553688, 0.010843006893992424, 0.8164450526237488]\n",
      "[2]        [u'2']   [-6.009137153625488, -3.665865898132324, 11.587852478027344, 3.1798863410949707, -3.0333058834075928, -4.280998706817627, -1.3579951524734497, -1.183574914932251, 4.8169965744018555, -1.2152471542358398]   [2.2757609130508172e-08, 2.37026000604601e-07, 0.9986233711242676, 0.00022277591051533818, 4.4618320771405706e-07, 1.2812900251901738e-07, 2.382821776336641e-06, 2.836882686096942e-06, 0.0011451342143118382, 2.7484397833177354e-06]\n",
      "[5]        [u'5']   [1.3700165748596191, -7.255740642547607, -4.728294372558594, -1.0182626247406006, 4.566244602203369, 6.888350963592529, -1.4476794004440308, 0.14910955727100372, 2.2279152870178223, 5.0454840660095215]     [0.003155231010168791, 5.661251520905353e-07, 7.088725851644995e-06, 0.0002896108489949256, 0.07711438089609146, 0.7863454222679138, 0.00018850441847462207, 0.0009306747233495116, 0.007440666668117046, 0.12452783435583115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Running [gcloud.ml-engine.local.predict] with arguments: [--json-instances: \"./data/test.json\", --model-dir: \"/home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn/trained/export/exporter/1550484398\", --verbosity: \"debug\"]\n",
      "WARNING: 2019-02-18 11:20:57.330275: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-18 11:20:57.335174: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\n",
      "INFO: Display format: \"default \n",
      "          table(\n",
      "              predictions:format=\"table(\n",
      "                  class_ids, classes, logits, probabilities\n",
      "              )\"\n",
      "          )\"\n",
      "DEBUG: SDK update checks are disabled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $PWD/src/$PKG_NAME/trained/export/exporter/)\n",
    "echo \"Selected Model:  $model_dir\"\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/src/$PKG_NAME/trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=./data/test.json \\\n",
    "    --verbosity debug > data/test_predictions\n",
    "cat data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 9 2 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "    gcloud ml-engine local predict - run prediction locally\n",
      "\n",
      "SYNOPSIS\n",
      "    gcloud ml-engine local predict --model-dir=MODEL_DIR\n",
      "        (--json-instances=JSON_INSTANCES | --text-instances=TEXT_INSTANCES)\n",
      "        [--framework=FRAMEWORK] [--signature-name=SIGNATURE_NAME]\n",
      "        [GCLOUD_WIDE_FLAG ...]\n",
      "\n",
      "DESCRIPTION\n",
      "    gcloud ml-engine local predict performs prediction locally with the given\n",
      "    instances. It requires the TensorFlow SDK be installed locally. The output\n",
      "    format mirrors gcloud ml-engine predict (online prediction)\n",
      "\n",
      "REQUIRED FLAGS\n",
      "     --model-dir=MODEL_DIR\n",
      "        Path to the model.\n",
      "\n",
      "     Exactly one of these must be specified:\n",
      "\n",
      "       --json-instances=JSON_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          JSON format; newline delimited.\n",
      "\n",
      "          An example of the JSON instances file:\n",
      "\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 3}\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 2}\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "       --text-instances=TEXT_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          UTF-8 encoded text format; newline delimited.\n",
      "\n",
      "          An example of the text instances file:\n",
      "\n",
      "              107,4.9,2.5,4.5,1.7\n",
      "              100,5.7,2.8,4.1,1.3\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "OPTIONAL FLAGS\n",
      "     --framework=FRAMEWORK\n",
      "        The ML framework used to train this version of the model. If not\n",
      "        specified, defaults to tensorflow. FRAMEWORK must be one of:\n",
      "        scikit-learn, tensorflow, xgboost.\n",
      "\n",
      "     --signature-name=SIGNATURE_NAME\n",
      "        The name of the signature defined in the SavedModel to use for this\n",
      "        job. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY in\n",
      "        https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants,\n",
      "        which is \"serving_default\". Only applies to TensorFlow models.\n",
      "\n",
      "GCLOUD WIDE FLAGS\n",
      "    These flags are available to all commands: --account, --configuration,\n",
      "    --flatten, --format, --help, --log-http, --project, --quiet, --trace-token,\n",
      "    --user-output-enabled, --verbosity. Run $ gcloud help for details.\n",
      "\n",
      "NOTES\n",
      "    These variants are also available:\n",
      "\n",
      "        $ gcloud alpha ml-engine local predict\n",
      "        $ gcloud beta ml-engine local predict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running locally using gcloud </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-02-18 11:21:45.778736: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-18 11:21:45.785785: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# rm -rf taxifare.tar.gz taxi_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=${PKG_NAME}.task \\\n",
    "   --package-path=${PWD}/src/${PKG_NAME} \\\n",
    "   -- \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/${PKG_NAME}/trained \\\n",
    "   --train_steps=500 \\\n",
    "   --job_dir=./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise in TensorBoard\n",
    "\n",
    "In Datalab Tensorboard is available using a special package. On your local machine, you can execute tensorflow using the command line.\n",
    "\n",
    "DATALAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(('{}/'+os.environ['PKG_NAME']).format(os.environ['PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Machine: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mW0218 13:54:57.334849 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0218 13:54:57.334848 140204896913152 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0218 13:54:57.335278 Reloader tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0mW0218 13:54:57.335278 140204896913152 tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "TensorBoard 1.12.0 at http://enryh:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir $PWD/src/$PKG_NAME/trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above step (to stop TensorBoard) appears stalled, just move on to the next step. You don't need to wait for it to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Submit training job using gcloud </h2>\n",
    "\n",
    "First copy the training data to the cloud.  Then, launch a training job.\n",
    "\n",
    "After you submit the job, go to the cloud console (http://console.cloud.google.com) and select <b>Machine Learning | Jobs</b> to monitor progress.  \n",
    "\n",
    "<b>Note:</b> Don't be concerned if the notebook stalls (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud.  Use the Cloud Console link (above) to monitor the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -rf gs://$BUCKET/$PKG_NAME/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs using 10000 steps: 21.3\n",
      "For ten epochs specify 4688 steps\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "batch_size = 128\n",
    "n_train = 60000\n",
    "print(\"Number of epochs using {} steps: {:.1f}\".format(steps, steps * batch_size / n_train))\n",
    "steps = int(60000 / 128 * 10) + 1\n",
    "print(\"For ten epochs specify {} steps\".format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = '/'.join(['gs:/', BUCKET, PKG_NAME, 'trained'])\n",
    "os.environ['OUTDIR'] = OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/$PKG_NAME/trained\n",
    "JOBNAME=mnist_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=$PKG_NAME.task \\\n",
    "   --package-path=${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --data_path=\"gs://${BUCKET}/$PKG_NAME/\" \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000 \\\n",
    "   --job_dir=$OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-02-18T10:50:11Z'\n",
      "etag: vvITuWEjDLQ=\n",
      "jobId: mnist_190218_105007\n",
      "startTime: '2019-02-18T10:50:59Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/\n",
      "  - --output_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\n",
      "  - --train_steps=5000\n",
      "  - --job_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs\n",
      "  packageUris:\n",
      "  - gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "  pythonModule: pkg_mnist_fnn.task\n",
      "  pythonVersion: '3.5'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.12'\n",
      "trainingOutput: {}\n",
      "INFO\t2019-02-18 11:50:11 +0100\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-02-18 11:50:11 +0100\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-02-18 11:50:11 +0100\tservice\t\tJob mnist_190218_105007 is queued.\n",
      "INFO\t2019-02-18 11:50:12 +0100\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-02-18 11:50:16 +0100\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-02-18 11:51:28 +0100\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\"],  \"python_module\": \"pkg_mnist_fnn.task\",  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\", \"--train_steps\\u003d5000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs\"],  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "INFO\t2019-02-18 11:51:36 +0100\tmaster-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-02-18 11:51:36 +0100\tmaster-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:36 +0100\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:38 +0100\tmaster-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:38 +0100\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:40 +0100\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "ERROR\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:44 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-18 11:51:44 +0100\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-02-18 11:51:44 +0100\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "ERROR\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/ --output_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained --train_steps=5000 --job_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t    8192/11490434 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t 4202496/11490434 [=========>....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t10280960/11490434 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t11493376/11490434 [==============================] - 0s 0us/step\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tTF_CONFIG environment variable: {'environment': 'cloud', 'job': {'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz'], 'python_module': 'pkg_mnist_fnn.task', 'region': 'europe-west1', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/', '--output_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained', '--train_steps=5000', '--job_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs'], 'python_version': '3.5', 'run_on_raw_vm': True, 'runtime_version': '1.12'}, 'cluster': {'master': ['127.0.0.1:2222']}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'type': 'master', 'index': 0}}\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tUsing default config.\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tUsing config: {'_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_experimental_distribute': None, '_task_type': 'master', '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tgraph_options {\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t  }\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t}\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t, '_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feb9507d898>, '_protocol': None, '_task_id': 0, '_model_dir': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained', '_num_worker_replicas': 1, '_train_distribute': None, '_num_ps_replicas': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_service': None, '_save_summary_steps': 100, '_master': '', '_log_step_count_steps': 100, '_evaluation_master': ''}\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-18 11:51:52 +0100\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-18 11:51:52 +0100\tmaster-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tDone running local_init_op.\n",
      "WARNING\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-18 11:52:00 +0100\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt.\n",
      "INFO\t2019-02-18 11:52:16 +0100\tmaster-replica-0\t\tloss = 21020.336, step = 1\n",
      "INFO\t2019-02-18 11:52:18 +0100\tmaster-replica-0\t\tglobal_step/sec: 78.6377\n",
      "INFO\t2019-02-18 11:52:18 +0100\tmaster-replica-0\t\tloss = 378.62857, step = 101 (1.273 sec)\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tglobal_step/sec: 112.205\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tloss = 213.95734, step = 201 (0.891 sec)\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tglobal_step/sec: 121.735\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tloss = 140.99504, step = 301 (0.822 sec)\n",
      "INFO\t2019-02-18 11:52:20 +0100\tmaster-replica-0\t\tglobal_step/sec: 108.659\n",
      "INFO\t2019-02-18 11:52:20 +0100\tmaster-replica-0\t\tloss = 150.20166, step = 401 (0.920 sec)\n",
      "INFO\t2019-02-18 11:52:21 +0100\tmaster-replica-0\t\tglobal_step/sec: 95.2181\n",
      "INFO\t2019-02-18 11:52:21 +0100\tmaster-replica-0\t\tloss = 94.12981, step = 501 (1.051 sec)\n",
      "INFO\t2019-02-18 11:52:22 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.359\n",
      "INFO\t2019-02-18 11:52:22 +0100\tmaster-replica-0\t\tloss = 66.368744, step = 601 (0.873 sec)\n",
      "INFO\t2019-02-18 11:52:23 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.446\n",
      "INFO\t2019-02-18 11:52:23 +0100\tmaster-replica-0\t\tloss = 57.992844, step = 701 (0.810 sec)\n",
      "INFO\t2019-02-18 11:52:24 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.831\n",
      "INFO\t2019-02-18 11:52:24 +0100\tmaster-replica-0\t\tloss = 62.30481, step = 801 (0.864 sec)\n",
      "INFO\t2019-02-18 11:52:25 +0100\tmaster-replica-0\t\tglobal_step/sec: 104.807\n",
      "INFO\t2019-02-18 11:52:25 +0100\tmaster-replica-0\t\tloss = 40.41247, step = 901 (0.953 sec)\n",
      "INFO\t2019-02-18 11:52:26 +0100\tmaster-replica-0\t\tglobal_step/sec: 106.735\n",
      "INFO\t2019-02-18 11:52:26 +0100\tmaster-replica-0\t\tloss = 56.066887, step = 1001 (0.937 sec)\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.481\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tloss = 69.17212, step = 1101 (0.810 sec)\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tglobal_step/sec: 119.021\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tloss = 44.911655, step = 1201 (0.840 sec)\n",
      "INFO\t2019-02-18 11:52:28 +0100\tmaster-replica-0\t\tglobal_step/sec: 109.615\n",
      "INFO\t2019-02-18 11:52:28 +0100\tmaster-replica-0\t\tloss = 50.094032, step = 1301 (0.913 sec)\n",
      "INFO\t2019-02-18 11:52:29 +0100\tmaster-replica-0\t\tglobal_step/sec: 112.56\n",
      "INFO\t2019-02-18 11:52:29 +0100\tmaster-replica-0\t\tloss = 42.603745, step = 1401 (0.888 sec)\n",
      "INFO\t2019-02-18 11:52:30 +0100\tmaster-replica-0\t\tglobal_step/sec: 104.745\n",
      "INFO\t2019-02-18 11:52:30 +0100\tmaster-replica-0\t\tloss = 49.61542, step = 1501 (0.955 sec)\n",
      "INFO\t2019-02-18 11:52:31 +0100\tmaster-replica-0\t\tglobal_step/sec: 116.735\n",
      "INFO\t2019-02-18 11:52:31 +0100\tmaster-replica-0\t\tloss = 44.09514, step = 1601 (0.856 sec)\n",
      "INFO\t2019-02-18 11:52:32 +0100\tmaster-replica-0\t\tglobal_step/sec: 118.031\n",
      "INFO\t2019-02-18 11:52:32 +0100\tmaster-replica-0\t\tloss = 33.072594, step = 1701 (0.847 sec)\n",
      "INFO\t2019-02-18 11:52:33 +0100\tmaster-replica-0\t\tglobal_step/sec: 110.691\n",
      "INFO\t2019-02-18 11:52:33 +0100\tmaster-replica-0\t\tloss = 48.484806, step = 1801 (0.905 sec)\n",
      "INFO\t2019-02-18 11:52:34 +0100\tmaster-replica-0\t\tglobal_step/sec: 106.028\n",
      "INFO\t2019-02-18 11:52:34 +0100\tmaster-replica-0\t\tloss = 34.51955, step = 1901 (0.942 sec)\n",
      "INFO\t2019-02-18 11:52:35 +0100\tmaster-replica-0\t\tglobal_step/sec: 106.991\n",
      "INFO\t2019-02-18 11:52:35 +0100\tmaster-replica-0\t\tloss = 32.30279, step = 2001 (0.939 sec)\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.76\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tloss = 46.576942, step = 2101 (0.810 sec)\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.519\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tloss = 35.051426, step = 2201 (0.866 sec)\n",
      "INFO\t2019-02-18 11:52:37 +0100\tmaster-replica-0\t\tglobal_step/sec: 105.382\n",
      "INFO\t2019-02-18 11:52:37 +0100\tmaster-replica-0\t\tloss = 25.920006, step = 2301 (0.949 sec)\n",
      "INFO\t2019-02-18 11:52:38 +0100\tmaster-replica-0\t\tglobal_step/sec: 104.221\n",
      "INFO\t2019-02-18 11:52:38 +0100\tmaster-replica-0\t\tloss = 23.265404, step = 2401 (0.959 sec)\n",
      "INFO\t2019-02-18 11:52:39 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.531\n",
      "INFO\t2019-02-18 11:52:39 +0100\tmaster-replica-0\t\tloss = 39.81682, step = 2501 (0.817 sec)\n",
      "INFO\t2019-02-18 11:52:40 +0100\tmaster-replica-0\t\tglobal_step/sec: 117.08\n",
      "INFO\t2019-02-18 11:52:40 +0100\tmaster-replica-0\t\tloss = 25.22154, step = 2601 (0.854 sec)\n",
      "INFO\t2019-02-18 11:52:41 +0100\tmaster-replica-0\t\tglobal_step/sec: 113.846\n",
      "INFO\t2019-02-18 11:52:41 +0100\tmaster-replica-0\t\tloss = 35.81294, step = 2701 (0.878 sec)\n",
      "INFO\t2019-02-18 11:52:42 +0100\tmaster-replica-0\t\tglobal_step/sec: 110.905\n",
      "INFO\t2019-02-18 11:52:42 +0100\tmaster-replica-0\t\tloss = 22.22393, step = 2801 (0.902 sec)\n",
      "INFO\t2019-02-18 11:52:43 +0100\tmaster-replica-0\t\tglobal_step/sec: 103.384\n",
      "INFO\t2019-02-18 11:52:43 +0100\tmaster-replica-0\t\tloss = 10.681934, step = 2901 (0.967 sec)\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.221\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tloss = 32.20569, step = 3001 (0.812 sec)\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.252\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tloss = 38.779522, step = 3101 (0.811 sec)\n",
      "INFO\t2019-02-18 11:52:45 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.333\n",
      "INFO\t2019-02-18 11:52:45 +0100\tmaster-replica-0\t\tloss = 31.31158, step = 3201 (0.867 sec)\n",
      "INFO\t2019-02-18 11:52:46 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.921\n",
      "INFO\t2019-02-18 11:52:46 +0100\tmaster-replica-0\t\tloss = 30.353138, step = 3301 (0.870 sec)\n",
      "INFO\t2019-02-18 11:52:47 +0100\tmaster-replica-0\t\tglobal_step/sec: 102.897\n",
      "INFO\t2019-02-18 11:52:47 +0100\tmaster-replica-0\t\tloss = 29.302868, step = 3401 (0.972 sec)\n",
      "INFO\t2019-02-18 11:52:48 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.955\n",
      "INFO\t2019-02-18 11:52:48 +0100\tmaster-replica-0\t\tloss = 33.63176, step = 3501 (0.813 sec)\n",
      "INFO\t2019-02-18 11:52:49 +0100\tmaster-replica-0\t\tglobal_step/sec: 120.468\n",
      "INFO\t2019-02-18 11:52:49 +0100\tmaster-replica-0\t\tloss = 33.30413, step = 3601 (0.830 sec)\n",
      "INFO\t2019-02-18 11:52:50 +0100\tmaster-replica-0\t\tglobal_step/sec: 111.124\n",
      "INFO\t2019-02-18 11:52:50 +0100\tmaster-replica-0\t\tloss = 20.989494, step = 3701 (0.900 sec)\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tglobal_step/sec: 103.302\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tloss = 15.920492, step = 3801 (0.968 sec)\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.782\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tloss = 13.740409, step = 3901 (0.871 sec)\n",
      "INFO\t2019-02-18 11:52:52 +0100\tmaster-replica-0\t\tglobal_step/sec: 127.275\n",
      "INFO\t2019-02-18 11:52:52 +0100\tmaster-replica-0\t\tloss = 16.958536, step = 4001 (0.786 sec)\n",
      "INFO\t2019-02-18 11:52:53 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.455\n",
      "INFO\t2019-02-18 11:52:53 +0100\tmaster-replica-0\t\tloss = 6.3217974, step = 4101 (0.866 sec)\n",
      "INFO\t2019-02-18 11:52:54 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.527\n",
      "INFO\t2019-02-18 11:52:54 +0100\tmaster-replica-0\t\tloss = 33.860027, step = 4201 (0.873 sec)\n",
      "INFO\t2019-02-18 11:52:55 +0100\tmaster-replica-0\t\tglobal_step/sec: 103.225\n",
      "INFO\t2019-02-18 11:52:55 +0100\tmaster-replica-0\t\tloss = 44.772766, step = 4301 (0.969 sec)\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tglobal_step/sec: 128.288\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tloss = 20.107887, step = 4401 (0.779 sec)\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tglobal_step/sec: 132.392\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tloss = 31.663818, step = 4501 (0.755 sec)\n",
      "INFO\t2019-02-18 11:52:57 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.712\n",
      "INFO\t2019-02-18 11:52:57 +0100\tmaster-replica-0\t\tloss = 28.413416, step = 4601 (0.815 sec)\n",
      "INFO\t2019-02-18 11:52:58 +0100\tmaster-replica-0\t\tSaving checkpoints for 4688 into gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt.\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tStarting evaluation at 2019-02-18-10:53:15\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-18 11:53:16 +0100\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt-4688\n",
      "INFO\t2019-02-18 11:53:17 +0100\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-18 11:53:17 +0100\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-02-18 11:53:18 +0100\tmaster-replica-0\t\tFinished evaluation at 2019-02-18-10:53:18\n",
      "INFO\t2019-02-18 11:53:18 +0100\tmaster-replica-0\t\tSaving dict for global step 4688: accuracy = 0.9641, average_loss = 0.12913208, global_step = 4688, loss = 16.345833\n",
      "INFO\t2019-02-18 11:53:22 +0100\tmaster-replica-0\t\tSaving 'checkpoint_path' summary for global step 4688: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt-4688\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tExport includes no default signature!\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt-4688\n",
      "WARNING\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tAssets added to graph.\n",
      "INFO\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2019-02-18 11:53:42 +0100\tmaster-replica-0\t\tSavedModel written to: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/export/exporter/temp-b'1550487203'/saved_model.pb\n",
      "INFO\t2019-02-18 11:53:48 +0100\tmaster-replica-0\t\tLoss for final step: 11.554545.\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\t['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\tTask completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/mnist_190218_105007?project=ml-productive-pipeline-53122\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fmnist_190218_105007&project=ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs describe    mnist_190218_105007\n",
    "gcloud ml-engine jobs stream-logs mnist_190218_105007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't be concerned if the notebook appears stalled (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud. \n",
    "\n",
    "<b>Use the Cloud Console link to monitor the job and do NOT proceed until the job is done.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Results using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#gcloud auth application-default login\n",
    "echo $OUTDIR\n",
    "#tensorboard --logdir $OUTDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deploy model </h2>\n",
    "\n",
    "Find out the actual name of the subdirectory where the model is stored and use it to deploy the model.  Deploying model will take up to <b>5 minutes</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/$PKG_NAME/trained/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"MNIST_MLENGINE\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/$PKG_NAME/trained/export/exporter | tail -1)\n",
    "echo \"Run these commands one-by-one (the very first time, you'll create a model and then create a version)\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models   create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=data/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "  images = f.readlines()\n",
    "plt.figure(figsize=(20,4))\n",
    "for i, image in enumerate(images):\n",
    "  if i < 4:\n",
    "    image = json.loads(image)\n",
    "    image = np.array(image['x'])\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatly, we do not have a True Positve. ToDO: Add more examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions using the [Python-Client-Library, see Tutorial](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library). Since we have created and deployed a model already, we use the [`predict`](https://cloud.google.com/ml-engine/reference/rest/v1/projects) Method instead of `create` as in the documentation. \n",
    "\n",
    "[API-Reference](https://cloud.google.com/ml-engine/reference/rest/)\n",
    "\n",
    "If you need a service account authentification, please follow [this link]() and uncomment the celllines after this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %bash\n",
    "# export GOOGLE_APPLICATION_CREDENTIALS=$PWD/ML-productive-pipeline-53122-64d3c31786e7.json\n",
    "# echo $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/datalab/proj_DL_models_and_pipelines_with_GCP/notebook/../ML-productive-pipeline-53122-64d3c31786e7.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdoc discovery.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Signature: discovery.build(serviceName, version, http=None, discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', developerKey=None, model=None, requestBuilder=<class 'googleapiclient.http.HttpRequest'>, credentials=None, cache_discovery=True, cache=None)\n",
    "Docstring:\n",
    "Construct a Resource for interacting with an API.\n",
    "\n",
    "Construct a Resource object for interacting with an API. The serviceName and\n",
    "version are the names from the Discovery service.\n",
    "\n",
    "Args:\n",
    "serviceName: string, name of the service.\n",
    "version: string, the version of the service.\n",
    "http: httplib2.Http, An instance of httplib2.Http or something that acts\n",
    "like it that HTTP requests will be made through.\n",
    "discoveryServiceUrl: string, a URI Template that points to the location of\n",
    "the discovery service. It should have two parameters {api} and\n",
    "{apiVersion} that when filled in produce an absolute URI to the discovery\n",
    "document for that service.\n",
    "developerKey: string, key obtained from\n",
    "https://code.google.com/apis/console.\n",
    "model: googleapiclient.Model, converts to and from the wire format.\n",
    "requestBuilder: googleapiclient.http.HttpRequest, encapsulator for an HTTP\n",
    "request.\n",
    "credentials: oauth2client.Credentials or\n",
    "google.auth.credentials.Credentials, credentials to be used for\n",
    "authentication.\n",
    "cache_discovery: Boolean, whether or not to cache the discovery doc.\n",
    "cache: googleapiclient.discovery_cache.base.CacheBase, an optional\n",
    "cache object for the discovery documents.\n",
    "\n",
    "Returns:\n",
    "A Resource object with methods for interacting with the service.\n",
    "File: /usr/local/envs/py3env/lib/python3.5/site-packages/googleapiclient/discovery.py\n",
    "Type: function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = discovery.build(serviceName='ml', version='v1',\n",
    "                      http=None, \n",
    "                      discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', \n",
    "                      developerKey=None, \n",
    "                      model=None, \n",
    "                      #requestBuilder=<class 'googleapiclient.http.HttpRequest'>, \n",
    "                      credentials=None, \n",
    "                      cache_discovery=True, \n",
    "                      cache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MNIST_MLENGINE'\n",
    "VERSION = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(rel_path='data')\n",
    "N=4\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()\n",
    "\n",
    "eol = \"\\r\\n\"\n",
    "n_lines = len(y_test)\n",
    "instances = []\n",
    "with open(\"data/test.json\", \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        instances.append({\"x\": image}) #, \"y\": int(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, VERSION)\n",
    "request_data = {\"instances\":\n",
    "  [\n",
    "   {\"x\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.23529411852359772, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705882430076599, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9450980424880981, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.6666666865348816, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.4470588266849518, 0.2823529541492462, 0.4470588266849518, 0.6392157077789307, 0.8901960849761963, 0.9960784316062927, 0.8823529481887817, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9803921580314636, 0.8980392217636108, 0.9960784316062927, 0.9960784316062927, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.054901961237192154, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137255012989044, 0.08235294371843338, 0.9254902005195618, 0.9960784316062927, 0.4156862795352936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921568632125854, 0.8196078538894653, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137254953384399, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784316062927, 0.9333333373069763, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137255012989044, 0.9764705896377563, 0.9960784316062927, 0.24313725531101227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.8039215803146362, 0.9725490212440491, 0.22745098173618317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176474094391, 0.9960784316062927, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137264251709, 0.9411764740943909, 0.2235294133424759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666666746139526, 0.9960784316062927, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0117647061124444, 0.7960784435272217, 0.9960784316062927, 0.8588235378265381, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784316062927, 0.9960784316062927, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156862765550613, 0.8784313797950745, 0.9960784316062927, 0.45098039507865906, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239215686917305, 0.9490196108818054, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.9960784316062927, 0.8588235378265381, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.8117647171020508, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
    "  ]\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
