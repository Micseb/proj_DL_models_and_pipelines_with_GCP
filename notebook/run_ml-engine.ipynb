{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Scaling up ML using Cloud ML Engine </h1>\n",
    "\n",
    "Adapted from [Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/cloudmle/cloudmle.ipynb) of Google Coursera Course [Serverless Machine Learning with Tensorflow on Google Cloud Platform](https://www.coursera.org/learn/serverless-machine-learning-gcp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: /content/datalab/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WORKINGDIR = os.getcwd()\n",
    "folders = WORKINGDIR.split('/')\n",
    "if folders.pop() == 'notebook':  # or a list: in ['notebook', 'src', etc.]\n",
    "  WORKINGDIR = '/'.join(folders)\n",
    "  print(\"New working directory: {}\".format(WORKINGDIR))\n",
    "else:\n",
    "  print(\"Current Working direcotory is kept: {}\".format(WORKINGDIR))\n",
    "os.chdir(WORKINGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Environment variables for project and bucket </h2>\n",
    "\n",
    "Note that:\n",
    "<ol>\n",
    "<li> Your project id is the *unique* string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads:  \n",
    "     \n",
    "     Project ID: ml-productive-pipeline-12345\n",
    "<li> Cloud training often involves saving and restoring model files. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available). A common pattern is to prefix the bucket name by the project id, so that it is unique. Also, for cost reasons, you might want to use a single region bucket. </li>\n",
    "</ol>\n",
    "\n",
    "<b>Add all detail in to [config.yaml](../config.yaml) file in main directory. Missing in public repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket': 'ml-productive-pipeline-53122', 'region': 'europe-west1', 'project-id': 'ml-productive-pipeline-53122', 'tf-version': 1.12}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "    \n",
    "print(config)\n",
    "\n",
    "# # #Create config manually and save as yaml:\n",
    "# config = {}\n",
    "# config['project-id'] = 'PROJECT'  # # REPLACE WITH YOUR PROJECT ID\n",
    "# config['region'] = 'europe-west1' # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "# config['bucket'] = 'Bucket-name'  # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "# \n",
    "# with open(\"../config_from_python.yaml\", 'wb', encoding= 'utf8') as f:\n",
    "#     yaml.dump(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO persistently add variables to the runtime of the datalab kernel, us the build in python function `os.environ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can access the environement variable in the terminal running this datalab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo $TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow the Cloud ML Engine service account to read/write to the bucket containing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "# echo $AUTH_TOKEN\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print(response['serviceAccount'])\")\n",
    "echo \"Current Service Account of VM: $SVC_ACCOUNT\"\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in Bucket: $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Packaging up the code </h2>\n",
    "\n",
    "Take your code and put into a standard Python package structure, see  <a href=\"package_ml_engine/mnist_ml_engine.py\">model.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\r\n",
      "First try to start Cloud ML\r\n",
      "\r\n",
      "References:\r\n",
      "Basic reference for packaging the model so that ml-engine can use it:\r\n",
      "- https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/cloudmle/taxifare\r\n",
      "MNIST-Estimator-Example:\r\n",
      "- https://codeburst.io/use-tensorflow-dnnclassifier-estimator-to-classify-mnist-dataset-a7222bf9f940\r\n",
      "\r\n",
      "ipython -i -m src.models.test_model_estimator_api.mnist_ml_engine -- --data_path=data --output_dir=src\\models\\test_model_estimator_api\\trained --train_steps=100\r\n",
      "\"\"\"\r\n",
      "import os\r\n",
      "import argparse\r\n",
      "import json\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "import numpy as np\r\n",
      "import shutil\r\n",
      "\r\n",
      "from package_ml_engine.utils import load_data\r\n",
      "\r\n",
      "###############################################################################\r\n",
      "#Factor into config:\r\n",
      "N_PIXEL = 784\r\n",
      "OUTDIR = 'trained'\r\n",
      "USE_TPU = False\r\n",
      "EPOCHS = 10\r\n",
      "\r\n",
      "if USE_TPU:\r\n",
      "    _device_update = 'tpu'\r\n",
      "else:\r\n",
      "    _device_update = 'cpu'\r\n",
      "\r\n",
      "IMAGE_SIZE = 28 * 28\r\n",
      "NUM_LABELS = 10\r\n",
      "BATCH_SIZE = 128\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "\r\n",
      "def parse_images(x):\r\n",
      "    return x.reshape(len(x), -1).astype('float32')\r\n",
      "\r\n",
      "\r\n",
      "def parse_labels(y):\r\n",
      "    return y.astype('int32')\r\n",
      "\r\n",
      "\r\n",
      "def numpy_input_fn(images: np.ndarray, labels: np.ndarray, mode=tf.estimator.ModeKeys.EVAL):\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        _epochs = EPOCHS\r\n",
      "        _shuffle = True\r\n",
      "        _num_threads = 2\r\n",
      "    else:\r\n",
      "        _epochs = 1\r\n",
      "        _shuffle = False\r\n",
      "        _num_threads = 1\r\n",
      "\r\n",
      "    return tf.estimator.inputs.numpy_input_fn(\r\n",
      "        {'x': images},\r\n",
      "        y=labels,\r\n",
      "        batch_size=BATCH_SIZE,\r\n",
      "        num_epochs=_epochs,\r\n",
      "        # Boolean, if True shuffles the queue. Avoid shuffle at prediction time.\r\n",
      "        shuffle=_shuffle,\r\n",
      "        queue_capacity=1000,\r\n",
      "        # Integer, number of threads used for reading and enqueueing. In order to have predicted and repeatable order of reading and enqueueing, such as in prediction and evaluation mode, num_threads should be 1.\r\n",
      "        num_threads=_num_threads\r\n",
      "    )\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_placeholders = {\r\n",
      "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\r\n",
      "    }\r\n",
      "    features = feature_placeholders\r\n",
      "    return tf.estimator.export.ServingInputReceiver(\r\n",
      "         features=features, \r\n",
      "         receiver_tensors=feature_placeholders,\r\n",
      "         receiver_tensors_alternatives=None\r\n",
      "         )\r\n",
      "\r\n",
      "\r\n",
      "def train_and_evaluate(args):\r\n",
      "    \"\"\"\r\n",
      "    Utility function for distributed training on ML-Engine\r\n",
      "    https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \r\n",
      "    \"\"\"\r\n",
      "    model = tf.estimator.DNNClassifier(\r\n",
      "        hidden_units=[256, 128, 64],\r\n",
      "        feature_columns=[tf.feature_column.numeric_column(\r\n",
      "            'x', shape=[N_PIXEL, ])],\r\n",
      "        model_dir=args['output_dir'],\r\n",
      "        n_classes=10,\r\n",
      "        optimizer=tf.train.AdamOptimizer,\r\n",
      "        # activation_fn=,\r\n",
      "        dropout=0.2,\r\n",
      "        batch_norm=False,\r\n",
      "        loss_reduction='weighted_sum',\r\n",
      "        warm_start_from=None\r\n",
      "    )\r\n",
      "   \r\n",
      "    train_spec = tf.estimator.TrainSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN),\r\n",
      "        max_steps=args['train_steps']\r\n",
      "    )\r\n",
      "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\r\n",
      "    eval_spec = tf.estimator.EvalSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\r\n",
      "        steps=None,\r\n",
      "        start_delay_secs=args['eval_delay_secs'],\r\n",
      "        throttle_secs=args['min_eval_frequency'],\r\n",
      "        exporters=exporter\r\n",
      "    )\r\n",
      "    tf.estimator.train_and_evaluate(\r\n",
      "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\r\n",
      "    print((model.get_variable_names()))\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument(\r\n",
      "        '--data_path',\r\n",
      "        help='GCS or local path to training data',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--output_dir',\r\n",
      "        help='GCS location to write checkpoints and export models',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_batch_size',\r\n",
      "        help='Batch size for training steps',\r\n",
      "        type=int,\r\n",
      "        default='128'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_steps',\r\n",
      "        help='Steps to run the training job for',\r\n",
      "        type=int,\r\n",
      "        default='200'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--hidden_units',\r\n",
      "        help='List of hidden layer sizes to use for DNN feature columns',\r\n",
      "        nargs='+',\r\n",
      "        type=int,\r\n",
      "        default=[128, 64, 32]\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--job_dir',\r\n",
      "        help='this model ignores this field, but it is required by gcloud',\r\n",
      "        default='junk'\r\n",
      "    )\r\n",
      "    # Eval arguments\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_delay_secs',\r\n",
      "        help='How long to wait before running first evaluation',\r\n",
      "        default='10',\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--min_eval_frequency',\r\n",
      "        help='Seconds between evaluations',\r\n",
      "        default=300,\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "\r\n",
      "    args = parser.parse_args().__dict__\r\n",
      "\r\n",
      "    OUTDIR = args['output_dir']\r\n",
      "    ##########################################\r\n",
      "    # Load Data in Memoery\r\n",
      "\r\n",
      "    #ToDo: Connect bucket:\r\n",
      "    (x_train, y_train), (x_test, y_test) = load_data(\r\n",
      "        rel_path=args['data_path'])\r\n",
      "    # #ToDo: replace numpy-arrays\r\n",
      "\r\n",
      "    x_train = parse_images(x_train)\r\n",
      "    x_test = parse_images(x_test)\r\n",
      "\r\n",
      "    y_train = parse_labels(y_train)\r\n",
      "    y_test = parse_labels(y_test)\r\n",
      "\r\n",
      "    # Define model\r\n",
      "\r\n",
      "    # #######################################\r\n",
      "    # # Train\r\n",
      "    shutil.rmtree(OUTDIR, ignore_errors=True)  # start fresh each time\r\n",
      "    \r\n",
      "    train_and_evaluate(args)\r\n",
      "\r\n",
      "\r\n",
      "    # model.train(input_fn=numpy_input_fn(\r\n",
      "    #     x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN))\r\n",
      "    # # #######################################\r\n",
      "    # # # Evaluate\r\n",
      "    # metrics_train = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(x_train, y_train, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # metrics_test = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(\r\n",
      "    #         x_test, y_test, mode=tf.estimator.ModeKeys.EVAL)\r\n",
      "    # )\r\n",
      "    # import pandas as pd\r\n",
      "    # metrics = pd.DataFrame(\r\n",
      "    #     {'Train': metrics_train, 'Test': metrics_test}).transpose()\r\n",
      "    # print(\"## Metrics DF\\n\", metrics)\r\n",
      "    # # #######################################\r\n",
      "    # # # get individual predictions:\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # for i, pred in enumerate(predictions_iterator):\r\n",
      "    #     if i % 999 == 0:\r\n",
      "    #         print('Image: {}'.format(i))\r\n",
      "    #         print(pred)\r\n",
      "    # #ToDo: 10000 Test-Images yield 20000 predictions?!\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # assert len(list(predictions_iterator)) == len(x_test)\r\n"
     ]
    }
   ],
   "source": [
    "!cat src/package_ml_engine/mnist_ml_engine.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Find absolute paths to your data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the absolute paths below.\n",
    "`/content` is mapped in Datalab to where the home icon takes you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/datalab/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo $PWD\n",
    "rm -rf $PWD/src/package_ml_engine/trained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running the Python module from the command-line </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-02-12 16:23:43.305371: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "# rm -rf package_ml_engine.tar.gz ${PWD}/package_ml_engine/trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/../\n",
    "python -m src.package_ml_engine.mnist_ml_engine \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/package_ml_engine/trained \\\n",
    "   --train_steps=100 \\\n",
    "   --job_dir=./tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1549988626\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "ls $PWD/src/package_ml_engine/trained/export/exporter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an test-image in numpy format saved as json (copy from test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/test.json\n"
     ]
    }
   ],
   "source": [
    "%writefile data/test.json\n",
    "{\"x\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.23529411852359772, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705882430076599, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9450980424880981, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.6666666865348816, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.4470588266849518, 0.2823529541492462, 0.4470588266849518, 0.6392157077789307, 0.8901960849761963, 0.9960784316062927, 0.8823529481887817, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9803921580314636, 0.8980392217636108, 0.9960784316062927, 0.9960784316062927, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.054901961237192154, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137255012989044, 0.08235294371843338, 0.9254902005195618, 0.9960784316062927, 0.4156862795352936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921568632125854, 0.8196078538894653, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137254953384399, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784316062927, 0.9333333373069763, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137255012989044, 0.9764705896377563, 0.9960784316062927, 0.24313725531101227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.8039215803146362, 0.9725490212440491, 0.22745098173618317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176474094391, 0.9960784316062927, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137264251709, 0.9411764740943909, 0.2235294133424759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666666746139526, 0.9960784316062927, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0117647061124444, 0.7960784435272217, 0.9960784316062927, 0.8588235378265381, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784316062927, 0.9960784316062927, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156862765550613, 0.8784313797950745, 0.9960784316062927, 0.45098039507865906, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239215686917305, 0.9490196108818054, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.9960784316062927, 0.8588235378265381, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.8117647171020508, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f42d7aed828>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42d7aed1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "image = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.23529411852359772, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705882430076599, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9450980424880981, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.6666666865348816, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.4470588266849518, 0.2823529541492462, 0.4470588266849518, 0.6392157077789307, 0.8901960849761963, 0.9960784316062927, 0.8823529481887817, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9803921580314636, 0.8980392217636108, 0.9960784316062927, 0.9960784316062927, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.054901961237192154, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137255012989044, 0.08235294371843338, 0.9254902005195618, 0.9960784316062927, 0.4156862795352936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921568632125854, 0.8196078538894653, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137254953384399, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784316062927, 0.9333333373069763, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137255012989044, 0.9764705896377563, 0.9960784316062927, 0.24313725531101227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.8039215803146362, 0.9725490212440491, 0.22745098173618317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176474094391, 0.9960784316062927, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137264251709, 0.9411764740943909, 0.2235294133424759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666666746139526, 0.9960784316062927, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0117647061124444, 0.7960784435272217, 0.9960784316062927, 0.8588235378265381, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784316062927, 0.9960784316062927, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156862765550613, 0.8784313797950745, 0.9960784316062927, 0.45098039507865906, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239215686917305, 0.9490196108818054, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.9960784316062927, 0.8588235378265381, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.8117647171020508, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with Python 3, delete the `*.pyc` files, see [post](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model:  1549988626\n",
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                                           PROBABILITIES\n",
      "[7]        [u'7']   [-0.10308753699064255, 0.0027766134589910507, 0.008046627044677734, -0.062273938208818436, -0.021005088463425636, -0.010045293718576431, -0.0804160013794899, 0.05865110456943512, -0.030750004574656487, 0.005777463316917419]  [0.0922301635146141, 0.10252958536148071, 0.10307133942842484, 0.09607227891683578, 0.10012001544237137, 0.10122334957122803, 0.09434504061937332, 0.1084214374423027, 0.09914910048246384, 0.10283771902322769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Running [gcloud.ml-engine.local.predict] with arguments: [--json-instances: \"./data/test.json\", --model-dir: \"/content/datalab/proj_DL_models_and_pipelines_with_GCP/src/package_ml_engine/trained/export/exporter/1549988626\", --verbosity: \"debug\"]\n",
      "WARNING: 2019-02-12 16:27:16.680845: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "\n",
      "INFO: Display format: \"default \n",
      "          table(\n",
      "              predictions:format=\"table(\n",
      "                  class_ids, classes, logits, probabilities\n",
      "              )\"\n",
      "          )\"\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "#remove any pyc files: Using Python3 you have to recompile\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "## local predict doesn't work with Python 3 yet\n",
    "model_dir=$(ls $PWD/src/package_ml_engine/trained/export/exporter/)\n",
    "echo \"Selected Model:  $model_dir\"\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/src/package_ml_engine/trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=./data/test.json \\\n",
    "    --verbosity debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "    gcloud ml-engine local predict - run prediction locally\n",
      "\n",
      "SYNOPSIS\n",
      "    gcloud ml-engine local predict --model-dir=MODEL_DIR\n",
      "        (--json-instances=JSON_INSTANCES | --text-instances=TEXT_INSTANCES)\n",
      "        [--framework=FRAMEWORK] [--signature-name=SIGNATURE_NAME]\n",
      "        [GCLOUD_WIDE_FLAG ...]\n",
      "\n",
      "DESCRIPTION\n",
      "    gcloud ml-engine local predict performs prediction locally with the given\n",
      "    instances. It requires the TensorFlow SDK be installed locally. The output\n",
      "    format mirrors gcloud ml-engine predict (online prediction)\n",
      "\n",
      "REQUIRED FLAGS\n",
      "     --model-dir=MODEL_DIR\n",
      "        Path to the model.\n",
      "\n",
      "     Exactly one of these must be specified:\n",
      "\n",
      "       --json-instances=JSON_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          JSON format; newline delimited.\n",
      "\n",
      "          An example of the JSON instances file:\n",
      "\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 3}\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 2}\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "       --text-instances=TEXT_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          UTF-8 encoded text format; newline delimited.\n",
      "\n",
      "          An example of the text instances file:\n",
      "\n",
      "              107,4.9,2.5,4.5,1.7\n",
      "              100,5.7,2.8,4.1,1.3\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "OPTIONAL FLAGS\n",
      "     --framework=FRAMEWORK\n",
      "        The ML framework used to train this version of the model. If not\n",
      "        specified, defaults to tensorflow. FRAMEWORK must be one of:\n",
      "        scikit-learn, tensorflow, xgboost.\n",
      "\n",
      "     --signature-name=SIGNATURE_NAME\n",
      "        The name of the signature defined in the SavedModel to use for this\n",
      "        job. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY in\n",
      "        https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants,\n",
      "        which is \"serving_default\". Only applies to TensorFlow models.\n",
      "\n",
      "GCLOUD WIDE FLAGS\n",
      "    These flags are available to all commands: --account, --configuration,\n",
      "    --flags-file, --flatten, --format, --help, --log-http, --project, --quiet,\n",
      "    --trace-token, --user-output-enabled, --verbosity. Run $ gcloud help for\n",
      "    details.\n",
      "\n",
      "NOTES\n",
      "    These variants are also available:\n",
      "\n",
      "        $ gcloud alpha ml-engine local predict\n",
      "        $ gcloud beta ml-engine local predict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running locally using gcloud </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "# rm -rf taxifare.tar.gz taxi_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=package_ml_engine.mnist_ml_engine \\\n",
    "   --package-path=${PWD}/src/package_ml_engine \\\n",
    "   -- \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/package_ml_engine/trained \\\n",
    "   --train_steps=500 \n",
    "   --job_dir=./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('{}/package_ml_engine'.format(os.environ['PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above step (to stop TensorBoard) appears stalled, just move on to the next step. You don't need to wait for it to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Submit training job using gcloud </h2>\n",
    "\n",
    "First copy the training data to the cloud.  Then, launch a training job.\n",
    "\n",
    "After you submit the job, go to the cloud console (http://console.cloud.google.com) and select <b>Machine Learning | Jobs</b> to monitor progress.  \n",
    "\n",
    "<b>Note:</b> Don't be concerned if the notebook stalls (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud.  Use the Cloud Console link (above) to monitor the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/mnist_ml_engine/*\n",
    "gsutil -m cp ${PWD}/data/mnist.npy gs://${BUCKET}/mnist_ml_engine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs using 10000 steps: 21.3\n",
      "For ten epochs specify 4688 steps\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "batch_size = 128\n",
    "n_train = 60000\n",
    "print(\"Number of epochs using {} steps: {:.1f}\".format(steps, steps * batch_size / n_train))\n",
    "steps = int(60000 / 128 * 10) + 1\n",
    "print(\"For ten epochs specify {} steps\".format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained europe-west1 mnist_190213_091458\n",
      "jobId: mnist_190213_091458\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [mnist_190213_091458] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_190213_091458\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190213_091458\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/mnist_ml_engine/trained\n",
    "JOBNAME=mnist_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=package_ml_engine.mnist_ml_engine \\\n",
    "   --package-path=${PWD}/src/package_ml_engine \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --data_path=\"gs://${BUCKET}/mnist_ml_engine/\" \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000 \\\n",
    "   --job_dir=$OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-02-13T09:15:01Z'\n",
      "etag: vILgAPivuaI=\n",
      "jobId: mnist_190213_091458\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path=gs://ml-productive-pipeline-53122/mnist_ml_engine/\n",
      "  - --output_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained\n",
      "  - --train_steps=5000\n",
      "  - --job_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs\n",
      "  packageUris:\n",
      "  - gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "  pythonModule: package_ml_engine.mnist_ml_engine\n",
      "  pythonVersion: '3.5'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.12'\n",
      "trainingOutput: {}\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tJob mnist_190213_091458 is queued.\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-02-13 09:15:06 +0000\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-02-13 09:16:49 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"https://2222-dot-5440812-dot-devshell.appspot.com\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\"],  \"python_module\": \"package_ml_engine.mnist_ml_engine\",  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/mnist_ml_engine/\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_ml_engine/trained\", \"--train_steps\\u003d5000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs\"],  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "INFO\t2019-02-13 09:17:08 +0000\tmaster-replica-0\t\tRunning module package_ml_engine.mnist_ml_engine.\n",
      "INFO\t2019-02-13 09:17:08 +0000\tmaster-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:08 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:11 +0000\tmaster-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:11 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:12 +0000\tmaster-replica-0\t\tProcessing ./package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:13 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:13 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): started\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/df/18/f2/2e166baf1f651d60056cb019a95433f05a81ed75186978c5d5\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tSuccessfully built package-ml-engine\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tInstalling collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tSuccessfully installed package-ml-engine-0.0.0\n",
      "ERROR\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tProcessing ./package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): started\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/df/18/f2/2e166baf1f651d60056cb019a95433f05a81ed75186978c5d5\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\tSuccessfully built package-ml-engine\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tInstalling collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\t  Found existing installation: package-ml-engine 0.0.0\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\t    Uninstalling package-ml-engine-0.0.0:\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\t      Successfully uninstalled package-ml-engine-0.0.0\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tSuccessfully installed package-ml-engine-0.0.0\n",
      "ERROR\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tRunning command: python3 -m package_ml_engine.mnist_ml_engine --data_path=gs://ml-productive-pipeline-53122/mnist_ml_engine/ --output_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained --train_steps=5000 --job_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs\n",
      "INFO\t2019-02-13 09:17:20 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t    8192/11490434 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t 4202496/11490434 [=========>....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t11493376/11490434 [==============================] - 0s 0us/step\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tTF_CONFIG environment variable: {'environment': 'cloud', 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'master'}, 'cluster': {'master': ['https://2222-dot-5440812-dot-devshell.appspot.com']}, 'job': {'run_on_raw_vm': True, 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz'], 'python_module': 'package_ml_engine.mnist_ml_engine', 'runtime_version': '1.12', 'python_version': '3.5', 'region': 'europe-west1', 'args': ['--data_path=gs://ml-productive-pipeline-53122/mnist_ml_engine/', '--output_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained', '--train_steps=5000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs']}}\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tUsing default config.\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tUsing config: {'_experimental_distribute': None, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_evaluation_master': '', '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f11b6132c50>, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tgraph_options {\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t  }\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t}\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_ml_engine/trained', '_is_chief': True, '_eval_distribute': None, '_save_checkpoints_steps': None, '_master': '', '_service': None, '_protocol': None, '_device_fn': None, '_task_type': 'master', '_train_distribute': None}\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-02-13 09:17:30 +0000\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-13 09:17:30 +0000\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0\n",
      "INFO\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tDone running local_init_op.\n",
      "WARNING\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-13 09:17:34 +0000\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt.\n",
      "INFO\t2019-02-13 09:17:48 +0000\tmaster-replica-0\t\tloss = 13075.43, step = 1\n",
      "INFO\t2019-02-13 09:17:49 +0000\tmaster-replica-0\t\tglobal_step/sec: 105.938\n",
      "INFO\t2019-02-13 09:17:49 +0000\tmaster-replica-0\t\tloss = 318.757, step = 101 (0.945 sec)\n",
      "INFO\t2019-02-13 09:17:50 +0000\tmaster-replica-0\t\tglobal_step/sec: 115.009\n",
      "INFO\t2019-02-13 09:17:50 +0000\tmaster-replica-0\t\tloss = 208.0139, step = 201 (0.869 sec)\n",
      "INFO\t2019-02-13 09:17:51 +0000\tmaster-replica-0\t\tglobal_step/sec: 103.904\n",
      "INFO\t2019-02-13 09:17:51 +0000\tmaster-replica-0\t\tloss = 190.60722, step = 301 (0.963 sec)\n",
      "INFO\t2019-02-13 09:17:52 +0000\tmaster-replica-0\t\tglobal_step/sec: 134.363\n",
      "INFO\t2019-02-13 09:17:52 +0000\tmaster-replica-0\t\tloss = 76.427704, step = 401 (0.744 sec)\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.016\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tloss = 102.79257, step = 501 (0.735 sec)\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.007\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tloss = 72.16882, step = 601 (0.862 sec)\n",
      "INFO\t2019-02-13 09:17:54 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.482\n",
      "INFO\t2019-02-13 09:17:54 +0000\tmaster-replica-0\t\tloss = 103.51003, step = 701 (0.859 sec)\n",
      "INFO\t2019-02-13 09:17:55 +0000\tmaster-replica-0\t\tglobal_step/sec: 112.921\n",
      "INFO\t2019-02-13 09:17:55 +0000\tmaster-replica-0\t\tloss = 74.13242, step = 801 (0.885 sec)\n",
      "INFO\t2019-02-13 09:17:56 +0000\tmaster-replica-0\t\tglobal_step/sec: 135.018\n",
      "INFO\t2019-02-13 09:17:56 +0000\tmaster-replica-0\t\tloss = 49.98626, step = 901 (0.741 sec)\n",
      "INFO\t2019-02-13 09:17:57 +0000\tmaster-replica-0\t\tglobal_step/sec: 137.529\n",
      "INFO\t2019-02-13 09:17:57 +0000\tmaster-replica-0\t\tloss = 65.611725, step = 1001 (0.727 sec)\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tglobal_step/sec: 113.163\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tloss = 67.49064, step = 1101 (0.884 sec)\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tglobal_step/sec: 120.725\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tloss = 100.73499, step = 1201 (0.828 sec)\n",
      "INFO\t2019-02-13 09:17:59 +0000\tmaster-replica-0\t\tglobal_step/sec: 112.274\n",
      "INFO\t2019-02-13 09:17:59 +0000\tmaster-replica-0\t\tloss = 53.569622, step = 1301 (0.891 sec)\n",
      "INFO\t2019-02-13 09:18:00 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.335\n",
      "INFO\t2019-02-13 09:18:00 +0000\tmaster-replica-0\t\tloss = 67.22011, step = 1401 (0.733 sec)\n",
      "INFO\t2019-02-13 09:18:01 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.526\n",
      "INFO\t2019-02-13 09:18:01 +0000\tmaster-replica-0\t\tloss = 64.85119, step = 1501 (0.798 sec)\n",
      "INFO\t2019-02-13 09:18:02 +0000\tmaster-replica-0\t\tglobal_step/sec: 109.054\n",
      "INFO\t2019-02-13 09:18:02 +0000\tmaster-replica-0\t\tloss = 48.82122, step = 1601 (0.916 sec)\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tglobal_step/sec: 120.836\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tloss = 41.147453, step = 1701 (0.828 sec)\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.791\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tloss = 76.92012, step = 1801 (0.856 sec)\n",
      "INFO\t2019-02-13 09:18:04 +0000\tmaster-replica-0\t\tglobal_step/sec: 134.562\n",
      "INFO\t2019-02-13 09:18:04 +0000\tmaster-replica-0\t\tloss = 46.08581, step = 1901 (0.743 sec)\n",
      "INFO\t2019-02-13 09:18:05 +0000\tmaster-replica-0\t\tglobal_step/sec: 132.02\n",
      "INFO\t2019-02-13 09:18:05 +0000\tmaster-replica-0\t\tloss = 33.523735, step = 2001 (0.758 sec)\n",
      "INFO\t2019-02-13 09:18:06 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.853\n",
      "INFO\t2019-02-13 09:18:06 +0000\tmaster-replica-0\t\tloss = 51.156525, step = 2101 (0.856 sec)\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tglobal_step/sec: 123.218\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tloss = 30.585655, step = 2201 (0.811 sec)\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tglobal_step/sec: 110.503\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tloss = 68.79298, step = 2301 (0.906 sec)\n",
      "INFO\t2019-02-13 09:18:08 +0000\tmaster-replica-0\t\tglobal_step/sec: 135.496\n",
      "INFO\t2019-02-13 09:18:08 +0000\tmaster-replica-0\t\tloss = 44.77977, step = 2401 (0.737 sec)\n",
      "INFO\t2019-02-13 09:18:09 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.105\n",
      "INFO\t2019-02-13 09:18:09 +0000\tmaster-replica-0\t\tloss = 51.819206, step = 2501 (0.735 sec)\n",
      "INFO\t2019-02-13 09:18:10 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.116\n",
      "INFO\t2019-02-13 09:18:10 +0000\tmaster-replica-0\t\tloss = 17.188972, step = 2601 (0.800 sec)\n",
      "INFO\t2019-02-13 09:18:11 +0000\tmaster-replica-0\t\tglobal_step/sec: 117.026\n",
      "INFO\t2019-02-13 09:18:11 +0000\tmaster-replica-0\t\tloss = 21.325272, step = 2701 (0.854 sec)\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tglobal_step/sec: 108.349\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tloss = 42.392746, step = 2801 (0.923 sec)\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tglobal_step/sec: 140.052\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tloss = 10.836456, step = 2901 (0.714 sec)\n",
      "INFO\t2019-02-13 09:18:13 +0000\tmaster-replica-0\t\tglobal_step/sec: 137.359\n",
      "INFO\t2019-02-13 09:18:13 +0000\tmaster-replica-0\t\tloss = 42.19614, step = 3001 (0.728 sec)\n",
      "INFO\t2019-02-13 09:18:14 +0000\tmaster-replica-0\t\tglobal_step/sec: 119.614\n",
      "INFO\t2019-02-13 09:18:14 +0000\tmaster-replica-0\t\tloss = 32.07009, step = 3101 (0.836 sec)\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.334\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tloss = 37.049297, step = 3201 (0.798 sec)\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tglobal_step/sec: 117.607\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tloss = 32.161743, step = 3301 (0.850 sec)\n",
      "INFO\t2019-02-13 09:18:16 +0000\tmaster-replica-0\t\tglobal_step/sec: 134.415\n",
      "INFO\t2019-02-13 09:18:16 +0000\tmaster-replica-0\t\tloss = 37.10141, step = 3401 (0.744 sec)\n",
      "INFO\t2019-02-13 09:18:17 +0000\tmaster-replica-0\t\tglobal_step/sec: 137.747\n",
      "INFO\t2019-02-13 09:18:17 +0000\tmaster-replica-0\t\tloss = 34.537544, step = 3501 (0.726 sec)\n",
      "INFO\t2019-02-13 09:18:18 +0000\tmaster-replica-0\t\tglobal_step/sec: 119.734\n",
      "INFO\t2019-02-13 09:18:18 +0000\tmaster-replica-0\t\tloss = 20.027512, step = 3601 (0.835 sec)\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tglobal_step/sec: 124.916\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tloss = 30.818651, step = 3701 (0.800 sec)\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tglobal_step/sec: 117.477\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tloss = 28.916504, step = 3801 (0.851 sec)\n",
      "INFO\t2019-02-13 09:18:20 +0000\tmaster-replica-0\t\tglobal_step/sec: 138.645\n",
      "INFO\t2019-02-13 09:18:20 +0000\tmaster-replica-0\t\tloss = 43.644524, step = 3901 (0.721 sec)\n",
      "INFO\t2019-02-13 09:18:21 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.812\n",
      "INFO\t2019-02-13 09:18:21 +0000\tmaster-replica-0\t\tloss = 13.6148205, step = 4001 (0.731 sec)\n",
      "INFO\t2019-02-13 09:18:22 +0000\tmaster-replica-0\t\tglobal_step/sec: 122.17\n",
      "INFO\t2019-02-13 09:18:22 +0000\tmaster-replica-0\t\tloss = 33.355637, step = 4101 (0.818 sec)\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tglobal_step/sec: 120.675\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tloss = 29.438255, step = 4201 (0.829 sec)\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tglobal_step/sec: 112.994\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tloss = 43.37506, step = 4301 (0.885 sec)\n",
      "INFO\t2019-02-13 09:18:24 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.65\n",
      "INFO\t2019-02-13 09:18:24 +0000\tmaster-replica-0\t\tloss = 18.002005, step = 4401 (0.732 sec)\n",
      "INFO\t2019-02-13 09:18:25 +0000\tmaster-replica-0\t\tglobal_step/sec: 146.716\n",
      "INFO\t2019-02-13 09:18:25 +0000\tmaster-replica-0\t\tloss = 8.663489, step = 4501 (0.681 sec)\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.573\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tloss = 31.115616, step = 4601 (0.733 sec)\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tglobal_step/sec: 130.71\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tloss = 17.96559, step = 4701 (0.765 sec)\n",
      "INFO\t2019-02-13 09:18:27 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.344\n",
      "INFO\t2019-02-13 09:18:27 +0000\tmaster-replica-0\t\tloss = 47.409725, step = 4801 (0.798 sec)\n",
      "INFO\t2019-02-13 09:18:28 +0000\tmaster-replica-0\t\tglobal_step/sec: 147.263\n",
      "INFO\t2019-02-13 09:18:28 +0000\tmaster-replica-0\t\tloss = 25.811298, step = 4901 (0.679 sec)\n",
      "INFO\t2019-02-13 09:18:28 +0000\tmaster-replica-0\t\tSaving checkpoints for 5000 into gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt.\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tStarting evaluation at 2019-02-13-09:18:43\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-13 09:18:44 +0000\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000\n",
      "INFO\t2019-02-13 09:18:45 +0000\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-13 09:18:45 +0000\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-02-13 09:18:46 +0000\tmaster-replica-0\t\tFinished evaluation at 2019-02-13-09:18:46\n",
      "INFO\t2019-02-13 09:18:46 +0000\tmaster-replica-0\t\tSaving dict for global step 5000: accuracy = 0.9674, average_loss = 0.14119945, global_step = 5000, loss = 17.873348\n",
      "INFO\t2019-02-13 09:18:48 +0000\tmaster-replica-0\t\tSaving 'checkpoint_path' summary for global step 5000: gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tExport includes no default signature!\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000\n",
      "WARNING\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tAssets added to graph.\n",
      "INFO\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2019-02-13 09:19:05 +0000\tmaster-replica-0\t\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/temp-b'1550049529'/saved_model.pb\n",
      "INFO\t2019-02-13 09:19:11 +0000\tmaster-replica-0\t\tLoss for final step: 21.900007.\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\t['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\tTask completed successfully.\n",
      "INFO\t2019-02-13 09:23:16 +0000\tservice\t\tJob completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/mnist_190213_091458?project=ml-productive-pipeline-53122\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fmnist_190213_091458&project=ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs describe    mnist_190213_091458\n",
    "gcloud ml-engine jobs stream-logs mnist_190213_091458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't be concerned if the notebook appears stalled (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud. \n",
    "\n",
    "<b>Use the Cloud Console link to monitor the job and do NOT proceed until the job is done.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deploy model </h2>\n",
    "\n",
    "Find out the actual name of the subdirectory where the model is stored and use it to deploy the model.  Deploying model will take up to <b>5 minutes</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/\n",
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/\n",
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/mnist_ml_engine/trained/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run these commands one-by-one (the very first time, you'll create a model and then create a version)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.models.create) Resource in project [ml-productive-pipeline-53122] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "Creating version (this might take a few minutes)......\n",
      ".....................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"MNIST_MLENGINE\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/mnist_ml_engine/trained/export/exporter | tail -1)\n",
    "echo \"Run these commands one-by-one (the very first time, you'll create a model and then create a version)\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models   create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                                     PROBABILITIES\n",
      "[8]        [u'8']   [-0.11568695306777954, -0.31675225496292114, -0.047930844128131866, 0.12332145869731903, -0.10088106244802475, -0.021981418132781982, -0.2649504244327545, -0.10476464033126831, 1.2383620738983154, 0.23731258511543274]  [0.07440567761659622, 0.06085335463285446, 0.0796218290925026, 0.09449440240859985, 0.0755155086517334, 0.08171500265598297, 0.06408874690532684, 0.07522281259298325, 0.28817883133888245, 0.10590385645627975]\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=data/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatly, we do not have a True Positve. ToDO: Add more examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6ab83ddb70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ab83cd7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "  image = json.load(f)\n",
    "image = np.array(image['x'])\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions using the [Python-Client-Library, see Tutorial](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library). Since we have created and deployed a model already, we use the [`predict`](https://cloud.google.com/ml-engine/reference/rest/v1/projects) Method instead of `create` as in the documentation. \n",
    "\n",
    "[API-Reference](https://cloud.google.com/ml-engine/reference/rest/)\n",
    "\n",
    "If you need a service account authentification, please follow [this link]() and uncomment the celllines after this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %bash\n",
    "# export GOOGLE_APPLICATION_CREDENTIALS=$PWD/ML-productive-pipeline-53122-64d3c31786e7.json\n",
    "# echo $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/datalab/proj_DL_models_and_pipelines_with_GCP/notebook/../ML-productive-pipeline-53122-64d3c31786e7.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdoc discovery.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Signature: discovery.build(serviceName, version, http=None, discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', developerKey=None, model=None, requestBuilder=<class 'googleapiclient.http.HttpRequest'>, credentials=None, cache_discovery=True, cache=None)\n",
    "Docstring:\n",
    "Construct a Resource for interacting with an API.\n",
    "\n",
    "Construct a Resource object for interacting with an API. The serviceName and\n",
    "version are the names from the Discovery service.\n",
    "\n",
    "Args:\n",
    "serviceName: string, name of the service.\n",
    "version: string, the version of the service.\n",
    "http: httplib2.Http, An instance of httplib2.Http or something that acts\n",
    "like it that HTTP requests will be made through.\n",
    "discoveryServiceUrl: string, a URI Template that points to the location of\n",
    "the discovery service. It should have two parameters {api} and\n",
    "{apiVersion} that when filled in produce an absolute URI to the discovery\n",
    "document for that service.\n",
    "developerKey: string, key obtained from\n",
    "https://code.google.com/apis/console.\n",
    "model: googleapiclient.Model, converts to and from the wire format.\n",
    "requestBuilder: googleapiclient.http.HttpRequest, encapsulator for an HTTP\n",
    "request.\n",
    "credentials: oauth2client.Credentials or\n",
    "google.auth.credentials.Credentials, credentials to be used for\n",
    "authentication.\n",
    "cache_discovery: Boolean, whether or not to cache the discovery doc.\n",
    "cache: googleapiclient.discovery_cache.base.CacheBase, an optional\n",
    "cache object for the discovery documents.\n",
    "\n",
    "Returns:\n",
    "A Resource object with methods for interacting with the service.\n",
    "File: /usr/local/envs/py3env/lib/python3.5/site-packages/googleapiclient/discovery.py\n",
    "Type: function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = discovery.build(serviceName='ml', version='v1',\n",
    "                      http=None, \n",
    "                      discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', \n",
    "                      developerKey=None, \n",
    "                      model=None, \n",
    "                      #requestBuilder=<class 'googleapiclient.http.HttpRequest'>, \n",
    "                      credentials=None, \n",
    "                      cache_discovery=True, \n",
    "                      cache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MNIST_MLENGINE'\n",
    "VERSION = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'class_ids': [8], 'classes': ['8'], 'logits': [-0.11568695306777954, -0.31675225496292114, -0.047930844128131866, 0.12332145869731903, -0.10088106244802475, -0.021981418132781982, -0.2649504244327545, -0.10476464033126831, 1.2383620738983154, 0.23731258511543274], 'probabilities': [0.07440567761659622, 0.06085335463285446, 0.0796218290925026, 0.09449440240859985, 0.0755155086517334, 0.08171500265598297, 0.06408874690532684, 0.07522281259298325, 0.28817883133888245, 0.10590385645627975]}]}\n"
     ]
    }
   ],
   "source": [
    "project_id = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, VERSION)\n",
    "request_data = {\"instances\":\n",
    "  [\n",
    "   {\"x\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.23529411852359772, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705882430076599, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9450980424880981, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.6666666865348816, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.4470588266849518, 0.2823529541492462, 0.4470588266849518, 0.6392157077789307, 0.8901960849761963, 0.9960784316062927, 0.8823529481887817, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9803921580314636, 0.8980392217636108, 0.9960784316062927, 0.9960784316062927, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.054901961237192154, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137255012989044, 0.08235294371843338, 0.9254902005195618, 0.9960784316062927, 0.4156862795352936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921568632125854, 0.8196078538894653, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137254953384399, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784316062927, 0.9333333373069763, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137255012989044, 0.9764705896377563, 0.9960784316062927, 0.24313725531101227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.8039215803146362, 0.9725490212440491, 0.22745098173618317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176474094391, 0.9960784316062927, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137264251709, 0.9411764740943909, 0.2235294133424759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666666746139526, 0.9960784316062927, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0117647061124444, 0.7960784435272217, 0.9960784316062927, 0.8588235378265381, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784316062927, 0.9960784316062927, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156862765550613, 0.8784313797950745, 0.9960784316062927, 0.45098039507865906, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239215686917305, 0.9490196108818054, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.9960784316062927, 0.8588235378265381, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.8117647171020508, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
    "  ]\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "print(request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
