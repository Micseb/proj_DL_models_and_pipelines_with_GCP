{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Scaling up ML using Cloud ML Engine </h1>\n",
    "\n",
    "Adapted from [Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/cloudmle/cloudmle.ipynb) of Google Coursera Course [Serverless Machine Learning with Tensorflow on Google Cloud Platform](https://www.coursera.org/learn/serverless-machine-learning-gcp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: /home/enryh/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WORKINGDIR = os.getcwd()\n",
    "folders = WORKINGDIR.split('/')\n",
    "if folders.pop() == 'notebook':  # or a list: in ['notebook', 'src', etc.]\n",
    "  WORKINGDIR = '/'.join(folders)\n",
    "  print(\"New working directory: {}\".format(WORKINGDIR))\n",
    "else:\n",
    "  print(\"Current Working direcotory is kept: {}\".format(WORKINGDIR))\n",
    "os.chdir(WORKINGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Environment variables for project and bucket </h2>\n",
    "\n",
    "Note that:\n",
    "<ol>\n",
    "<li> Your project id is the *unique* string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads:  \n",
    "     \n",
    "     Project ID: ml-productive-pipeline-12345\n",
    "<li> Cloud training often involves saving and restoring model files. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available). A common pattern is to prefix the bucket name by the project id, so that it is unique. Also, for cost reasons, you might want to use a single region bucket. </li>\n",
    "</ol>\n",
    "\n",
    "<b>Add all detail in to [config.yaml](../config.yaml) file in main directory. Missing in public repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project-id': 'ml-productive-pipeline-53122', 'region': 'europe-west1', 'bucket': 'ml-productive-pipeline-53122', 'tf-version': 1.12, 'pkg-name': 'pkg_mnist_fnn'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "    \n",
    "print(config)\n",
    "\n",
    "# # #Create config manually and save as yaml:\n",
    "# config = {}\n",
    "# config['project-id'] = 'PROJECT'  # # REPLACE WITH YOUR PROJECT ID\n",
    "# config['region'] = 'europe-west1' # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "# config['bucket'] = 'Bucket-name'  # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "# \n",
    "# with open(\"../config_from_python.yaml\", 'wb', encoding= 'utf8') as f:\n",
    "#     yaml.dump(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO persistently add variables to the runtime of the datalab kernel, us the build in python function `os.environ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = config['pkg-name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can access the environement variable in the terminal running this datalab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow the Cloud ML Engine service account to read/write to the bucket containing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Service Account of VM: service-552147390438@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "Authorizing the Cloud ML Service account service-552147390438@cloud-ml.google.com.iam.gserviceaccount.com to access files in Bucket: ml-productive-pipeline-53122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   233    0   233    0     0    228      0 --:--:--  0:00:01 --:--:--   228\r",
      "100   233    0   233    0     0    228      0 --:--:--  0:00:01 --:--:--   228\n",
      "No changes to gs://ml-productive-pipeline-53122/\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist.npy\n",
      "No changes to gs://ml-productive-pipeline-53122/test.tfrecords\n",
      "No changes to gs://ml-productive-pipeline-53122/train.tfrecords\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-henry/content/daily-20190124094427\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-henry/content/hourly-20190124094427\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-henry/content/weekly-20190124094427\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-instance-test/content/daily-20190123104613\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-instance-test/content/hourly-20190123104613\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-instance-test/content/weekly-20190123104613\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-test/content/daily-20190123103151\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-test/content/hourly-20190123103151\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/datalab-test/content/weekly-20190123103151\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/daily-20190109134925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/hourly-20190109134925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/hourly-20190109145925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/hourly-20190109160925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/europe-west4-a/mydatalabvm/content/weekly-20190109134925\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190206144909\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190207093049\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190207133121\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190207183847\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190211085550\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190212092016\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190213080842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190214120536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190214173824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/daily-20190215123039\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190213113842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190213124842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190213135842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214120536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214131536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214184824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214173824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214142536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190215123039\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/hourly-20190214195824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190206144909\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190207093049\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190207133121\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190207183847\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190211085550\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190212092016\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190213080842\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190214120536\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190214173824\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/daily-20190121072344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalab-henry/content/weekly-20190215123039\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121094344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/daily-20190123114907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121083344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121072344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121105344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121120344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190121131345\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123114907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123140907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123151907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/hourly-20190123125907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/weekly-20190121072344\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/daily-20190206212641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/datalabml/content/weekly-20190123114907\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/hourly-20190206212641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/hourly-20190206223641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/hourly-20190206234641\n",
      "No changes to gs://ml-productive-pipeline-53122/datalab-backups/us-west1-c/mydatalabvm/content/weekly-20190206212641\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190212_122128/ed5251323934ae8bf21773bd24f0b5dee39a866770daf974045271eeb09410d2/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190212_165517/e5c6f75c4ee2c7409d218fa24f1af6a7db5d9c43c9197e2fde3065e81d4ddb9c/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190213_090323/28fe45aaa21d81e66ce0b2d2434a9c572adc587f9976848299d0228cff3005a1/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190213_091455/ec79430baf1229da2b1ec34bbc90436dfffb2589d7010059c139a327428f3007/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "No changes to gs://ml-productive-pipeline-53122/model_dir_tmp/1549054852/saved_model.pb\n",
      "No changes to gs://ml-productive-pipeline-53122/model_dir_tmp/1549054852/variables/variables.data-00000-of-00001\n",
      "No changes to gs://ml-productive-pipeline-53122/model_dir_tmp/1549054852/variables/variables.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/variables.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/checkpoint\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/variables.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.meta\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/variables.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/events.out.tfevents.1550049398.cmle-training-10500309129451260749\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/eval/events.out.tfevents.1550049526.cmle-training-5096003917298122300\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.index\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/saved_model.pb\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/eval/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/saved_model.pb\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/eval/events.out.tfevents.1550049479.cmle-training-10500309129451260749\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/variables/variables.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/variables.data-00000-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/graph.pbtxt\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/events.out.tfevents.1550049448.cmle-training-5096003917298122300\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/variables/variables.data-00001-of-00002\n",
      "Updated ACL on gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000.meta\n",
      "No changes to gs://ml-productive-pipeline-53122/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "# echo $AUTH_TOKEN\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print(response['serviceAccount'])\")\n",
    "echo \"Current Service Account of VM: $SVC_ACCOUNT\"\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in Bucket: $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Packaging up the code </h2>\n",
    "\n",
    "Take your code and put into a standard Python package structure, see  <a href=\"package_ml_engine/mnist_ml_engine.py\">model.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\r\n",
      "First try to start Cloud ML\r\n",
      "\r\n",
      "References:\r\n",
      "Basic reference for packaging the model so that ml-engine can use it:\r\n",
      "- https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/cloudmle/taxifare\r\n",
      "MNIST-Estimator-Example:\r\n",
      "- https://codeburst.io/use-tensorflow-dnnclassifier-estimator-to-classify-mnist-dataset-a7222bf9f940\r\n",
      "\r\n",
      "ipython -i -m src.models.test_model_estimator_api.mnist_ml_engine -- --data_path=data --output_dir=src\\models\\test_model_estimator_api\\trained --train_steps=100\r\n",
      "\"\"\"\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "import numpy as np\r\n",
      "\r\n",
      "from .utils import load_data\r\n",
      "###############################################################################\r\n",
      "#Factor into config:\r\n",
      "N_PIXEL = 784\r\n",
      "OUTDIR = 'trained'\r\n",
      "USE_TPU = False\r\n",
      "EPOCHS = 10\r\n",
      "\r\n",
      "if USE_TPU:\r\n",
      "    _device_update = 'tpu'\r\n",
      "else:\r\n",
      "    _device_update = 'cpu'\r\n",
      "\r\n",
      "IMAGE_SIZE = 28 * 28\r\n",
      "NUM_LABELS = 10\r\n",
      "BATCH_SIZE = 128\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "\r\n",
      "def parse_images(x):\r\n",
      "    return x.reshape(len(x), -1).astype('float32')\r\n",
      "\r\n",
      "\r\n",
      "def parse_labels(y):\r\n",
      "    return y.astype('int32')\r\n",
      "\r\n",
      "\r\n",
      "def numpy_input_fn(images: np.ndarray, labels: np.ndarray, mode=tf.estimator.ModeKeys.EVAL):\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        _epochs = EPOCHS\r\n",
      "        _shuffle = True\r\n",
      "        _num_threads = 2\r\n",
      "    else:\r\n",
      "        _epochs = 1\r\n",
      "        _shuffle = False\r\n",
      "        _num_threads = 1\r\n",
      "\r\n",
      "    return tf.estimator.inputs.numpy_input_fn(\r\n",
      "        {'x': images},\r\n",
      "        y=labels,\r\n",
      "        batch_size=BATCH_SIZE,\r\n",
      "        num_epochs=_epochs,\r\n",
      "        # Boolean, if True shuffles the queue. Avoid shuffle at prediction time.\r\n",
      "        shuffle=_shuffle,\r\n",
      "        queue_capacity=1000,\r\n",
      "        # Integer, number of threads used for reading and enqueueing. In order to have predicted and repeatable order of reading and enqueueing, such as in prediction and evaluation mode, num_threads should be 1.\r\n",
      "        num_threads=_num_threads\r\n",
      "    )\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_placeholders = {\r\n",
      "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\r\n",
      "    }\r\n",
      "    features = feature_placeholders\r\n",
      "    return tf.estimator.export.ServingInputReceiver(\r\n",
      "         features=features, \r\n",
      "         receiver_tensors=feature_placeholders,\r\n",
      "         receiver_tensors_alternatives=None\r\n",
      "         )\r\n",
      "\r\n",
      "\r\n",
      "def train_and_evaluate(args):\r\n",
      "    \"\"\"\r\n",
      "    Utility function for distributed training on ML-Engine\r\n",
      "    https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \r\n",
      "    \"\"\"\r\n",
      "    ##########################################\r\n",
      "    # Load Data in Memoery\r\n",
      "\r\n",
      "  # #ToDo: replace numpy-arrays\r\n",
      "    (x_train, y_train), (x_test, y_test) = load_data(\r\n",
      "        rel_path=args['data_path'])\r\n",
      "  \r\n",
      "    x_train = parse_images(x_train)\r\n",
      "    x_test = parse_images(x_test)\r\n",
      "\r\n",
      "    y_train = parse_labels(y_train)\r\n",
      "    y_test = parse_labels(y_test)\r\n",
      "\r\n",
      "    model = tf.estimator.DNNClassifier(\r\n",
      "        hidden_units=[256, 128, 64],\r\n",
      "        feature_columns=[tf.feature_column.numeric_column(\r\n",
      "            'x', shape=[N_PIXEL, ])],\r\n",
      "        model_dir=args['output_dir'],\r\n",
      "        n_classes=10,\r\n",
      "        optimizer=tf.train.AdamOptimizer,\r\n",
      "        # activation_fn=,\r\n",
      "        dropout=0.2,\r\n",
      "        batch_norm=False,\r\n",
      "        loss_reduction='weighted_sum',\r\n",
      "        warm_start_from=None\r\n",
      "    )\r\n",
      "   \r\n",
      "    train_spec = tf.estimator.TrainSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN),\r\n",
      "        max_steps=args['train_steps']\r\n",
      "    )\r\n",
      "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\r\n",
      "    eval_spec = tf.estimator.EvalSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\r\n",
      "        steps=None,\r\n",
      "        start_delay_secs=args['eval_delay_secs'],\r\n",
      "        throttle_secs=args['min_eval_frequency'],\r\n",
      "        exporters=exporter\r\n",
      "    )\r\n",
      "    tf.estimator.train_and_evaluate(\r\n",
      "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\r\n",
      "    print((model.get_variable_names()))\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    # model.train(input_fn=numpy_input_fn(\r\n",
      "    #     x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN))\r\n",
      "    # # #######################################\r\n",
      "\r\n",
      "# How to evaluate in the cloud over a whole evaluation set?\r\n",
      "    # # # Evaluate\r\n",
      "    # metrics_train = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(x_train, y_train, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # metrics_test = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(\r\n",
      "    #         x_test, y_test, mode=tf.estimator.ModeKeys.EVAL)\r\n",
      "    # )\r\n",
      "    # import pandas as pd\r\n",
      "    # metrics = pd.DataFrame(\r\n",
      "    #     {'Train': metrics_train, 'Test': metrics_test}).transpose()\r\n",
      "    # print(\"## Metrics DF\\n\", metrics)\r\n",
      "    # # #######################################\r\n",
      "    # # # get individual predictions:\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # for i, pred in enumerate(predictions_iterator):\r\n",
      "    #     if i % 999 == 0:\r\n",
      "    #         print('Image: {}'.format(i))\r\n",
      "    #         print(pred)\r\n",
      "    # #ToDo: 10000 Test-Images yield 20000 predictions?!\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # assert len(list(predictions_iterator)) == len(x_test)\r\n"
     ]
    }
   ],
   "source": [
    "!cat src/$PKG_NAME/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\r\n",
      "Parse arguments and call main function\r\n",
      "\"\"\"\r\n",
      "import os\r\n",
      "import argparse\r\n",
      "import shutil\r\n",
      "\r\n",
      "from .model import train_and_evaluate\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument(\r\n",
      "        '--data_path',\r\n",
      "        help='GCS or local path to training data',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--output_dir',\r\n",
      "        help='GCS location to write checkpoints and export models',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_batch_size',\r\n",
      "        help='Batch size for training steps',\r\n",
      "        type=int,\r\n",
      "        default='128'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_steps',\r\n",
      "        help='Steps to run the training job for',\r\n",
      "        type=int,\r\n",
      "        default='200'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--hidden_units',\r\n",
      "        help='List of hidden layer sizes to use for DNN feature columns',\r\n",
      "        nargs='+',\r\n",
      "        type=int,\r\n",
      "        default=[128, 64, 32]\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--job_dir',\r\n",
      "        help='this model ignores this field, but it is required by gcloud',\r\n",
      "        default='junk'\r\n",
      "    )\r\n",
      "    # Eval arguments\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_delay_secs',\r\n",
      "        help='How long to wait before running first evaluation',\r\n",
      "        default='10',\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--min_eval_frequency',\r\n",
      "        help='Seconds between evaluations',\r\n",
      "        default=300,\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "\r\n",
      "    args = parser.parse_args().__dict__\r\n",
      "\r\n",
      "    OUTDIR = args['output_dir']\r\n",
      "    # #######################################\r\n",
      "    # # Train\r\n",
      "    # ToDo execute outside from skript\r\n",
      "    shutil.rmtree(OUTDIR, ignore_errors=True)  # start fresh each time\r\n",
      "    train_and_evaluate(args)"
     ]
    }
   ],
   "source": [
    "!cat src/$PKG_NAME/task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Find absolute paths to your data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the absolute paths below.\n",
    "`/content` is mapped in Datalab to where the home icon takes you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory /home/enryh/proj_DL_models_and_pipelines_with_GCP\n",
      "Package Directory /home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn\n",
      "Savaed Model directory to be erased: /home/enryh/proj_DL_models_and_pipelines_with_GCP/src//trained\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Working Directory $PWD\"\n",
    "echo \"Package Directory $PWD/src/$PKG_NAME\"\n",
    "echo \"Savaed Model directory to be erased: $PWD/src/$PKG_Name/trained\"\n",
    "rm -rf $PWD/src/$PKG_NAME/trained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running the Python module from the command-line </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Package Path: src.pkg_mnist_fnn.task\n",
      "['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n",
      "Saved model: /home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn/trained/export/exporter/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-02-15 17:32:46.123401: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-15 17:32:46.127955: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf $PKG_NAME.tar.gz ${PWD}/package_ml_engine/trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/../\n",
    "\n",
    "echo \"Python Package Path: src.${PKG_NAME}.task\"\n",
    "\n",
    "python -m src.${PKG_NAME}.task \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/${PKG_NAME}/trained \\\n",
    "   --train_steps=1000 \\\n",
    "   --job_dir=tmp\n",
    "   \n",
    "echo \"Saved model: ${PWD}/src/${PKG_NAME}/trained/export/exporter/ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550243277\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls $PWD/src/$PKG_NAME/trained/export/exporter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an test-image in numpy format saved as json (copy from test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /home/enryh/proj_DL_models_and_pipelines_with_GCP/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(rel_path='data')\n",
    "N=4\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "eol = \"\\r\\n\"\n",
    "n_lines = len(y_test)\n",
    "with open(\"data/test.json\", \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        _dict = {\"x\": image} #, \"y\": int(label)}\n",
    "        f.write(json.dumps(_dict) + eol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "  images = f.readlines()\n",
    "plt.figure(figsize=(20,4))\n",
    "for i, image in enumerate(images):\n",
    "  if i < 4:\n",
    "    image = json.loads(image)\n",
    "    image = np.array(image['x'])\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags.py      local_predict.py\tmodels_util.py\t      uploads.py\r\n",
      "__init__.py   local_train.py\toperations_util.py    versions_util.py\r\n",
      "jobs_prep.py  local_utils.py\tpredict_utilities.py\r\n",
      "jobs_util.py  log_utils.py\tresources.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with `Python 3`, delete the `*.pyc` files, see [post](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)\n",
    "\n",
    "Default Datalab\n",
    "```\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "Default UNIX:\n",
    "```\n",
    "sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "\n",
    "> Process running Datalab or Jupyter Notebook needs admin rights. This is not always given for locally run notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# #remove any pyc files: Using Python3 you have to recompile\n",
    "# #Note: you need admin rights\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "# sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model:  1550248398\n",
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                    PROBABILITIES\n",
      "[6]        [u'6']   [6.261812210083008, -1.336929440498352, 4.513674259185791, 0.6058327555656433, 12.668279647827148, 7.083803653717041, 12.901329040527344, 1.4406895637512207, 2.4258909225463867, 7.3969550132751465]     [0.0007261795690283179, 3.638752730239503e-07, 0.00012642622459679842, 2.539121624067775e-06, 0.4398833215236664, 0.001652077422477305, 0.5553280115127563, 5.851361038367031e-06, 1.567200706631411e-05, 0.0022595934569835663]\n",
      "[1]        [u'1']   [-5.945840835571289, 40.77927780151367, 11.099405288696289, -1.9702718257904053, 12.539984703063965, 13.683131217956543, 1.515440821647644, 20.698762893676758, 24.271228790283203, -1.7380123138427734]  [5.099620982971267e-21, 0.9999998807907104, 1.2888283918831983e-13, 2.7171045230443443e-19, 5.442910662109557e-13, 1.7072354814573476e-12, 8.870185271928687e-18, 1.9017050156833193e-09, 6.770883942408545e-08, 3.427490593526123e-19]\n",
      "[8]        [u'8']   [0.38332992792129517, -0.905997633934021, 0.9535257816314697, 3.391974925994873, 0.7862745523452759, 3.051562547683716, 0.5670366287231445, -4.718357563018799, 11.747766494750977, 1.290295124053955]    [1.1595033356570639e-05, 3.193920747435186e-06, 2.0507117369561456e-05, 0.0002349145506741479, 1.7348766050417908e-05, 0.00016713616787455976, 1.393331967847189e-05, 7.057279560740426e-08, 0.9995025396347046, 2.8718488465528935e-05]\n",
      "[7]        [u'7']   [1.1083576679229736, 9.440372467041016, 5.38111686706543, 7.239932537078857, 4.282691955566406, 0.09656532108783722, -5.621509075164795, 12.412473678588867, 5.970654487609863, 6.3118462562561035]       [1.1603866369114257e-05, 0.04821152612566948, 0.00083222083048895, 0.005339639727026224, 0.0002774589229375124, 4.218780759401852e-06, 1.3863044934225854e-08, 0.9417118430137634, 0.0015006227185949683, 0.002110810251906514]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Running [gcloud.ml-engine.local.predict] with arguments: [--json-instances: \"./data/test.json\", --model-dir: \"/home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn/trained/export/exporter/1550248398\", --verbosity: \"debug\"]\n",
      "WARNING: 2019-02-15 17:33:22.652942: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-15 17:33:22.657580: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\n",
      "INFO: Display format: \"default \n",
      "          table(\n",
      "              predictions:format=\"table(\n",
      "                  class_ids, classes, logits, probabilities\n",
      "              )\"\n",
      "          )\"\n",
      "DEBUG: SDK update checks are disabled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $PWD/src/$PKG_NAME/trained/export/exporter/)\n",
    "echo \"Selected Model:  $model_dir\"\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/src/$PKG_NAME/trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=./data/test.json \\\n",
    "    --verbosity debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 8 7]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running locally using gcloud </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-02-15 18:30:07.129903: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-15 18:30:07.134765: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# rm -rf taxifare.tar.gz taxi_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=${PKG_NAME}.task \\\n",
    "   --package-path=${PWD}/src/${PKG_NAME} \\\n",
    "   -- \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/${PKG_NAME}/trained \\\n",
    "   --train_steps=500 \\\n",
    "   --job_dir=./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.datalab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-5e7a288ad978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PKG_NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PWD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.datalab'"
     ]
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(('{}/'+os.environ['PKG_NAME']).format(os.environ['PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCMeta',\n",
       " 'TensorBoard',\n",
       " 'TensorBoardServer',\n",
       " 'TensorBoardServerException',\n",
       " 'WerkzeugServer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'absl_flags',\n",
       " 'absolute_import',\n",
       " 'abstractmethod',\n",
       " 'application',\n",
       " 'argparse',\n",
       " 'argparse_flags',\n",
       " 'base_plugin',\n",
       " 'defaultdict',\n",
       " 'division',\n",
       " 'efi',\n",
       " 'errno',\n",
       " 'logger',\n",
       " 'logging',\n",
       " 'os',\n",
       " 'print_function',\n",
       " 'serving',\n",
       " 'setup_environment',\n",
       " 'socket',\n",
       " 'sys',\n",
       " 'threading',\n",
       " 'util',\n",
       " 'version']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tensorboard.program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'wsgi_app' and 'flags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-dc0f571a2e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBoardServer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PKG_NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PWD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'wsgi_app' and 'flags'"
     ]
    }
   ],
   "source": [
    "from tensorboard.program import TensorBoard\n",
    "TensorBoard().start(('{}/'+os.environ['PKG_NAME']).format(os.environ['PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above step (to stop TensorBoard) appears stalled, just move on to the next step. You don't need to wait for it to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Submit training job using gcloud </h2>\n",
    "\n",
    "First copy the training data to the cloud.  Then, launch a training job.\n",
    "\n",
    "After you submit the job, go to the cloud console (http://console.cloud.google.com) and select <b>Machine Learning | Jobs</b> to monitor progress.  \n",
    "\n",
    "<b>Note:</b> Don't be concerned if the notebook stalls (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud.  Use the Cloud Console link (above) to monitor the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/$PKG_NAME/*\n",
    "gsutil -m cp ${PWD}/data/mnist.npy gs://${BUCKET}/$PKG_NAME/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs using 10000 steps: 21.3\n",
      "For ten epochs specify 4688 steps\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "batch_size = 128\n",
    "n_train = 60000\n",
    "print(\"Number of epochs using {} steps: {:.1f}\".format(steps, steps * batch_size / n_train))\n",
    "steps = int(60000 / 128 * 10) + 1\n",
    "print(\"For ten epochs specify {} steps\".format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained europe-west1 mnist_190213_091458\n",
      "jobId: mnist_190213_091458\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [mnist_190213_091458] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_190213_091458\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190213_091458\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/$PKG_NAME/trained\n",
    "JOBNAME=mnist_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=$PKG_NAME.task \\\n",
    "   --package-path=${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --data_path=\"gs://${BUCKET}/$PKG_NAME/\" \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000 \\\n",
    "   --job_dir=$OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-02-13T09:15:01Z'\n",
      "etag: vILgAPivuaI=\n",
      "jobId: mnist_190213_091458\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path=gs://ml-productive-pipeline-53122/mnist_ml_engine/\n",
      "  - --output_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained\n",
      "  - --train_steps=5000\n",
      "  - --job_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs\n",
      "  packageUris:\n",
      "  - gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "  pythonModule: package_ml_engine.mnist_ml_engine\n",
      "  pythonVersion: '3.5'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.12'\n",
      "trainingOutput: {}\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tJob mnist_190213_091458 is queued.\n",
      "INFO\t2019-02-13 09:15:01 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-02-13 09:15:06 +0000\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-02-13 09:16:49 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"https://2222-dot-5440812-dot-devshell.appspot.com\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\"],  \"python_module\": \"package_ml_engine.mnist_ml_engine\",  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/mnist_ml_engine/\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_ml_engine/trained\", \"--train_steps\\u003d5000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs\"],  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "INFO\t2019-02-13 09:17:08 +0000\tmaster-replica-0\t\tRunning module package_ml_engine.mnist_ml_engine.\n",
      "INFO\t2019-02-13 09:17:08 +0000\tmaster-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:08 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:11 +0000\tmaster-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:11 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:12 +0000\tmaster-replica-0\t\tProcessing ./package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:13 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:13 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): started\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/df/18/f2/2e166baf1f651d60056cb019a95433f05a81ed75186978c5d5\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tSuccessfully built package-ml-engine\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tInstalling collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tSuccessfully installed package-ml-engine-0.0.0\n",
      "ERROR\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-13 09:17:14 +0000\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tProcessing ./package_ml_engine-0.0.0.tar.gz\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:15 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): started\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\t  Building wheel for package-ml-engine (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/df/18/f2/2e166baf1f651d60056cb019a95433f05a81ed75186978c5d5\n",
      "INFO\t2019-02-13 09:17:16 +0000\tmaster-replica-0\t\tSuccessfully built package-ml-engine\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tInstalling collected packages: package-ml-engine\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\t  Found existing installation: package-ml-engine 0.0.0\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\t    Uninstalling package-ml-engine-0.0.0:\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\t      Successfully uninstalled package-ml-engine-0.0.0\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tSuccessfully installed package-ml-engine-0.0.0\n",
      "ERROR\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-13 09:17:18 +0000\tmaster-replica-0\t\tRunning command: python3 -m package_ml_engine.mnist_ml_engine --data_path=gs://ml-productive-pipeline-53122/mnist_ml_engine/ --output_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained --train_steps=5000 --job_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs\n",
      "INFO\t2019-02-13 09:17:20 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t    8192/11490434 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t 4202496/11490434 [=========>....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t11493376/11490434 [==============================] - 0s 0us/step\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tTF_CONFIG environment variable: {'environment': 'cloud', 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'master'}, 'cluster': {'master': ['https://2222-dot-5440812-dot-devshell.appspot.com']}, 'job': {'run_on_raw_vm': True, 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190213_091458/5bdda660e394bb7b04a29442d8a27a7ffe9afca2c9b3d9c159012832a00818d9/package_ml_engine-0.0.0.tar.gz'], 'python_module': 'package_ml_engine.mnist_ml_engine', 'runtime_version': '1.12', 'python_version': '3.5', 'region': 'europe-west1', 'args': ['--data_path=gs://ml-productive-pipeline-53122/mnist_ml_engine/', '--output_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained', '--train_steps=5000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/jobs']}}\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tUsing default config.\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tUsing config: {'_experimental_distribute': None, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_evaluation_master': '', '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f11b6132c50>, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tgraph_options {\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t  }\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t}\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\t, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_ml_engine/trained', '_is_chief': True, '_eval_distribute': None, '_save_checkpoints_steps': None, '_master': '', '_service': None, '_protocol': None, '_device_fn': None, '_task_type': 'master', '_train_distribute': None}\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-02-13 09:17:21 +0000\tmaster-replica-0\t\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-13 09:17:27 +0000\tmaster-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-02-13 09:17:30 +0000\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-13 09:17:30 +0000\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-0\n",
      "INFO\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tDone running local_init_op.\n",
      "WARNING\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:17:32 +0000\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-13 09:17:34 +0000\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt.\n",
      "INFO\t2019-02-13 09:17:48 +0000\tmaster-replica-0\t\tloss = 13075.43, step = 1\n",
      "INFO\t2019-02-13 09:17:49 +0000\tmaster-replica-0\t\tglobal_step/sec: 105.938\n",
      "INFO\t2019-02-13 09:17:49 +0000\tmaster-replica-0\t\tloss = 318.757, step = 101 (0.945 sec)\n",
      "INFO\t2019-02-13 09:17:50 +0000\tmaster-replica-0\t\tglobal_step/sec: 115.009\n",
      "INFO\t2019-02-13 09:17:50 +0000\tmaster-replica-0\t\tloss = 208.0139, step = 201 (0.869 sec)\n",
      "INFO\t2019-02-13 09:17:51 +0000\tmaster-replica-0\t\tglobal_step/sec: 103.904\n",
      "INFO\t2019-02-13 09:17:51 +0000\tmaster-replica-0\t\tloss = 190.60722, step = 301 (0.963 sec)\n",
      "INFO\t2019-02-13 09:17:52 +0000\tmaster-replica-0\t\tglobal_step/sec: 134.363\n",
      "INFO\t2019-02-13 09:17:52 +0000\tmaster-replica-0\t\tloss = 76.427704, step = 401 (0.744 sec)\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.016\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tloss = 102.79257, step = 501 (0.735 sec)\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.007\n",
      "INFO\t2019-02-13 09:17:53 +0000\tmaster-replica-0\t\tloss = 72.16882, step = 601 (0.862 sec)\n",
      "INFO\t2019-02-13 09:17:54 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.482\n",
      "INFO\t2019-02-13 09:17:54 +0000\tmaster-replica-0\t\tloss = 103.51003, step = 701 (0.859 sec)\n",
      "INFO\t2019-02-13 09:17:55 +0000\tmaster-replica-0\t\tglobal_step/sec: 112.921\n",
      "INFO\t2019-02-13 09:17:55 +0000\tmaster-replica-0\t\tloss = 74.13242, step = 801 (0.885 sec)\n",
      "INFO\t2019-02-13 09:17:56 +0000\tmaster-replica-0\t\tglobal_step/sec: 135.018\n",
      "INFO\t2019-02-13 09:17:56 +0000\tmaster-replica-0\t\tloss = 49.98626, step = 901 (0.741 sec)\n",
      "INFO\t2019-02-13 09:17:57 +0000\tmaster-replica-0\t\tglobal_step/sec: 137.529\n",
      "INFO\t2019-02-13 09:17:57 +0000\tmaster-replica-0\t\tloss = 65.611725, step = 1001 (0.727 sec)\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tglobal_step/sec: 113.163\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tloss = 67.49064, step = 1101 (0.884 sec)\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tglobal_step/sec: 120.725\n",
      "INFO\t2019-02-13 09:17:58 +0000\tmaster-replica-0\t\tloss = 100.73499, step = 1201 (0.828 sec)\n",
      "INFO\t2019-02-13 09:17:59 +0000\tmaster-replica-0\t\tglobal_step/sec: 112.274\n",
      "INFO\t2019-02-13 09:17:59 +0000\tmaster-replica-0\t\tloss = 53.569622, step = 1301 (0.891 sec)\n",
      "INFO\t2019-02-13 09:18:00 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.335\n",
      "INFO\t2019-02-13 09:18:00 +0000\tmaster-replica-0\t\tloss = 67.22011, step = 1401 (0.733 sec)\n",
      "INFO\t2019-02-13 09:18:01 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.526\n",
      "INFO\t2019-02-13 09:18:01 +0000\tmaster-replica-0\t\tloss = 64.85119, step = 1501 (0.798 sec)\n",
      "INFO\t2019-02-13 09:18:02 +0000\tmaster-replica-0\t\tglobal_step/sec: 109.054\n",
      "INFO\t2019-02-13 09:18:02 +0000\tmaster-replica-0\t\tloss = 48.82122, step = 1601 (0.916 sec)\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tglobal_step/sec: 120.836\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tloss = 41.147453, step = 1701 (0.828 sec)\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.791\n",
      "INFO\t2019-02-13 09:18:03 +0000\tmaster-replica-0\t\tloss = 76.92012, step = 1801 (0.856 sec)\n",
      "INFO\t2019-02-13 09:18:04 +0000\tmaster-replica-0\t\tglobal_step/sec: 134.562\n",
      "INFO\t2019-02-13 09:18:04 +0000\tmaster-replica-0\t\tloss = 46.08581, step = 1901 (0.743 sec)\n",
      "INFO\t2019-02-13 09:18:05 +0000\tmaster-replica-0\t\tglobal_step/sec: 132.02\n",
      "INFO\t2019-02-13 09:18:05 +0000\tmaster-replica-0\t\tloss = 33.523735, step = 2001 (0.758 sec)\n",
      "INFO\t2019-02-13 09:18:06 +0000\tmaster-replica-0\t\tglobal_step/sec: 116.853\n",
      "INFO\t2019-02-13 09:18:06 +0000\tmaster-replica-0\t\tloss = 51.156525, step = 2101 (0.856 sec)\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tglobal_step/sec: 123.218\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tloss = 30.585655, step = 2201 (0.811 sec)\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tglobal_step/sec: 110.503\n",
      "INFO\t2019-02-13 09:18:07 +0000\tmaster-replica-0\t\tloss = 68.79298, step = 2301 (0.906 sec)\n",
      "INFO\t2019-02-13 09:18:08 +0000\tmaster-replica-0\t\tglobal_step/sec: 135.496\n",
      "INFO\t2019-02-13 09:18:08 +0000\tmaster-replica-0\t\tloss = 44.77977, step = 2401 (0.737 sec)\n",
      "INFO\t2019-02-13 09:18:09 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.105\n",
      "INFO\t2019-02-13 09:18:09 +0000\tmaster-replica-0\t\tloss = 51.819206, step = 2501 (0.735 sec)\n",
      "INFO\t2019-02-13 09:18:10 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.116\n",
      "INFO\t2019-02-13 09:18:10 +0000\tmaster-replica-0\t\tloss = 17.188972, step = 2601 (0.800 sec)\n",
      "INFO\t2019-02-13 09:18:11 +0000\tmaster-replica-0\t\tglobal_step/sec: 117.026\n",
      "INFO\t2019-02-13 09:18:11 +0000\tmaster-replica-0\t\tloss = 21.325272, step = 2701 (0.854 sec)\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tglobal_step/sec: 108.349\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tloss = 42.392746, step = 2801 (0.923 sec)\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tglobal_step/sec: 140.052\n",
      "INFO\t2019-02-13 09:18:12 +0000\tmaster-replica-0\t\tloss = 10.836456, step = 2901 (0.714 sec)\n",
      "INFO\t2019-02-13 09:18:13 +0000\tmaster-replica-0\t\tglobal_step/sec: 137.359\n",
      "INFO\t2019-02-13 09:18:13 +0000\tmaster-replica-0\t\tloss = 42.19614, step = 3001 (0.728 sec)\n",
      "INFO\t2019-02-13 09:18:14 +0000\tmaster-replica-0\t\tglobal_step/sec: 119.614\n",
      "INFO\t2019-02-13 09:18:14 +0000\tmaster-replica-0\t\tloss = 32.07009, step = 3101 (0.836 sec)\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.334\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tloss = 37.049297, step = 3201 (0.798 sec)\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tglobal_step/sec: 117.607\n",
      "INFO\t2019-02-13 09:18:15 +0000\tmaster-replica-0\t\tloss = 32.161743, step = 3301 (0.850 sec)\n",
      "INFO\t2019-02-13 09:18:16 +0000\tmaster-replica-0\t\tglobal_step/sec: 134.415\n",
      "INFO\t2019-02-13 09:18:16 +0000\tmaster-replica-0\t\tloss = 37.10141, step = 3401 (0.744 sec)\n",
      "INFO\t2019-02-13 09:18:17 +0000\tmaster-replica-0\t\tglobal_step/sec: 137.747\n",
      "INFO\t2019-02-13 09:18:17 +0000\tmaster-replica-0\t\tloss = 34.537544, step = 3501 (0.726 sec)\n",
      "INFO\t2019-02-13 09:18:18 +0000\tmaster-replica-0\t\tglobal_step/sec: 119.734\n",
      "INFO\t2019-02-13 09:18:18 +0000\tmaster-replica-0\t\tloss = 20.027512, step = 3601 (0.835 sec)\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tglobal_step/sec: 124.916\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tloss = 30.818651, step = 3701 (0.800 sec)\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tglobal_step/sec: 117.477\n",
      "INFO\t2019-02-13 09:18:19 +0000\tmaster-replica-0\t\tloss = 28.916504, step = 3801 (0.851 sec)\n",
      "INFO\t2019-02-13 09:18:20 +0000\tmaster-replica-0\t\tglobal_step/sec: 138.645\n",
      "INFO\t2019-02-13 09:18:20 +0000\tmaster-replica-0\t\tloss = 43.644524, step = 3901 (0.721 sec)\n",
      "INFO\t2019-02-13 09:18:21 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.812\n",
      "INFO\t2019-02-13 09:18:21 +0000\tmaster-replica-0\t\tloss = 13.6148205, step = 4001 (0.731 sec)\n",
      "INFO\t2019-02-13 09:18:22 +0000\tmaster-replica-0\t\tglobal_step/sec: 122.17\n",
      "INFO\t2019-02-13 09:18:22 +0000\tmaster-replica-0\t\tloss = 33.355637, step = 4101 (0.818 sec)\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tglobal_step/sec: 120.675\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tloss = 29.438255, step = 4201 (0.829 sec)\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tglobal_step/sec: 112.994\n",
      "INFO\t2019-02-13 09:18:23 +0000\tmaster-replica-0\t\tloss = 43.37506, step = 4301 (0.885 sec)\n",
      "INFO\t2019-02-13 09:18:24 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.65\n",
      "INFO\t2019-02-13 09:18:24 +0000\tmaster-replica-0\t\tloss = 18.002005, step = 4401 (0.732 sec)\n",
      "INFO\t2019-02-13 09:18:25 +0000\tmaster-replica-0\t\tglobal_step/sec: 146.716\n",
      "INFO\t2019-02-13 09:18:25 +0000\tmaster-replica-0\t\tloss = 8.663489, step = 4501 (0.681 sec)\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tglobal_step/sec: 136.573\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tloss = 31.115616, step = 4601 (0.733 sec)\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tglobal_step/sec: 130.71\n",
      "INFO\t2019-02-13 09:18:26 +0000\tmaster-replica-0\t\tloss = 17.96559, step = 4701 (0.765 sec)\n",
      "INFO\t2019-02-13 09:18:27 +0000\tmaster-replica-0\t\tglobal_step/sec: 125.344\n",
      "INFO\t2019-02-13 09:18:27 +0000\tmaster-replica-0\t\tloss = 47.409725, step = 4801 (0.798 sec)\n",
      "INFO\t2019-02-13 09:18:28 +0000\tmaster-replica-0\t\tglobal_step/sec: 147.263\n",
      "INFO\t2019-02-13 09:18:28 +0000\tmaster-replica-0\t\tloss = 25.811298, step = 4901 (0.679 sec)\n",
      "INFO\t2019-02-13 09:18:28 +0000\tmaster-replica-0\t\tSaving checkpoints for 5000 into gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt.\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tStarting evaluation at 2019-02-13-09:18:43\n",
      "INFO\t2019-02-13 09:18:43 +0000\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-13 09:18:44 +0000\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000\n",
      "INFO\t2019-02-13 09:18:45 +0000\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-13 09:18:45 +0000\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-02-13 09:18:46 +0000\tmaster-replica-0\t\tFinished evaluation at 2019-02-13-09:18:46\n",
      "INFO\t2019-02-13 09:18:46 +0000\tmaster-replica-0\t\tSaving dict for global step 5000: accuracy = 0.9674, average_loss = 0.14119945, global_step = 5000, loss = 17.873348\n",
      "INFO\t2019-02-13 09:18:48 +0000\tmaster-replica-0\t\tSaving 'checkpoint_path' summary for global step 5000: gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tExport includes no default signature!\n",
      "INFO\t2019-02-13 09:18:51 +0000\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/model.ckpt-5000\n",
      "WARNING\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tAssets added to graph.\n",
      "INFO\t2019-02-13 09:18:52 +0000\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2019-02-13 09:19:05 +0000\tmaster-replica-0\t\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/temp-b'1550049529'/saved_model.pb\n",
      "INFO\t2019-02-13 09:19:11 +0000\tmaster-replica-0\t\tLoss for final step: 21.900007.\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\t['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-02-13 09:19:12 +0000\tmaster-replica-0\t\tTask completed successfully.\n",
      "INFO\t2019-02-13 09:23:16 +0000\tservice\t\tJob completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/mnist_190213_091458?project=ml-productive-pipeline-53122\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fmnist_190213_091458&project=ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs describe    mnist_190213_091458\n",
    "gcloud ml-engine jobs stream-logs mnist_190213_091458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't be concerned if the notebook appears stalled (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud. \n",
    "\n",
    "<b>Use the Cloud Console link to monitor the job and do NOT proceed until the job is done.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deploy model </h2>\n",
    "\n",
    "Find out the actual name of the subdirectory where the model is stored and use it to deploy the model.  Deploying model will take up to <b>5 minutes</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/\n",
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049482/\n",
      "gs://ml-productive-pipeline-53122/mnist_ml_engine/trained/export/exporter/1550049529/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/$PKG_NAME/trained/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run these commands one-by-one (the very first time, you'll create a model and then create a version)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.models.create) Resource in project [ml-productive-pipeline-53122] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "Creating version (this might take a few minutes)......\n",
      ".....................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"MNIST_MLENGINE\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/$PKG_NAME/trained/export/exporter | tail -1)\n",
    "echo \"Run these commands one-by-one (the very first time, you'll create a model and then create a version)\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models   create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                                    PROBABILITIES\n",
      "[8]        [u'8']   [-0.11568696796894073, -0.31675225496292114, -0.047930844128131866, 0.12332145869731903, -0.10088108479976654, -0.021981418132781982, -0.2649504244327545, -0.1047646552324295, 1.2383620738983154, 0.23731258511543274]  [0.07440567016601562, 0.06085335463285446, 0.0796218290925026, 0.09449440240859985, 0.0755155086517334, 0.08171500265598297, 0.06408874690532684, 0.07522281259298325, 0.28817883133888245, 0.10590385645627975]\n",
      "[8]        [u'8']   [-0.02354954555630684, -0.2320529669523239, 0.17249378561973572, 0.24533908069133759, -0.16902874410152435, 0.01791192591190338, -0.08056589961051941, -0.10166634619235992, 1.4544720649719238, 0.2056676745414734]      [0.07270009070634842, 0.059017810970544815, 0.08844545483589172, 0.09512875229120255, 0.06285706907510757, 0.07577770203351974, 0.06867095082998276, 0.06723714619874954, 0.31873634457588196, 0.091428741812706]\n",
      "[8]        [u'8']   [-0.16256700456142426, -0.1803399622440338, -0.04731864109635353, 0.09617628157138824, -0.14122284948825836, -0.006139315664768219, -0.26647713780403137, -0.17138567566871643, 1.3138511180877686, 0.1989886462688446]   [0.06994932889938354, 0.0687171071767807, 0.07849378138780594, 0.09060545265674591, 0.07145838439464569, 0.08179358392953873, 0.06304576992988586, 0.06933517754077911, 0.30618491768836975, 0.10041652619838715]\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=data/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "  images = f.readlines()\n",
    "plt.figure(figsize=(20,4))\n",
    "for i, image in enumerate(images):\n",
    "  if i < 4:\n",
    "    image = json.loads(image)\n",
    "    image = np.array(image['x'])\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatly, we do not have a True Positve. ToDO: Add more examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions using the [Python-Client-Library, see Tutorial](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library). Since we have created and deployed a model already, we use the [`predict`](https://cloud.google.com/ml-engine/reference/rest/v1/projects) Method instead of `create` as in the documentation. \n",
    "\n",
    "[API-Reference](https://cloud.google.com/ml-engine/reference/rest/)\n",
    "\n",
    "If you need a service account authentification, please follow [this link]() and uncomment the celllines after this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %bash\n",
    "# export GOOGLE_APPLICATION_CREDENTIALS=$PWD/ML-productive-pipeline-53122-64d3c31786e7.json\n",
    "# echo $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/datalab/proj_DL_models_and_pipelines_with_GCP/notebook/../ML-productive-pipeline-53122-64d3c31786e7.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdoc discovery.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Signature: discovery.build(serviceName, version, http=None, discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', developerKey=None, model=None, requestBuilder=<class 'googleapiclient.http.HttpRequest'>, credentials=None, cache_discovery=True, cache=None)\n",
    "Docstring:\n",
    "Construct a Resource for interacting with an API.\n",
    "\n",
    "Construct a Resource object for interacting with an API. The serviceName and\n",
    "version are the names from the Discovery service.\n",
    "\n",
    "Args:\n",
    "serviceName: string, name of the service.\n",
    "version: string, the version of the service.\n",
    "http: httplib2.Http, An instance of httplib2.Http or something that acts\n",
    "like it that HTTP requests will be made through.\n",
    "discoveryServiceUrl: string, a URI Template that points to the location of\n",
    "the discovery service. It should have two parameters {api} and\n",
    "{apiVersion} that when filled in produce an absolute URI to the discovery\n",
    "document for that service.\n",
    "developerKey: string, key obtained from\n",
    "https://code.google.com/apis/console.\n",
    "model: googleapiclient.Model, converts to and from the wire format.\n",
    "requestBuilder: googleapiclient.http.HttpRequest, encapsulator for an HTTP\n",
    "request.\n",
    "credentials: oauth2client.Credentials or\n",
    "google.auth.credentials.Credentials, credentials to be used for\n",
    "authentication.\n",
    "cache_discovery: Boolean, whether or not to cache the discovery doc.\n",
    "cache: googleapiclient.discovery_cache.base.CacheBase, an optional\n",
    "cache object for the discovery documents.\n",
    "\n",
    "Returns:\n",
    "A Resource object with methods for interacting with the service.\n",
    "File: /usr/local/envs/py3env/lib/python3.5/site-packages/googleapiclient/discovery.py\n",
    "Type: function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = discovery.build(serviceName='ml', version='v1',\n",
    "                      http=None, \n",
    "                      discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', \n",
    "                      developerKey=None, \n",
    "                      model=None, \n",
    "                      #requestBuilder=<class 'googleapiclient.http.HttpRequest'>, \n",
    "                      credentials=None, \n",
    "                      cache_discovery=True, \n",
    "                      cache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MNIST_MLENGINE'\n",
    "VERSION = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /home/enryh/proj_DL_models_and_pipelines_with_GCP/data/mnist.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'x': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   75.0,\n",
       "   184.0,\n",
       "   217.0,\n",
       "   35.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   4.0,\n",
       "   60.0,\n",
       "   105.0,\n",
       "   240.0,\n",
       "   221.0,\n",
       "   37.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   4.0,\n",
       "   118.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   251.0,\n",
       "   112.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   131.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   152.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   45.0,\n",
       "   137.0,\n",
       "   248.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   142.0,\n",
       "   9.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   50.0,\n",
       "   223.0,\n",
       "   254.0,\n",
       "   253.0,\n",
       "   251.0,\n",
       "   152.0,\n",
       "   9.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   48.0,\n",
       "   226.0,\n",
       "   253.0,\n",
       "   254.0,\n",
       "   253.0,\n",
       "   158.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   48.0,\n",
       "   236.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   254.0,\n",
       "   55.0,\n",
       "   5.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   50.0,\n",
       "   226.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   226.0,\n",
       "   59.0,\n",
       "   11.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   45.0,\n",
       "   223.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   226.0,\n",
       "   43.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   164.0,\n",
       "   254.0,\n",
       "   254.0,\n",
       "   254.0,\n",
       "   121.0,\n",
       "   0.0,\n",
       "   106.0,\n",
       "   105.0,\n",
       "   202.0,\n",
       "   254.0,\n",
       "   254.0,\n",
       "   254.0,\n",
       "   254.0,\n",
       "   201.0,\n",
       "   87.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   4.0,\n",
       "   60.0,\n",
       "   206.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   245.0,\n",
       "   209.0,\n",
       "   254.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   235.0,\n",
       "   62.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   24.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   254.0,\n",
       "   241.0,\n",
       "   238.0,\n",
       "   238.0,\n",
       "   242.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   235.0,\n",
       "   62.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   29.0,\n",
       "   206.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   161.0,\n",
       "   133.0,\n",
       "   134.0,\n",
       "   23.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   146.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   208.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   32.0,\n",
       "   118.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   244.0,\n",
       "   178.0,\n",
       "   126.0,\n",
       "   7.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   49.0,\n",
       "   146.0,\n",
       "   250.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   164.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   31.0,\n",
       "   222.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   241.0,\n",
       "   71.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   18.0,\n",
       "   31.0,\n",
       "   66.0,\n",
       "   227.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   225.0,\n",
       "   52.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   135.0,\n",
       "   233.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   239.0,\n",
       "   134.0,\n",
       "   134.0,\n",
       "   134.0,\n",
       "   205.0,\n",
       "   254.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   237.0,\n",
       "   119.0,\n",
       "   7.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   255.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   255.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   210.0,\n",
       "   120.0,\n",
       "   12.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   209.0,\n",
       "   245.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   236.0,\n",
       "   208.0,\n",
       "   199.0,\n",
       "   31.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   63.0,\n",
       "   235.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   200.0,\n",
       "   104.0,\n",
       "   104.0,\n",
       "   62.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'x': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   11.0,\n",
       "   215.0,\n",
       "   72.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   37.0,\n",
       "   253.0,\n",
       "   175.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   128.0,\n",
       "   253.0,\n",
       "   194.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   4.0,\n",
       "   220.0,\n",
       "   253.0,\n",
       "   72.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   55.0,\n",
       "   253.0,\n",
       "   246.0,\n",
       "   46.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   204.0,\n",
       "   254.0,\n",
       "   209.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   16.0,\n",
       "   239.0,\n",
       "   253.0,\n",
       "   60.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   163.0,\n",
       "   253.0,\n",
       "   247.0,\n",
       "   46.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   40.0,\n",
       "   254.0,\n",
       "   253.0,\n",
       "   138.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   155.0,\n",
       "   254.0,\n",
       "   253.0,\n",
       "   36.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   19.0,\n",
       "   254.0,\n",
       "   255.0,\n",
       "   115.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   123.0,\n",
       "   253.0,\n",
       "   254.0,\n",
       "   18.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   32.0,\n",
       "   245.0,\n",
       "   253.0,\n",
       "   204.0,\n",
       "   9.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   82.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   52.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   40.0,\n",
       "   243.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   107.0,\n",
       "   254.0,\n",
       "   254.0,\n",
       "   136.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   68.0,\n",
       "   252.0,\n",
       "   253.0,\n",
       "   184.0,\n",
       "   5.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   196.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   99.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   254.0,\n",
       "   253.0,\n",
       "   218.0,\n",
       "   12.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   156.0,\n",
       "   253.0,\n",
       "   94.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'x': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   3.0,\n",
       "   105.0,\n",
       "   132.0,\n",
       "   132.0,\n",
       "   132.0,\n",
       "   190.0,\n",
       "   255.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   230.0,\n",
       "   132.0,\n",
       "   99.0,\n",
       "   3.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   129.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   253.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   105.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   181.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   235.0,\n",
       "   217.0,\n",
       "   216.0,\n",
       "   216.0,\n",
       "   216.0,\n",
       "   216.0,\n",
       "   216.0,\n",
       "   41.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   181.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   156.0,\n",
       "   44.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   35.0,\n",
       "   232.0,\n",
       "   252.0,\n",
       "   232.0,\n",
       "   192.0,\n",
       "   18.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   49.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   167.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   89.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   167.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   169.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   64.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   16.0,\n",
       "   205.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   48.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   37.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   203.0,\n",
       "   121.0,\n",
       "   121.0,\n",
       "   121.0,\n",
       "   122.0,\n",
       "   110.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   164.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   255.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   167.0,\n",
       "   32.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   44.0,\n",
       "   228.0,\n",
       "   246.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   253.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   71.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   74.0,\n",
       "   96.0,\n",
       "   96.0,\n",
       "   96.0,\n",
       "   96.0,\n",
       "   102.0,\n",
       "   216.0,\n",
       "   221.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   225.0,\n",
       "   30.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   12.0,\n",
       "   196.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   48.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   55.0,\n",
       "   229.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   48.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   91.0,\n",
       "   152.0,\n",
       "   11.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   7.0,\n",
       "   184.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   48.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   193.0,\n",
       "   252.0,\n",
       "   76.0,\n",
       "   0.0,\n",
       "   41.0,\n",
       "   91.0,\n",
       "   209.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   153.0,\n",
       "   9.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   193.0,\n",
       "   252.0,\n",
       "   239.0,\n",
       "   217.0,\n",
       "   234.0,\n",
       "   253.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   229.0,\n",
       "   37.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   193.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   253.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   156.0,\n",
       "   18.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   9.0,\n",
       "   149.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   252.0,\n",
       "   253.0,\n",
       "   241.0,\n",
       "   57.0,\n",
       "   4.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'x': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   5.0,\n",
       "   47.0,\n",
       "   138.0,\n",
       "   109.0,\n",
       "   148.0,\n",
       "   90.0,\n",
       "   255.0,\n",
       "   254.0,\n",
       "   176.0,\n",
       "   53.0,\n",
       "   33.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   188.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   236.0,\n",
       "   97.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   47.0,\n",
       "   245.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   233.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   56.0,\n",
       "   213.0,\n",
       "   195.0,\n",
       "   170.0,\n",
       "   103.0,\n",
       "   67.0,\n",
       "   67.0,\n",
       "   67.0,\n",
       "   67.0,\n",
       "   67.0,\n",
       "   209.0,\n",
       "   253.0,\n",
       "   233.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   11.0,\n",
       "   6.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   11.0,\n",
       "   92.0,\n",
       "   252.0,\n",
       "   129.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   52.0,\n",
       "   200.0,\n",
       "   253.0,\n",
       "   156.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   76.0,\n",
       "   198.0,\n",
       "   239.0,\n",
       "   253.0,\n",
       "   235.0,\n",
       "   10.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   60.0,\n",
       "   166.0,\n",
       "   252.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   181.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   7.0,\n",
       "   238.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   252.0,\n",
       "   25.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   110.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   223.0,\n",
       "   156.0,\n",
       "   86.0,\n",
       "   8.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   67.0,\n",
       "   175.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   117.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   5.0,\n",
       "   47.0,\n",
       "   5.0,\n",
       "   103.0,\n",
       "   140.0,\n",
       "   190.0,\n",
       "   253.0,\n",
       "   249.0,\n",
       "   54.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   46.0,\n",
       "   253.0,\n",
       "   246.0,\n",
       "   23.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   21.0,\n",
       "   253.0,\n",
       "   249.0,\n",
       "   50.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   10.0,\n",
       "   111.0,\n",
       "   188.0,\n",
       "   253.0,\n",
       "   250.0,\n",
       "   65.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   9.0,\n",
       "   17.0,\n",
       "   124.0,\n",
       "   203.0,\n",
       "   232.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   248.0,\n",
       "   96.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   5.0,\n",
       "   94.0,\n",
       "   171.0,\n",
       "   205.0,\n",
       "   237.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   239.0,\n",
       "   61.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   106.0,\n",
       "   115.0,\n",
       "   208.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   252.0,\n",
       "   243.0,\n",
       "   138.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   113.0,\n",
       "   161.0,\n",
       "   246.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   253.0,\n",
       "   197.0,\n",
       "   160.0,\n",
       "   82.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   39.0,\n",
       "   190.0,\n",
       "   192.0,\n",
       "   160.0,\n",
       "   253.0,\n",
       "   204.0,\n",
       "   149.0,\n",
       "   106.0,\n",
       "   46.0,\n",
       "   46.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]}]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(rel_path='data')\n",
    "N=4\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()\n",
    "\n",
    "eol = \"\\r\\n\"\n",
    "n_lines = len(y_test)\n",
    "instances = []\n",
    "with open(\"data/test.json\", \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        instances.append({\"x\": image}) #, \"y\": int(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'class_ids': [8], 'classes': ['8'], 'logits': [-0.11568695306777954, -0.31675225496292114, -0.047930844128131866, 0.12332145869731903, -0.10088106244802475, -0.021981418132781982, -0.2649504244327545, -0.10476464033126831, 1.2383620738983154, 0.23731258511543274], 'probabilities': [0.07440567761659622, 0.06085335463285446, 0.0796218290925026, 0.09449440240859985, 0.0755155086517334, 0.08171500265598297, 0.06408874690532684, 0.07522281259298325, 0.28817883133888245, 0.10590385645627975]}]}\n"
     ]
    }
   ],
   "source": [
    "project_id = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, VERSION)\n",
    "request_data = {\"instances\":\n",
    "  [\n",
    "   {\"x\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.23529411852359772, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705882430076599, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9450980424880981, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.6666666865348816, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.4470588266849518, 0.2823529541492462, 0.4470588266849518, 0.6392157077789307, 0.8901960849761963, 0.9960784316062927, 0.8823529481887817, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9803921580314636, 0.8980392217636108, 0.9960784316062927, 0.9960784316062927, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.054901961237192154, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137255012989044, 0.08235294371843338, 0.9254902005195618, 0.9960784316062927, 0.4156862795352936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921568632125854, 0.8196078538894653, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137254953384399, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784316062927, 0.9333333373069763, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137255012989044, 0.9764705896377563, 0.9960784316062927, 0.24313725531101227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.8039215803146362, 0.9725490212440491, 0.22745098173618317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176474094391, 0.9960784316062927, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137264251709, 0.9411764740943909, 0.2235294133424759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666666746139526, 0.9960784316062927, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0117647061124444, 0.7960784435272217, 0.9960784316062927, 0.8588235378265381, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784316062927, 0.9960784316062927, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156862765550613, 0.8784313797950745, 0.9960784316062927, 0.45098039507865906, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239215686917305, 0.9490196108818054, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.9960784316062927, 0.8588235378265381, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.8117647171020508, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
    "  ]\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "print(request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
