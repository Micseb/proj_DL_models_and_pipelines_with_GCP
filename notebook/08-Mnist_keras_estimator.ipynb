{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification example with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Install packages on Google  Cloud Datalab (locally use conda env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Select in the Python3 Kernel:\n",
    "In the menu bar the of 'Kernel', select   \n",
    "**python3**\n",
    "### Install needed packages\n",
    "copy the command below in a Google Cloud Datalab cell  \n",
    "**!pip install tensorflow==1.12**\n",
    "### Restart the Kernel \n",
    "this is to take into account the new installed packages. Click in the menu bar on:  \n",
    "**Reset Session**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include paths to our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/notebook\n",
      "/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "workingdir=os.getcwd()\n",
    "print(workingdir)\n",
    "d=[d for d in os.listdir(workingdir)]\n",
    "n=0\n",
    "while not set(['notebook']).issubset(set(d)):\n",
    "    workingdir=str(pathlib.Path(workingdir).parents[0])\n",
    "    print(workingdir)\n",
    "    d=[d for d in os.listdir(str(workingdir))]\n",
    "    n+=1\n",
    "    if n>5:\n",
    "        break\n",
    "sys.path.insert(0, workingdir)\n",
    "os.chdir(workingdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup librairies import and plots style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.color import gray2rgb, rgb2gray, label2rgb\n",
    "import _pickle as cPickle\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from random import sample, randint, shuffle\n",
    "import time\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import json \n",
    "import subprocess\n",
    "import requests\n",
    "import google.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.mnist_utils as mnist_utils\n",
    "import src.utils.ml_utils as ml_utils\n",
    "import src.utils.tensorflow_helper as tensorflow_helper\n",
    "import src.model_mnist_v1.trainer.model as mnist_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(mnist_utils)\n",
    "importlib.reload(mnist_v1)\n",
    "importlib.reload(ml_utils)\n",
    "importlib.reload(tensorflow_helper);# to reload the function and mask the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set plots style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seaborn-dark', 'seaborn-darkgrid', 'seaborn-ticks', 'fivethirtyeight', 'seaborn-whitegrid', 'classic', '_classic_test', 'fast', 'seaborn-talk', 'seaborn-dark-palette', 'seaborn-bright', 'seaborn-pastel', 'grayscale', 'seaborn-notebook', 'ggplot', 'seaborn-colorblind', 'seaborn-muted', 'seaborn', 'Solarize_Light2', 'seaborn-paper', 'bmh', 'tableau-colorblind10', 'seaborn-white', 'dark_background', 'seaborn-poster', 'seaborn-deep']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color code: https://matplotlib.org/gallery/color/named_colors.html#sphx-glr-gallery-color-named-colors-py\n",
    "plt.style.use('seaborn-ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization of some examples per classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train='data/mnist/numpy_train/'\n",
    "path_test='data/mnist/numpy_test/'\n",
    "x_train=cPickle.load(open(path_train+'x_train.pkl', 'rb'))\n",
    "y_train=cPickle.load(open(path_train+'y_train.pkl', 'rb'))\n",
    "x_test=cPickle.load(open(path_test+'x_test.pkl', 'rb'))\n",
    "y_test=cPickle.load(open(path_test+'y_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some example from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1080 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_utils.plot_mnist_images(x_train[0:25], y_train[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of classes\n",
    "NUM_CLASSES =10\n",
    "\n",
    "# dimension of the input data\n",
    "DIM_INPUT = 784\n",
    "\n",
    "# number of epoch to train our model\n",
    "EPOCHS = 100\n",
    "\n",
    "# size of our mini batch\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# shuffle buffer size\n",
    "SHUFFLE_BUFFER_SIZE = 10 * BATCH_SIZE\n",
    "\n",
    "# prefetch buffer size\n",
    "PREFETCH_BUFFER_SIZE = tf.contrib.data.AUTOTUNE\n",
    "\n",
    "# number of paralell calls\n",
    "NUM_PARALELL_CALL = 4\n",
    "\n",
    "# model version\n",
    "MODEL='v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow_helper.del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for jupyter notebook and avoir : \"UnrecognizedFlagError: Unknown command line flag 'f'\"\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel') \n",
    "\n",
    "# path to store the model and input for Tensorboard and SavedModel\n",
    "tf.app.flags.DEFINE_string('model_dir', 'results/Models/Mnist/tf_1_12/estimator/ckpt/', 'Dir to save a model and checkpoints')\n",
    "tf.app.flags.DEFINE_string('saved_dir', 'results/Models/Mnist/tf_1_12/estimator/pt/', 'Dir to save a model for TF serving')\n",
    "\n",
    "# path to store the model and input for Tensorboard\n",
    "#tf.app.flags.DEFINE_string('model_dir_keras', './results/Models/Mnist/tf_1_12/keras/'+MODEL+'/ckpt/', 'Dir to save a model and checkpoints with keras')\n",
    "#tf.app.flags.DEFINE_string('tensorboard_dir_keras', './results/Models/Mnist/tf_1_12/keras/'+MODEL+'/logs/', 'Dir to save logs for TensorBoard with keras')\n",
    "\n",
    "# parameters for the input dataset and train the model\n",
    "tf.app.flags.DEFINE_integer('epoch', EPOCHS, 'number of epoch')\n",
    "tf.app.flags.DEFINE_integer('step_per_epoch', len(x_train) // BATCH_SIZE, 'number of step per epoch')\n",
    "tf.app.flags.DEFINE_integer('batch_size', BATCH_SIZE, 'Batch size')\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size', SHUFFLE_BUFFER_SIZE , 'Shuffle buffer size')\n",
    "tf.app.flags.DEFINE_integer('prefetch_buffer_size', PREFETCH_BUFFER_SIZE, 'Prefetch buffer size')\n",
    "tf.app.flags.DEFINE_integer('num_parallel_calls', NUM_PARALELL_CALL, 'Number of paralell calls')\n",
    "\n",
    "# parameters for the model\n",
    "tf.app.flags.DEFINE_integer('num_classes', NUM_CLASSES, 'number of classes in our model')\n",
    "tf.app.flags.DEFINE_integer('dim_input', DIM_INPUT, 'dimension of the input data for our model')\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/tarrade/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/ipykernel_launcher.py:\n",
      "  --batch_size: Batch size\n",
      "    (default: '128')\n",
      "    (an integer)\n",
      "  --dim_input: dimension of the input data for our model\n",
      "    (default: '784')\n",
      "    (an integer)\n",
      "  --epoch: number of epoch\n",
      "    (default: '100')\n",
      "    (an integer)\n",
      "  --f: kernel\n",
      "    (default: '')\n",
      "  --model_dir: Dir to save a model and checkpoints\n",
      "    (default: 'results/Models/Mnist/tf_1_12/estimator/ckpt/')\n",
      "  --num_classes: number of classes in our model\n",
      "    (default: '10')\n",
      "    (an integer)\n",
      "  --num_parallel_calls: Number of paralell calls\n",
      "    (default: '4')\n",
      "    (an integer)\n",
      "  --prefetch_buffer_size: Prefetch buffer size\n",
      "    (default: '-1')\n",
      "    (an integer)\n",
      "  --saved_dir: Dir to save a model for TF serving\n",
      "    (default: 'results/Models/Mnist/tf_1_12/estimator/pt/')\n",
      "  --shuffle_buffer_size: Shuffle buffer size\n",
      "    (default: '1280')\n",
      "    (an integer)\n",
      "  --step_per_epoch: number of step per epoch\n",
      "    (default: '468')\n",
      "    (an integer)\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n"
     ]
    }
   ],
   "source": [
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eval', 'infer', 'train')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre defined flags\n",
    "tf.estimator.ModeKeys.EVAL, tf.estimator.ModeKeys.PREDICT, tf.estimator.ModeKeys.TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the number relater to the number of events (epoch, batch size, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_input(data, step='training'):\n",
    "    print('Summary for the {} dataset:'.format(step))\n",
    "    if step=='training':\n",
    "        print('  - number of epoch            :', FLAGS.epoch)\n",
    "        print('  - number of events per epoch :', len(data))\n",
    "        print('  - batch size                 :', FLAGS.batch_size)\n",
    "        print('  - number of step per epoch   :', FLAGS.step_per_epoch)\n",
    "        print('  - total number of steps      :', FLAGS.epoch * FLAGS.step_per_epoch)\n",
    "    else:\n",
    "        print('  - number of epoch            :', 1)\n",
    "        print('  - number of events per epoch :', len(data))\n",
    "        print('  - batch size                 :', None)\n",
    "        print('  - number of step per epoch   :', 1)\n",
    "        print('  - total number of steps      :', 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for the training dataset:\n",
      "  - number of epoch            : 100\n",
      "  - number of events per epoch : 60000\n",
      "  - batch size                 : 128\n",
      "  - number of step per epoch   : 468\n",
      "  - total number of steps      : 46800\n"
     ]
    }
   ],
   "source": [
    "print_summary_input(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for the testing dataset:\n",
      "  - number of epoch            : 1\n",
      "  - number of events per epoch : 10000\n",
      "  - batch size                 : None\n",
      "  - number of step per epoch   : 1\n",
      "  - total number of steps      : 1\n"
     ]
    }
   ],
   "source": [
    "print_summary_input(x_test, 'testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning modelling with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting existing models\n",
    "delete fist the folder for a clean start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model will be saved here:\n",
      " results/Models/Mnist/tf_1_12/estimator/ckpt/\n"
     ]
    }
   ],
   "source": [
    "print('trained model will be saved here:\\n', FLAGS.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the folder from previous try \n",
    "shutil.rmtree(FLAGS.model_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model will be saved here:\n",
      " results/Models/Mnist/tf_1_12/estimator/pt/\n"
     ]
    }
   ],
   "source": [
    "print('trained model will be saved here:\\n', FLAGS.saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the folder from previous try \n",
    "shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model_opt_tf = mnist_v1.keras_baseline_model(FLAGS, opt='tf')\n",
    "\n",
    "# store the origina weights\n",
    "initial_weights = model_opt_tf.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the nuber of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_opt_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check input and output layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_input']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt_tf.input_names # Use this name as the dictionary key in the TF input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_2']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt_tf.output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and inference using  tf.estimator and tf.data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **batch_size** determines the number of samples in each mini batch. Its maximum is the number of all samples, which makes gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but iterations are slower. Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around. batch_size allows to adjust between the two extremes: accurate gradient direction and fast iteration. Also, the maximum value for batch_size may be limited if your model + data set does not fit into the available (GPU) memory.\n",
    "- **steps_per_epoch** the number of batch iterations before a training epoch is considered finished. If you have a training set of fixed size you can ignore it but it may be useful if you have a huge data set or if you are generating random data augmentations on the fly, i.e. if your training set has a (generated) infinite size. If you have the time to go through your whole training data set I recommend to skip this parameter.\n",
    "- **validation_steps** similar to steps_per_epoch but on the validation data set instead on the training data. If you have the time to go through your whole validation data set I recommend to skip this parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.train.SessionRunHook):\n",
    "    def begin(self):\n",
    "        self.times = []\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        self.iter_time_start = time.time()\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        self.times.append(time.time() - self.iter_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = TimeHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tf.distribute.startegy work across multiple devices/machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    }
   ],
   "source": [
    "# the tf.distribute.Strategy API is an easy way to distribute your training across multiple devices/machines\n",
    "\n",
    "#strategy=None\n",
    "## work with Keras with tf.train optimiser not tf.keras\n",
    "strategy = tf.contrib.distribute.OneDeviceStrategy('device:CPU:0')\n",
    "#strategy = tf.contrib.distribute.OneDeviceStrategy('device:GPU:0')\n",
    "#NUM_GPUS = 2\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=NUM_GPUS)\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy()\n",
    "\n",
    "# config tf.estimator to use a give strategy\n",
    "training_config = tf.estimator.RunConfig(train_distribute=strategy,\n",
    "                                         model_dir=FLAGS.model_dir,\n",
    "                                         save_summary_steps=1,\n",
    "                                         save_checkpoints_steps=100,\n",
    "                                         keep_checkpoint_max=3,\n",
    "                                         log_step_count_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform a keras model to estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x1c46e7c470>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c46e7c908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model_opt_tf.set_weights(initial_weights)\n",
    "\n",
    "# transfor keras model to estimator model\n",
    "estimator_train_model = tf.keras.estimator.model_to_estimator(keras_model=model_opt_tf,\n",
    "                                                              config=training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x1c479ba320>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c4789fd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model_opt_tf.set_weights(initial_weights)\n",
    "\n",
    "# transfor keras model to estimator model\n",
    "estimator_train_model = tf.keras.estimator.model_to_estimator(keras_model=model_opt_tf,\n",
    "                                                              config=training_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dataset\n",
    "Use tf.data.dataset to feed the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure you have the tfrecords file locally if you want to train localy (or get them from Cloud Storage)\n",
    "path_test_tfrecords = 'data/mnist/tfrecords_image_test'\n",
    "path_train_tfrecords = 'data/mnist/tfrecords_image_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input dataset functions for training and testing will be pass during fit to load, convert, preprocess and reshuffle the images and labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# method and arguments\n",
    "\n",
    "# train\n",
    "train(\n",
    "    input_fn,\n",
    "    hooks=None,\n",
    "    steps=None,\n",
    "    max_steps=None,\n",
    "    saving_listeners=None\n",
    ")\n",
    "--> Trains a model given training data input_fn\n",
    "\n",
    "--> return: nothing\n",
    "\n",
    "# evalute\n",
    "evaluate(\n",
    "    input_fn,\n",
    "    steps=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    name=None\n",
    ")\n",
    "--> Evaluates the model given evaluation data input_fn\n",
    "\n",
    "--> return: A dict containing the evaluation metrics specified in model_fn keyed by name, as well as an entry global_step which contains the value of the global step for which this evaluation was performed. For canned estimators, the dict contains the loss (mean loss per mini-batch) and the average_loss (mean loss per sample). Canned classifiers also return the accuracy. Canned regressors also return the label/mean and the prediction/mean.\n",
    "\n",
    "# predict\n",
    "predict(\n",
    "    input_fn,\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    yield_single_examples=True\n",
    ")\n",
    "--> Yields predictions for given features.\n",
    "\n",
    "--> return: Evaluated values of predictions tensors\n",
    "\n",
    "# train and evaluate\n",
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "--> Train and evaluate the estimator\n",
    "\n",
    "--> return: A tuple of the result of the evaluate call to the Estimator and the export results using the specified ExportStrategy. Currently, the return value is undefined for distributed training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=[os.remove(x) for x in glob.glob(FLAGS.model_dir+'*') if 'keras' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.5371077, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 20 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 40 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 60 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 80 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.6277\n",
      "INFO:tensorflow:loss = 0.15460324, step = 100 (4.850 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 120 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 140 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 160 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 180 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 25.224\n",
      "INFO:tensorflow:loss = 0.22668627, step = 200 (3.965 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 220 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 240 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 260 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 280 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 300 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 25.383\n",
      "INFO:tensorflow:loss = 0.18011616, step = 300 (3.939 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 320 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 340 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 360 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 380 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 400 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 23.743\n",
      "INFO:tensorflow:loss = 0.14215985, step = 400 (4.214 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 420 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 440 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 460 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 480 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 500 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.8821\n",
      "INFO:tensorflow:loss = 0.103973165, step = 500 (4.787 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 520 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 540 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 560 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 580 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 600 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 18.4768\n",
      "INFO:tensorflow:loss = 0.090466, step = 600 (5.413 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 620 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 640 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 660 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 680 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 700 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.131\n",
      "INFO:tensorflow:loss = 0.08377133, step = 700 (4.732 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 720 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 740 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 760 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 780 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 800 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.2993\n",
      "INFO:tensorflow:loss = 0.06619618, step = 800 (4.695 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 820 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 840 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 860 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 880 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 900 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.4901\n",
      "INFO:tensorflow:loss = 0.12774345, step = 900 (4.882 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 920 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 940 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 960 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 980 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 0.030821266.\n",
      "CPU times: user 2min 53s, sys: 21.9 s, total: 3min 15s\n",
      "Wall time: 48.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# need if file are removed with previous event files\n",
    "tf.summary.FileWriterCache.clear()\n",
    "# Delete both saved and checkpointed models\n",
    "#shutil.rmtree(FLAGS.model_dir, ignore_errors=True)\n",
    "#shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)\n",
    "# Fit the model (using estimator.train and data.Dataset)\n",
    "estimator_train_model.train(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(glob.glob(path_train_tfrecords+'/train*.tfrecords'),\n",
    "                                                                                     FLAGS,\n",
    "                                                                                     mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                                                                                     batch_size=FLAGS.batch_size),\n",
    "                            steps=1000),\n",
    "                            hooks=[time_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags \n",
      "/Users/tarrade/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/ipykernel_launcher.py:\n",
      "  --batch_size: Batch size\n",
      "    (default: '128')\n",
      "    (an integer)\n",
      "  --dim_input: dimension of the input data for our model\n",
      "    (default: '784')\n",
      "    (an integer)\n",
      "  --epoch: number of epoch\n",
      "    (default: '100')\n",
      "    (an integer)\n",
      "  --f: kernel\n",
      "    (default: '')\n",
      "  --model_dir: Dir to save a model and checkpoints\n",
      "    (default: 'results/Models/Mnist/tf_1_12/estimator/ckpt/')\n",
      "  --num_classes: number of classes in our model\n",
      "    (default: '10')\n",
      "    (an integer)\n",
      "  --num_parallel_calls: Number of paralell calls\n",
      "    (default: '4')\n",
      "    (an integer)\n",
      "  --prefetch_buffer_size: Prefetch buffer size\n",
      "    (default: '-1')\n",
      "    (an integer)\n",
      "  --saved_dir: Dir to save a model for TF serving\n",
      "    (default: 'results/Models/Mnist/tf_1_12/estimator/pt/')\n",
      "  --shuffle_buffer_size: Shuffle buffer size\n",
      "    (default: '1280')\n",
      "    (an integer)\n",
      "  --step_per_epoch: number of step per epoch\n",
      "    (default: '468')\n",
      "    (an integer)\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 20, '_save_checkpoints_steps': 20, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x1c48f459b0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c49049c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 20 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.5091658, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 20 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-18-15:39:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-18-15:39:34\n",
      "INFO:tensorflow:Saving dict for global step 20: accuracy = 0.8710443, global_step = 20, loss = 0.45188025\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-20\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-20\n",
      "WARNING:tensorflow:From /Users/tarrade/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: results/Models/Mnist/tf_1_12/estimator/ckpt/export/exporter/temp-b'1552923575'/saved_model.pb\n",
      "INFO:tensorflow:Saving checkpoints for 40 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 60 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 80 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 100 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 16.7279\n",
      "INFO:tensorflow:loss = 0.21343213, step = 100 (5.980 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 120 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 140 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 160 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 180 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 200 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 32.8054\n",
      "INFO:tensorflow:loss = 0.2332618, step = 200 (3.049 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 220 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 240 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 260 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 280 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-18-15:39:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-280\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-18-15:39:45\n",
      "INFO:tensorflow:Saving dict for global step 280: accuracy = 0.9568829, global_step = 280, loss = 0.13606004\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 280: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-280\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-280\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: results/Models/Mnist/tf_1_12/estimator/ckpt/export/exporter/temp-b'1552923585'/saved_model.pb\n",
      "INFO:tensorflow:Saving checkpoints for 300 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 20.1287\n",
      "INFO:tensorflow:loss = 0.16189528, step = 300 (4.968 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 320 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 340 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 360 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 380 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 400 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 35.2141\n",
      "INFO:tensorflow:loss = 0.12350128, step = 400 (2.840 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 420 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 440 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 460 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 480 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 500 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 33.3106\n",
      "INFO:tensorflow:loss = 0.07751522, step = 500 (3.002 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 520 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 540 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 560 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-18-15:39:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-560\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-18-15:39:55\n",
      "INFO:tensorflow:Saving dict for global step 560: accuracy = 0.9651899, global_step = 560, loss = 0.10247178\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 560: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-560\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-560\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: results/Models/Mnist/tf_1_12/estimator/ckpt/export/exporter/temp-b'1552923595'/saved_model.pb\n",
      "INFO:tensorflow:Saving checkpoints for 580 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 600 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 19.033\n",
      "INFO:tensorflow:loss = 0.1096233, step = 600 (5.255 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 620 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 640 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 660 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 680 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 700 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 33.1316\n",
      "INFO:tensorflow:loss = 0.08202767, step = 700 (3.018 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 720 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 740 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 760 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 780 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 800 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 32.6929\n",
      "INFO:tensorflow:loss = 0.059397873, step = 800 (3.061 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 820 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-18-15:40:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-820\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-18-15:40:05\n",
      "INFO:tensorflow:Saving dict for global step 820: accuracy = 0.9726068, global_step = 820, loss = 0.09058477\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 820: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-820\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-820\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: results/Models/Mnist/tf_1_12/estimator/ckpt/export/exporter/temp-b'1552923605'/saved_model.pb\n",
      "INFO:tensorflow:Saving checkpoints for 840 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 860 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 880 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 900 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 19.6212\n",
      "INFO:tensorflow:loss = 0.11920511, step = 900 (5.094 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 920 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 940 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 960 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 980 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-18-15:40:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-18-15:40:13\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9728046, global_step = 1000, loss = 0.07933134\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: results/Models/Mnist/tf_1_12/estimator/ckpt/export/exporter/temp-b'1552923613'/saved_model.pb\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 0.07127096.\n",
      "CPU times: user 2min 51s, sys: 19.7 s, total: 3min 10s\n",
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Delete both saved and checkpointed models\n",
    "shutil.rmtree(FLAGS.model_dir, ignore_errors=True)\n",
    "shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)\n",
    "# need if file are removed with previous event files\n",
    "tf.summary.FileWriterCache.clear()\n",
    "# Reset Keras\n",
    "tf.keras.backend.clear_session()\n",
    "# Fit the model (using estimator.train and data.Dataset)\n",
    "mnist_v1.train_and_evaluate(FLAGS, use_keras=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import numpy as np\n",
    "\n",
    "def load_data_tensorboard(path):\n",
    "    event_acc = event_accumulator.EventAccumulator(path)\n",
    "    event_acc.Reload()\n",
    "    data = {}\n",
    "    \n",
    "    for tag in sorted(event_acc.Tags()[\"scalars\"]):\n",
    "        x, y = [], []\n",
    "        for scalar_event in event_acc.Scalars(tag):\n",
    "            x.append(scalar_event.step)\n",
    "            y.append(scalar_event.value)\n",
    "        data[tag] = (np.asarray(x), np.asarray(y))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "INFO:tensorflow:No path found after results/Models/Mnist/tf_1_12/estimator/ckpt/events.out.tfevents.1552923570.Fabien-Tarrades-MacBook-Pro.local\n"
     ]
    }
   ],
   "source": [
    "history=load_data_tensorboard(FLAGS.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "INFO:tensorflow:No path found after results/Models/Mnist/tf_1_12/estimator/ckpt/events.out.tfevents.1552923570.Fabien-Tarrades-MacBook-Pro.local\n",
      "{'global_step/sec': (array([101, 201, 301, 401, 501, 601, 701, 801, 901]), array([16.72790146, 32.80542755, 20.12867355, 35.21408463, 33.31061554,\n",
      "       19.03300858, 33.13162613, 32.69285583, 19.62119293])), 'loss_1': (array([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181, 201, 221, 241,\n",
      "       261, 281, 301, 321, 341, 361, 381, 401, 421, 441, 461, 481, 501,\n",
      "       521, 541, 561, 581, 601, 621, 641, 661, 681, 701, 721, 741, 761,\n",
      "       781, 801, 821, 841, 861, 881, 901, 921, 941, 961, 981]), array([2.50916576, 0.41445929, 0.46398604, 0.30309707, 0.28942156,\n",
      "       0.21343213, 0.13179359, 0.26019508, 0.17771605, 0.20141423,\n",
      "       0.23326179, 0.20387469, 0.21480151, 0.11904723, 0.22463453,\n",
      "       0.16189528, 0.18795162, 0.15812938, 0.08215295, 0.08590715,\n",
      "       0.12350128, 0.19844094, 0.16425976, 0.10932589, 0.09518369,\n",
      "       0.07751522, 0.09323327, 0.12699535, 0.12116995, 0.11565709,\n",
      "       0.1096233 , 0.08677372, 0.11910996, 0.09222627, 0.08778068,\n",
      "       0.08202767, 0.12203079, 0.08953345, 0.15157489, 0.09174161,\n",
      "       0.05939787, 0.15880862, 0.21366251, 0.03676502, 0.15806526,\n",
      "       0.11920511, 0.0564068 , 0.03888568, 0.09436345, 0.09894559]))}\n"
     ]
    }
   ],
   "source": [
    "print(load_data_tensorboard(FLAGS.model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['global_step/sec', 'loss_1']), 50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.keys(),len(history['loss_1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9, 3), dpi=100)\n",
    "plt.subplots_adjust(wspace=0.6)\n",
    "ax1 = plt.subplot(122)\n",
    "ax2 = plt.subplot(121)\n",
    "ax1.plot(history['loss_1'][0], history['loss_1'][1], 'b', label='training loss')\n",
    "#ax1.plot(np.arange(0, epochs), history['loss_1'][1], 'r', label='validation accuracy');\n",
    "ax1.set_title('Loss')\n",
    "ax1.set_xlabel(\"Number of steps\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the output created during the training\n",
    "https://medium.com/@prasadpal107/saving-freezing-optimizing-for-inference-restoring-of-tensorflow-models-b4146deb21b5  \n",
    "- creating a keras model will create the **keras** folder \n",
    "- **checkpoint**, text file that contain all checkpoint information, like model ckpt file name and path\n",
    "- **model.ckpt-xxx.meta** and **model.ckpt-xxx.data-yyyyy-of-zzzzz** and **model.ckpt-xxx.index** file created for each model  \n",
    "  .ckpt-xxx.meta contains the complete graph. It includes GraphDef, SaverDef, and so on  \n",
    "  .ckpt-xxx.data contains the values of variables(weights, biases, placeholders, gradients, hyper-parameters etc)   \n",
    "  .ckpt-xxx.index is a table where each key is the name of a tensor and its value is a serialized BundleEntryProto \n",
    "- **graph.pbtxt** holds a network of nodes, each representing one operation, connected to each other as inputs and outputs (graph structure)\n",
    "- **events.out.tfevents.xxxxxxxxxx** which contain information that TensorBoard uses to create visualizations\n",
    "\n",
    "Meta files holds ,more than just the structure of the graph like MetaInfoDef , GraphDef SaverDef , CollectionDef . Whereas .pbtxt files holds only the structure of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras\n",
      "checkpoint\n",
      "model.ckpt-940.data-00000-of-00001\n",
      "model.ckpt-1000.data-00000-of-00001\n",
      "model.ckpt-920.meta\n",
      "model.ckpt-940.meta\n",
      "model.ckpt-1000.meta\n",
      "model.ckpt-960.meta\n",
      "events.out.tfevents.1552739145.Fabien-Tarrades-MacBook-Pro.local\n",
      "graph.pbtxt\n",
      "model.ckpt-980.meta\n",
      "model.ckpt-960.data-00000-of-00001\n",
      "model.ckpt-920.index\n",
      "model.ckpt-920.data-00000-of-00001\n",
      "eval\n",
      "model.ckpt-980.data-00000-of-00001\n",
      "export\n",
      "model.ckpt-960.index\n",
      "model.ckpt-980.index\n",
      "model.ckpt-940.index\n",
      "model.ckpt-1000.index\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(FLAGS.model_dir+'*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow logs will be saved here:\n",
      " results/Models/Mnist/tf_1_12/estimator/ckpt/\n"
     ]
    }
   ],
   "source": [
    "print('Tensorflow logs will be saved here:\\n',FLAGS.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1551962933.Fabien-Tarrades-MacBook-Pro.local\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(FLAGS.model_dir+'*events.out.tfevents.*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_command='tensorboard --logdir \"'+FLAGS.model_dir+'\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a separate shell with the same env activated (need Tensoflow and TensorBoard)\n",
      "  copy and pate the command below without \">>\":\n",
      "  >> tensorboard --logdir \"results/Models/Mnist/tf_1_12/estimator/ckpt/\"\n"
     ]
    }
   ],
   "source": [
    "print('In a separate shell with the same env activated (need Tensoflow and TensorBoard)')\n",
    "print('  copy and pate the command below without \">>\":')\n",
    "print('  >>',tensorboard_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the output of the TimeHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = sum(time_hist.times)\n",
    "print(f\"total time with the current strategy: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_time_per_batch = np.mean(time_hist.times)\n",
    "print(f\"{BATCH_SIZE/avg_time_per_batch} images/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and losses"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# method and arguments\n",
    "evaluate(\n",
    "    input_fn,\n",
    "    steps=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(glob.glob(path_train_tfrecords+'/train*.tfrecords'),\n",
    "                                                                                              FLAGS,\n",
    "                                                                                              mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                                                                                              batch_size=FLAGS.batch_size),\n",
    "                                     steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test accuracy\n",
    "print('Loss:')\n",
    "print('  - loss [training dataset]: {0:.3f}'.format(score['loss']))\n",
    "print('')\n",
    "print('Accuracy:')\n",
    "print('  - accuracy [training dataset]: {:.2f}%'.format(100*score['accuracy']))\n",
    "print('')\n",
    "print('Number of steps:')\n",
    "print('  - number of steps [training dataset]: {}'.format(score['global_step']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(glob.glob(path_test_tfrecords+'/test*.tfrecords'),\n",
    "                                                                                              FLAGS,\n",
    "                                                                                              mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                                                                              batch_size=FLAGS.batch_size),\n",
    "                                     steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test accuracy\n",
    "print('Loss:')\n",
    "print('  - loss [testing dataset]: {0:.3f}'.format(score['loss']))\n",
    "print('')\n",
    "print('Accuracy:')\n",
    "print('  - accuracy [testing dataset]: {:.2f}%'.format(100*score['accuracy']))\n",
    "print('')\n",
    "print('Number of steps:')\n",
    "print('  - number of steps [testing dataset]: {}'.format(score['global_step']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the model\n",
    "predictions = model_fn(features, labels, tf.estimator.ModeKeys.EVAL).predictions\n",
    "\n",
    "# Manually load the latest checkpoint\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state('/my/directory')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    # Loop through the batches and store predictions and labels\n",
    "    prediction_values = []\n",
    "    label_values = []\n",
    "    while True:\n",
    "        try:\n",
    "            preds, lbls = sess.run([predictions, labels])\n",
    "            prediction_values += preds\n",
    "            label_values += lbls\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    # store prediction_values and label_values somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# method and arguments\n",
    "predict(\n",
    "    input_fn,\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    yield_single_examples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = mnist_v1.input_mnist_tfrecord_dataset_fn(sorted(glob.glob(path_test_tfrecords+'/test*.tfrecords'), key=os.path.getmtime),\n",
    "                                                           FLAGS,\n",
    "                                                           mode=tf.estimator.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = testing_dataset.make_one_shot_iterator()\n",
    "# next_element\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "\n",
    "n_iter=10\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time.clock()\n",
    "            x,y = sess.run([features, labels])\n",
    "            print('iteration n:', n, 'execution time:', time.clock() - start_time, 'seconds')\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print('first label of the batch',np.argmax(y[0]),'\\n')\n",
    "            n+=1\n",
    "            if n>=n_iter:\n",
    "                print('number of iteration reached')\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('tf.errors.OutOfRangeError')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=list(estimator_train_model.predict(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(sorted(glob.glob(path_test_tfrecords+'/test*.tfrecords'), key=os.path.getmtime),\n",
    "                                                                                                  FLAGS,\n",
    "                                                                                                  mode=tf.estimator.ModeKeys.PREDICT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer=model_opt_tf.output_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    prediction_array = predictions[i][output_layer]\n",
    "    predicted_label = np.argmax(prediction_array)\n",
    "    print('Actual label:', y_test[i])\n",
    "    print(\"Predicted label: \", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_iter=estimator_train_model.predict(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(sorted(glob.glob(path_test_tfrecords+'/test*.tfrecords'), key=os.path.getmtime),\n",
    "                                                                                                  FLAGS,\n",
    "                                                                                                  mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                                                                                  batch_size=len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for pred in list(itertools.islice(preds_iter, 5)):\n",
    "    prediction_array = pred['dense_2']\n",
    "    predicted_label = np.argmax(prediction_array)\n",
    "    print(prediction_array)\n",
    "    print(i)\n",
    "    if i==0:\n",
    "        print('--> ',pred.keys())\n",
    "    print()\n",
    "    print('Actual label:', y_test[i])\n",
    "    print(\"Predicted label: \", predicted_label)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras's model checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer=model_opt_tf.output_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator's model checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.get_variable_value(estimator_train_model.get_variable_names()[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.get_variable_value(estimator_train_model.get_variable_names()[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.latest_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model serving using Keras, tf.estimator and tf.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(FLAGS.saved_dir+'*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    \"\"\"Serving input_fn that builds features from placeholders#\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.estimator.export.ServingInputReceiver\n",
    "    \"\"\"\n",
    "    input_images = tf.placeholder(tf.float32, [None, 784])\n",
    "    features = {'dense_2_input' : input_images} # this is the dict that is then passed as \"features\" parameter to your model_fn\n",
    "    receiver_tensors = {'dense_2_input': input_images} # As far as I understand this is needed to map the input to a name you can retrieve later\n",
    "   \n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FLAGS.saved_dir):\n",
    "    os.makedirs(FLAGS.saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Only export predict mode\n",
    "estimator_train_model.export_saved_model(os.path.abspath(FLAGS.saved_dir), \n",
    "                                         serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(FLAGS.saved_dir+'*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update the model id in the path below with the correct one from above i.e'1549040172'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag='1549054852'\n",
    "os.environ['MODEL_FOR_SERVING']=FLAGS.saved_dir+model_tag+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the folder name below with the one from above i.e '1549040172'\n",
    "for file in glob.glob(FLAGS.saved_dir+model_tag+'/*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the saved model before serving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! saved_model_cli show --dir $MODEL_FOR_SERVING --tag serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cloud ML Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking gcloud installation (SDK)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "install SDK"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "in case of issue with \"Bad magic number in .pyc file\" -> mix python 2 and python 3\n",
    "which python -> path (should use python 3)\n",
    "export CLOUDSDK_PYTHON=path (should use python 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud components list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud components update"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud auth configure-docker"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud version"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud ml-engine versions create --help"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda3/bin/python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a input json file and string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input needed to get prediction using ml-engine an option --json-instances: 'dense_2_input' for each new entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction=x_test[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_prediction.tolist()\n",
    "json_file = \"../data/input_predict_gcloud.json\" \n",
    "\n",
    "with codecs.open(json_file, 'w', encoding='utf-8') as f:\n",
    "    for el in data:\n",
    "        instance = {'dense_2_input': el}\n",
    "        json.dump(instance, f , sort_keys=True)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input needed to get prediction using ml-engine and cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_prediction.tolist()\n",
    "json_file = \"../data/input_predict_cURL.json\" \n",
    "\n",
    "with codecs.open(json_file, 'w', encoding='utf-8') as f:\n",
    "    tmp={}\n",
    "    list_tmp=[]\n",
    "    for el in data:\n",
    "        tmp['dense_2_input']=el\n",
    "        list_tmp.append(tmp)\n",
    "    instance = {\"instances\": list_tmp}    \n",
    "    json.dump(instance, f , sort_keys=True)\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input needed to get prediction using ml-engine and requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_predict_request = json.dumps({\"signature_name\": \"serving_default\", \"instances\": input_prediction.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title):\n",
    "    plt.figure()\n",
    "    plt.imshow(img.reshape(28,28))\n",
    "    plt.axis('off')\n",
    "    plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    show(x_test[i],'Test dataset, true label: '+str(np.argmax(y_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model inference using gcloud locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda3/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine local predict --model-dir $MODEL_FOR_SERVING --json-instances ../data/input_predict_gcloud.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model using Cloud ML Engine\n",
    "- https://cloud.google.com/ml-engine/docs/v1/predict-request\n",
    "- https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#requesting_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PROJECT']=subprocess.run('gcloud config list project --format \"value(core.project)\"', shell=True, check=True, stdout=subprocess.PIPE).stdout.decode().replace('\\n', '')\n",
    "os.environ['MODEL']='mnist'\n",
    "os.environ['BUCKET']='gs://'+os.environ['PROJECT']\n",
    "os.environ['VERSION']='v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsutil need python 2.7\n",
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r $MODEL_FOR_SERVING $BUCKET/model_dir_tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine models list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when creating the model for the first time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud ml-engine models create ${MODEL} \\\n",
    "--regions us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a version and store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine versions create ${VERSION} \\\n",
    "--model ${MODEL} \\\n",
    "--origin=${BUCKET}/model_dir_tmp/1549054852 \\\n",
    "--runtime-version=1.12 \\\n",
    "--staging-bucket=${BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the list of model in ML-Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !gcloud ml-engine versions list --model mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our model using ML-Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine predict --model=${MODEL} --version=${VERSION} --json-instances ../data/input_predict_gcloud.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing using RESTful API \n",
    "- https://www.tensorflow.org/serving/api_rest  \n",
    "RESTful API is an application program interface (API) that uses HTTP requests to GET, PUT, POST and DELETE data (Json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://ml.googleapis.com/v1/projects/${PROJECT}/models/${MODEL}/versions/${VERSION} \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "https://ml.googleapis.com/v1/projects/${PROJECT}/models/${MODEL}/versions/${VERSION}:predict \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-d @../data/input_predict_cURL.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python and requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ml.googleapis.com/v1/projects/'+os.environ['PROJECT']+'/models/'+os.environ['MODEL']+'/versions/'+os.environ['VERSION']+':predict'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, stdout=subprocess.PIPE).stdout.decode().replace('\\n', ''))\n",
    "}\n",
    "\n",
    "json_response = requests.post(url=url, data=input_predict_request, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    show(x_test[i], 'The model thought this was a {} , and it was actually a {}'.format(np.argmax(predictions[i]['dense_3']),np.argmax(y_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing using gRPC API \n",
    "- https://cloud.google.com/endpoints/docs/grpc/about-grpc  \n",
    "gRPC is a high performance, open-source universal RPC framework, developed by Google. In gRPC, a client application can directly call methods on a server application on a different machine as if it was a local object, making it easier to create distributed applications and services (Protobuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload the model and make evaluation using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_model_opt_keras=tf.keras.models.load_model(FLAGS.model_dir_keras+'keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = reload_model_opt_keras.evaluate(x_train, \n",
    "                                        y_train, \n",
    "                                        verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the model using Keras and tf.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_opt_keras.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_opt_keras.evaluate(x_train, \n",
    "                       y_train, \n",
    "                       verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    show(x_test[i], 'The model thought this was a {} , and it was actually a {}'.format(np.argmax(predictions[i]['dense_3']),np.argmax(y_test[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_gcp_dl]",
   "language": "python",
   "name": "conda-env-env_gcp_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
