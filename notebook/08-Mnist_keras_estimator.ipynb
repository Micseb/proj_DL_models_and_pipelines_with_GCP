{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification example with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Install packages on Google  Cloud Datalab (locally use conda env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Select in the Python3 Kernel:\n",
    "In the menu bar the of 'Kernel', select   \n",
    "**python3**\n",
    "### Install needed packages\n",
    "copy the command below in a Google Cloud Datalab cell  \n",
    "**!pip install tensorflow==1.12**\n",
    "### Restart the Kernel \n",
    "this is to take into account the new installed packages. Click in the menu bar on:  \n",
    "**Reset Session**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include paths to our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/notebook\n",
      "/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "workingdir=os.getcwd()\n",
    "print(workingdir)\n",
    "d=[d for d in os.listdir(workingdir)]\n",
    "n=0\n",
    "while not set(['notebook']).issubset(set(d)):\n",
    "    workingdir=str(pathlib.Path(workingdir).parents[0])\n",
    "    print(workingdir)\n",
    "    d=[d for d in os.listdir(str(workingdir))]\n",
    "    n+=1\n",
    "    if n>5:\n",
    "        break\n",
    "sys.path.insert(0, workingdir)\n",
    "os.chdir(workingdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup librairies import and plots style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.color import gray2rgb, rgb2gray, label2rgb\n",
    "import _pickle as cPickle\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from random import sample, randint, shuffle\n",
    "import time\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import json \n",
    "import subprocess\n",
    "import requests\n",
    "import google.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.mnist_utils as mnist_utils\n",
    "import src.utils.ml_utils as ml_utils\n",
    "import src.utils.tensorflow_helper as tensorflow_helper\n",
    "import src.model_mnist_v1.trainer.model as mnist_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(mnist_utils)\n",
    "importlib.reload(mnist_v1)\n",
    "importlib.reload(ml_utils)\n",
    "importlib.reload(tensorflow_helper);# to reload the function and mask the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set plots style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seaborn-dark', 'seaborn-darkgrid', 'seaborn-ticks', 'fivethirtyeight', 'seaborn-whitegrid', 'classic', '_classic_test', 'fast', 'seaborn-talk', 'seaborn-dark-palette', 'seaborn-bright', 'seaborn-pastel', 'grayscale', 'seaborn-notebook', 'ggplot', 'seaborn-colorblind', 'seaborn-muted', 'seaborn', 'Solarize_Light2', 'seaborn-paper', 'bmh', 'tableau-colorblind10', 'seaborn-white', 'dark_background', 'seaborn-poster', 'seaborn-deep']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color code: https://matplotlib.org/gallery/color/named_colors.html#sphx-glr-gallery-color-named-colors-py\n",
    "plt.style.use('seaborn-ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization of some examples per classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train='data/mnist/numpy_train/'\n",
    "path_test='data/mnist/numpy_test/'\n",
    "x_train=cPickle.load(open(path_train+'x_train.pkl', 'rb'))\n",
    "y_train=cPickle.load(open(path_train+'y_train.pkl', 'rb'))\n",
    "x_test=cPickle.load(open(path_test+'x_test.pkl', 'rb'))\n",
    "y_test=cPickle.load(open(path_test+'y_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some example from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1080 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_utils.plot_mnist_images(x_train[0:25], y_train[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of classes\n",
    "NUM_CLASSES =10\n",
    "\n",
    "# dimension of the input data\n",
    "DIM_INPUT = 784\n",
    "\n",
    "# number of epoch to train our model\n",
    "EPOCHS = 100\n",
    "\n",
    "# size of our mini batch\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# shuffle buffer size\n",
    "SHUFFLE_BUFFER_SIZE = 10 * BATCH_SIZE\n",
    "\n",
    "# prefetch buffer size\n",
    "PREFETCH_BUFFER_SIZE = tf.contrib.data.AUTOTUNE\n",
    "\n",
    "# number of paralell calls\n",
    "NUM_PARALELL_CALL = 4\n",
    "\n",
    "# model version\n",
    "MODEL='v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow_helper.del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for jupyter notebook and avoir : \"UnrecognizedFlagError: Unknown command line flag 'f'\"\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel') \n",
    "\n",
    "# path to store the model and input for Tensorboard and SavedModel\n",
    "tf.app.flags.DEFINE_string('model_dir', 'results/Models/Mnist/tf_1_12/estimator/ckpt/', 'Dir to save a model and checkpoints')\n",
    "tf.app.flags.DEFINE_string('saved_dir', 'results/Models/Mnist/tf_1_12/estimator/pt/', 'Dir to save a model for TF serving')\n",
    "\n",
    "# path to store the model and input for Tensorboard\n",
    "#tf.app.flags.DEFINE_string('model_dir_keras', './results/Models/Mnist/tf_1_12/keras/'+MODEL+'/ckpt/', 'Dir to save a model and checkpoints with keras')\n",
    "#tf.app.flags.DEFINE_string('tensorboard_dir_keras', './results/Models/Mnist/tf_1_12/keras/'+MODEL+'/logs/', 'Dir to save logs for TensorBoard with keras')\n",
    "\n",
    "# parameters for the input dataset and train the model\n",
    "tf.app.flags.DEFINE_integer('epoch', EPOCHS, 'number of epoch')\n",
    "tf.app.flags.DEFINE_integer('step_per_epoch', len(x_train) // BATCH_SIZE, 'number of step per epoch')\n",
    "tf.app.flags.DEFINE_integer('batch_size', BATCH_SIZE, 'Batch size')\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size', SHUFFLE_BUFFER_SIZE , 'Shuffle buffer size')\n",
    "tf.app.flags.DEFINE_integer('prefetch_buffer_size', PREFETCH_BUFFER_SIZE, 'Prefetch buffer size')\n",
    "tf.app.flags.DEFINE_integer('num_parallel_calls', NUM_PARALELL_CALL, 'Number of paralell calls')\n",
    "\n",
    "# parameters for the model\n",
    "tf.app.flags.DEFINE_integer('num_classes', NUM_CLASSES, 'number of classes in our model')\n",
    "tf.app.flags.DEFINE_integer('dim_input', DIM_INPUT, 'dimension of the input data for our model')\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/tarrade/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/ipykernel_launcher.py:\n",
      "  --batch_size: Batch size\n",
      "    (default: '128')\n",
      "    (an integer)\n",
      "  --dim_input: dimension of the input data for our model\n",
      "    (default: '784')\n",
      "    (an integer)\n",
      "  --epoch: number of epoch\n",
      "    (default: '100')\n",
      "    (an integer)\n",
      "  --f: kernel\n",
      "    (default: '')\n",
      "  --model_dir: Dir to save a model and checkpoints\n",
      "    (default: 'results/Models/Mnist/tf_1_12/estimator/ckpt/')\n",
      "  --num_classes: number of classes in our model\n",
      "    (default: '10')\n",
      "    (an integer)\n",
      "  --num_parallel_calls: Number of paralell calls\n",
      "    (default: '4')\n",
      "    (an integer)\n",
      "  --prefetch_buffer_size: Prefetch buffer size\n",
      "    (default: '-1')\n",
      "    (an integer)\n",
      "  --saved_dir: Dir to save a model for TF serving\n",
      "    (default: 'results/Models/Mnist/tf_1_12/estimator/pt/')\n",
      "  --shuffle_buffer_size: Shuffle buffer size\n",
      "    (default: '1280')\n",
      "    (an integer)\n",
      "  --step_per_epoch: number of step per epoch\n",
      "    (default: '468')\n",
      "    (an integer)\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, tensorflow.python.platform.flags._FlagValuesWrapper)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eval', 'infer', 'train')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre defined flags\n",
    "tf.estimator.ModeKeys.EVAL, tf.estimator.ModeKeys.PREDICT, tf.estimator.ModeKeys.TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the number relater to the number of events (epoch, batch size, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_input(data, step='training'):\n",
    "    print('Summary for the {} dataset:'.format(step))\n",
    "    if step=='training':\n",
    "        print('  - number of epoch            :', FLAGS.epoch)\n",
    "        print('  - number of events per epoch :', len(data))\n",
    "        print('  - batch size                 :', FLAGS.batch_size)\n",
    "        print('  - number of step per epoch   :', FLAGS.step_per_epoch)\n",
    "        print('  - total number of steps      :', FLAGS.epoch * FLAGS.step_per_epoch)\n",
    "    else:\n",
    "        print('  - number of epoch            :', 1)\n",
    "        print('  - number of events per epoch :', len(data))\n",
    "        print('  - batch size                 :', None)\n",
    "        print('  - number of step per epoch   :', 1)\n",
    "        print('  - total number of steps      :', 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for the training dataset:\n",
      "  - number of epoch            : 100\n",
      "  - number of events per epoch : 60000\n",
      "  - batch size                 : 128\n",
      "  - number of step per epoch   : 468\n",
      "  - total number of steps      : 46800\n"
     ]
    }
   ],
   "source": [
    "print_summary_input(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for the testing dataset:\n",
      "  - number of epoch            : 1\n",
      "  - number of events per epoch : 10000\n",
      "  - batch size                 : None\n",
      "  - number of step per epoch   : 1\n",
      "  - total number of steps      : 1\n"
     ]
    }
   ],
   "source": [
    "print_summary_input(x_test, 'testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning modelling with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting existing models\n",
    "delete fist the folder for a clean start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model will be saved here:\n",
      " results/Models/Mnist/tf_1_12/estimator/ckpt/\n"
     ]
    }
   ],
   "source": [
    "print('trained model will be saved here:\\n', FLAGS.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the folder from previous try \n",
    "shutil.rmtree(FLAGS.model_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model will be saved here:\n",
      " results/Models/Mnist/tf_1_12/estimator/pt/\n"
     ]
    }
   ],
   "source": [
    "print('trained model will be saved here:\\n', FLAGS.saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the folder from previous try \n",
    "shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model_opt_tf = mnist_v1.keras_baseline_model(FLAGS, opt='tf')\n",
    "\n",
    "# store the origina weights\n",
    "initial_weights = model_opt_tf.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the nuber of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_opt_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check input and output layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_input']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt_tf.input_names # Use this name as the dictionary key in the TF input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_2']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt_tf.output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and inference using  tf.estimator and tf.data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **batch_size** determines the number of samples in each mini batch. Its maximum is the number of all samples, which makes gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but iterations are slower. Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around. batch_size allows to adjust between the two extremes: accurate gradient direction and fast iteration. Also, the maximum value for batch_size may be limited if your model + data set does not fit into the available (GPU) memory.\n",
    "- **steps_per_epoch** the number of batch iterations before a training epoch is considered finished. If you have a training set of fixed size you can ignore it but it may be useful if you have a huge data set or if you are generating random data augmentations on the fly, i.e. if your training set has a (generated) infinite size. If you have the time to go through your whole training data set I recommend to skip this parameter.\n",
    "- **validation_steps** similar to steps_per_epoch but on the validation data set instead on the training data. If you have the time to go through your whole validation data set I recommend to skip this parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.train.SessionRunHook):\n",
    "    def begin(self):\n",
    "        self.times = []\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        self.iter_time_start = time.time()\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        self.times.append(time.time() - self.iter_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = TimeHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tf.distribute.startegy work across multiple devices/machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    }
   ],
   "source": [
    "# the tf.distribute.Strategy API is an easy way to distribute your training across multiple devices/machines\n",
    "\n",
    "#strategy=None\n",
    "## work with Keras with tf.train optimiser not tf.keras\n",
    "strategy = tf.contrib.distribute.OneDeviceStrategy('device:CPU:0')\n",
    "#strategy = tf.contrib.distribute.OneDeviceStrategy('device:GPU:0')\n",
    "#NUM_GPUS = 2\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=NUM_GPUS)\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy()\n",
    "\n",
    "# config tf.estimator to use a give strategy\n",
    "training_config = tf.estimator.RunConfig(train_distribute=strategy,\n",
    "                                         model_dir=FLAGS.model_dir,\n",
    "                                         save_summary_steps=1,\n",
    "                                         save_checkpoints_steps=100,\n",
    "                                         keep_checkpoint_max=3,\n",
    "                                         log_step_count_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform a keras model to estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x1c3cf6c8d0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c69dcfe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model_opt_tf.set_weights(initial_weights)\n",
    "\n",
    "# transfor keras model to estimator model\n",
    "estimator_train_model = tf.keras.estimator.model_to_estimator(keras_model=model_opt_tf,\n",
    "                                                              config=training_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dataset\n",
    "Use tf.data.dataset to feed the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure you have the tfrecords file locally if you want to train localy (or get them from Cloud Storage)\n",
    "path_test_tfrecords = 'data/mnist/tfrecords_image_test'\n",
    "path_train_tfrecords = 'data/mnist/tfrecords_image_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input dataset functions for training and testing will be pass during fit to load, convert, preprocess and reshuffle the images and labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# method and arguments\n",
    "\n",
    "# train\n",
    "train(\n",
    "    input_fn,\n",
    "    hooks=None,\n",
    "    steps=None,\n",
    "    max_steps=None,\n",
    "    saving_listeners=None\n",
    ")\n",
    "--> Trains a model given training data input_fn\n",
    "\n",
    "--> return: nothing\n",
    "\n",
    "# evalute\n",
    "evaluate(\n",
    "    input_fn,\n",
    "    steps=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    name=None\n",
    ")\n",
    "--> Evaluates the model given evaluation data input_fn\n",
    "\n",
    "--> return: A dict containing the evaluation metrics specified in model_fn keyed by name, as well as an entry global_step which contains the value of the global step for which this evaluation was performed. For canned estimators, the dict contains the loss (mean loss per mini-batch) and the average_loss (mean loss per sample). Canned classifiers also return the accuracy. Canned regressors also return the label/mean and the prediction/mean.\n",
    "\n",
    "# predict\n",
    "predict(\n",
    "    input_fn,\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    yield_single_examples=True\n",
    ")\n",
    "--> Yields predictions for given features.\n",
    "\n",
    "--> return: Evaluated values of predictions tensors\n",
    "\n",
    "# train and evaluate\n",
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "--> Train and evaluate the estimator\n",
    "\n",
    "--> return: A tuple of the result of the evaluate call to the Estimator and the export results using the specified ExportStrategy. Currently, the return value is undefined for distributed training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=[os.remove(x) for x in glob.glob(FLAGS.model_dir+'*') if 'keras' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.5371077, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 20 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 40 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 60 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 80 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.6277\n",
      "INFO:tensorflow:loss = 0.15460324, step = 100 (4.850 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 120 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 140 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 160 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 180 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 25.224\n",
      "INFO:tensorflow:loss = 0.22668627, step = 200 (3.965 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 220 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 240 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 260 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 280 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 300 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 25.383\n",
      "INFO:tensorflow:loss = 0.18011616, step = 300 (3.939 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 320 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 340 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 360 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 380 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 400 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 23.743\n",
      "INFO:tensorflow:loss = 0.14215985, step = 400 (4.214 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 420 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 440 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 460 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 480 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 500 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.8821\n",
      "INFO:tensorflow:loss = 0.103973165, step = 500 (4.787 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 520 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 540 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 560 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 580 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 600 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 18.4768\n",
      "INFO:tensorflow:loss = 0.090466, step = 600 (5.413 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 620 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 640 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 660 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 680 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 700 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.131\n",
      "INFO:tensorflow:loss = 0.08377133, step = 700 (4.732 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 720 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 740 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 760 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 780 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 800 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.2993\n",
      "INFO:tensorflow:loss = 0.06619618, step = 800 (4.695 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 820 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 840 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 860 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 880 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 900 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.4901\n",
      "INFO:tensorflow:loss = 0.12774345, step = 900 (4.882 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 920 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 940 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 960 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 980 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 0.030821266.\n",
      "CPU times: user 2min 53s, sys: 21.9 s, total: 3min 15s\n",
      "Wall time: 48.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# need if file are removed with previous event files\n",
    "tf.summary.FileWriterCache.clear()\n",
    "# Delete both saved and checkpointed models\n",
    "#shutil.rmtree(FLAGS.model_dir, ignore_errors=True)\n",
    "#shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)\n",
    "# Fit the model (using estimator.train and data.Dataset)\n",
    "estimator_train_model.train(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(glob.glob(path_train_tfrecords+'/train*.tfrecords'),\n",
    "                                                                                     FLAGS,\n",
    "                                                                                     mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                                                                                     batch_size=FLAGS.batch_size),\n",
    "                            steps=1000),\n",
    "                            hooks=[time_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 20, '_save_checkpoints_steps': 20, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x1c685a1898>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c4064d8d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 20 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('results/Models/Mnist/tf_1_12/estimator/ckpt/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.563668, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 20 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-18:28:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-18:28:10\n",
      "INFO:tensorflow:Saving dict for global step 20: accuracy = 0.86560524, global_step = 20, loss = 0.4484818\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-20\n",
      "INFO:tensorflow:Saving checkpoints for 40 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 60 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 80 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 100 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 17.1401\n",
      "INFO:tensorflow:loss = 0.20652479, step = 100 (5.835 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 120 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 140 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 160 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 180 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 200 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 32.8833\n",
      "INFO:tensorflow:loss = 0.19212145, step = 200 (3.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 220 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 240 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 260 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 280 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-18:28:19\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-280\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-18:28:21\n",
      "INFO:tensorflow:Saving dict for global step 280: accuracy = 0.9582674, global_step = 280, loss = 0.13100697\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 280: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-280\n",
      "INFO:tensorflow:Saving checkpoints for 300 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 19.7505\n",
      "INFO:tensorflow:loss = 0.2264704, step = 300 (5.063 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 320 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 340 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 360 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 380 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 400 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 30.1602\n",
      "INFO:tensorflow:loss = 0.16364685, step = 400 (3.316 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 420 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 440 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 460 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 480 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 500 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 27.5823\n",
      "INFO:tensorflow:loss = 0.10438985, step = 500 (3.626 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 520 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-18:28:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-520\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-18:28:31\n",
      "INFO:tensorflow:Saving dict for global step 520: accuracy = 0.9675633, global_step = 520, loss = 0.103007525\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 520: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-520\n",
      "INFO:tensorflow:Saving checkpoints for 540 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 560 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 580 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 600 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 19.0892\n",
      "INFO:tensorflow:loss = 0.17371337, step = 600 (5.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 620 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 640 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 660 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 680 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 700 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 28.2189\n",
      "INFO:tensorflow:loss = 0.10554991, step = 700 (3.543 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 720 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 740 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 760 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-18:28:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-760\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-18:28:41\n",
      "INFO:tensorflow:Saving dict for global step 760: accuracy = 0.9730024, global_step = 760, loss = 0.08701541\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 760: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-760\n",
      "INFO:tensorflow:Saving checkpoints for 780 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 800 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 17.3362\n",
      "INFO:tensorflow:loss = 0.06398413, step = 800 (5.768 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 820 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 840 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 860 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 880 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 900 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 28.7492\n",
      "INFO:tensorflow:loss = 0.13535959, step = 900 (3.479 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 920 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 940 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 960 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 980 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-18:28:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-18:28:52\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9761669, global_step = 1000, loss = 0.07320196\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 0.032828975.\n",
      "CPU times: user 3min 1s, sys: 21.8 s, total: 3min 22s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Delete both saved and checkpointed models\n",
    "shutil.rmtree(FLAGS.model_dir, ignore_errors=True)\n",
    "shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)\n",
    "# need if file are removed with previous event files\n",
    "tf.summary.FileWriterCache.clear()\n",
    "# Reset Keras\n",
    "tf.keras.backend.clear_session()\n",
    "# Fit the model (using estimator.train and data.Dataset)\n",
    "mnist_v1.train_and_evaluate(FLAGS, use_keras=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x1c67f683c8>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c67f688d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "label Tensor(\"ExperimentalFunctionBufferingResourceGetNext:1\", shape=(128, 10), dtype=float32, device=/device:CPU:0) logits Tensor(\"sequential/dense_2/Softmax:0\", shape=(128, 10), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.302267, step = 0\n",
      "INFO:tensorflow:global_step/sec: 19.8209\n",
      "INFO:tensorflow:loss = 1.926553, step = 10 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9321\n",
      "INFO:tensorflow:loss = 1.6792604, step = 20 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6529\n",
      "INFO:tensorflow:loss = 1.6813326, step = 30 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.1807\n",
      "INFO:tensorflow:loss = 1.6771377, step = 40 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5735\n",
      "INFO:tensorflow:loss = 1.605129, step = 50 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.4829\n",
      "INFO:tensorflow:loss = 1.6069326, step = 60 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4645\n",
      "INFO:tensorflow:loss = 1.6123676, step = 70 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.178\n",
      "INFO:tensorflow:loss = 1.5758951, step = 80 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4934\n",
      "INFO:tensorflow:loss = 1.636717, step = 90 (0.328 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-19:35:28\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-19:35:31\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9089, global_step = 100, loss = 1.560962\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-100\n",
      "INFO:tensorflow:global_step/sec: 2.78417\n",
      "INFO:tensorflow:loss = 1.540368, step = 100 (3.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4172\n",
      "INFO:tensorflow:loss = 1.5436571, step = 110 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4565\n",
      "INFO:tensorflow:loss = 1.5251633, step = 120 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.524\n",
      "INFO:tensorflow:loss = 1.5228658, step = 130 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.937\n",
      "INFO:tensorflow:loss = 1.5765798, step = 140 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.74\n",
      "INFO:tensorflow:loss = 1.5397482, step = 150 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.296\n",
      "INFO:tensorflow:loss = 1.5633941, step = 160 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4954\n",
      "INFO:tensorflow:loss = 1.570312, step = 170 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2259\n",
      "INFO:tensorflow:loss = 1.5319955, step = 180 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3612\n",
      "INFO:tensorflow:loss = 1.581109, step = 190 (0.365 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 22.8243\n",
      "INFO:tensorflow:loss = 1.5371165, step = 200 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.1639\n",
      "INFO:tensorflow:loss = 1.5396385, step = 210 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2304\n",
      "INFO:tensorflow:loss = 1.566997, step = 220 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1276\n",
      "INFO:tensorflow:loss = 1.5616378, step = 230 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5807\n",
      "INFO:tensorflow:loss = 1.5420644, step = 240 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3276\n",
      "INFO:tensorflow:loss = 1.5383301, step = 250 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.9964\n",
      "INFO:tensorflow:loss = 1.5250263, step = 260 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6968\n",
      "INFO:tensorflow:loss = 1.5286498, step = 270 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.1354\n",
      "INFO:tensorflow:loss = 1.5481582, step = 280 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4688\n",
      "INFO:tensorflow:loss = 1.5314356, step = 290 (0.394 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 19.0245\n",
      "INFO:tensorflow:loss = 1.5293062, step = 300 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1719\n",
      "INFO:tensorflow:loss = 1.5321739, step = 310 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8561\n",
      "INFO:tensorflow:loss = 1.5163457, step = 320 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4738\n",
      "INFO:tensorflow:loss = 1.51802, step = 330 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7339\n",
      "INFO:tensorflow:loss = 1.538052, step = 340 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8221\n",
      "INFO:tensorflow:loss = 1.5402727, step = 350 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6239\n",
      "INFO:tensorflow:loss = 1.4899862, step = 360 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5003\n",
      "INFO:tensorflow:loss = 1.530852, step = 370 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0689\n",
      "INFO:tensorflow:loss = 1.5125948, step = 380 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8019\n",
      "INFO:tensorflow:loss = 1.5140138, step = 390 (0.314 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-19:35:41\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-19:35:43\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.9412, global_step = 400, loss = 1.5221816\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 4.08942\n",
      "INFO:tensorflow:loss = 1.5209081, step = 400 (2.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8375\n",
      "INFO:tensorflow:loss = 1.5264952, step = 410 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7854\n",
      "INFO:tensorflow:loss = 1.5847012, step = 420 (0.324 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.107\n",
      "INFO:tensorflow:loss = 1.5294662, step = 430 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5788\n",
      "INFO:tensorflow:loss = 1.5284812, step = 440 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.9268\n",
      "INFO:tensorflow:loss = 1.5120089, step = 450 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3566\n",
      "INFO:tensorflow:loss = 1.5153697, step = 460 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0108\n",
      "INFO:tensorflow:loss = 1.5006472, step = 470 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.711\n",
      "INFO:tensorflow:loss = 1.5063378, step = 480 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3923\n",
      "INFO:tensorflow:loss = 1.5080242, step = 490 (0.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 19.5216\n",
      "INFO:tensorflow:loss = 1.527153, step = 500 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0701\n",
      "INFO:tensorflow:loss = 1.5142444, step = 510 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.152\n",
      "INFO:tensorflow:loss = 1.5060213, step = 520 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2374\n",
      "INFO:tensorflow:loss = 1.4903066, step = 530 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6848\n",
      "INFO:tensorflow:loss = 1.527108, step = 540 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.064\n",
      "INFO:tensorflow:loss = 1.4885114, step = 550 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1276\n",
      "INFO:tensorflow:loss = 1.4832729, step = 560 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5308\n",
      "INFO:tensorflow:loss = 1.5217912, step = 570 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2014\n",
      "INFO:tensorflow:loss = 1.5152447, step = 580 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5775\n",
      "INFO:tensorflow:loss = 1.5059063, step = 590 (0.350 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 21.0483\n",
      "INFO:tensorflow:loss = 1.5180671, step = 600 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.2955\n",
      "INFO:tensorflow:loss = 1.4978678, step = 610 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2666\n",
      "INFO:tensorflow:loss = 1.4901965, step = 620 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2406\n",
      "INFO:tensorflow:loss = 1.51755, step = 630 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6138\n",
      "INFO:tensorflow:loss = 1.5356071, step = 640 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8183\n",
      "INFO:tensorflow:loss = 1.4819744, step = 650 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4695\n",
      "INFO:tensorflow:loss = 1.4918567, step = 660 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5798\n",
      "INFO:tensorflow:loss = 1.5161678, step = 670 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2233\n",
      "INFO:tensorflow:loss = 1.5205249, step = 680 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.7257\n",
      "INFO:tensorflow:loss = 1.4979931, step = 690 (0.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-19:35:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-19:35:56\n",
      "INFO:tensorflow:Saving dict for global step 700: accuracy = 0.9615, global_step = 700, loss = 1.5012604\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 700: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-700\n",
      "INFO:tensorflow:global_step/sec: 4.01736\n",
      "INFO:tensorflow:loss = 1.5255874, step = 700 (2.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2277\n",
      "INFO:tensorflow:loss = 1.5208285, step = 710 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.471\n",
      "INFO:tensorflow:loss = 1.5030323, step = 720 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1056\n",
      "INFO:tensorflow:loss = 1.484925, step = 730 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.4558\n",
      "INFO:tensorflow:loss = 1.5118587, step = 740 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3874\n",
      "INFO:tensorflow:loss = 1.4839014, step = 750 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4531\n",
      "INFO:tensorflow:loss = 1.5196748, step = 760 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4016\n",
      "INFO:tensorflow:loss = 1.5090737, step = 770 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0416\n",
      "INFO:tensorflow:loss = 1.5214171, step = 780 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3744\n",
      "INFO:tensorflow:loss = 1.4918162, step = 790 (0.330 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 16.9245\n",
      "INFO:tensorflow:loss = 1.4859136, step = 800 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9133\n",
      "INFO:tensorflow:loss = 1.5025699, step = 810 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9307\n",
      "INFO:tensorflow:loss = 1.5160701, step = 820 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1966\n",
      "INFO:tensorflow:loss = 1.4774209, step = 830 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6673\n",
      "INFO:tensorflow:loss = 1.5211232, step = 840 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.94\n",
      "INFO:tensorflow:loss = 1.5100293, step = 850 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2788\n",
      "INFO:tensorflow:loss = 1.4790412, step = 860 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7519\n",
      "INFO:tensorflow:loss = 1.5117338, step = 870 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7261\n",
      "INFO:tensorflow:loss = 1.5201762, step = 880 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4085\n",
      "INFO:tensorflow:loss = 1.4851279, step = 890 (0.340 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (10 secs).\n",
      "INFO:tensorflow:global_step/sec: 18.6435\n",
      "INFO:tensorflow:loss = 1.4954106, step = 900 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6117\n",
      "INFO:tensorflow:loss = 1.5060242, step = 910 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2542\n",
      "INFO:tensorflow:loss = 1.5034163, step = 920 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5861\n",
      "INFO:tensorflow:loss = 1.5080061, step = 930 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3061\n",
      "INFO:tensorflow:loss = 1.5015204, step = 940 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3314\n",
      "INFO:tensorflow:loss = 1.4700534, step = 950 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5978\n",
      "INFO:tensorflow:loss = 1.4815857, step = 960 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3858\n",
      "INFO:tensorflow:loss = 1.4993379, step = 970 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.0682\n",
      "INFO:tensorflow:loss = 1.5256033, step = 980 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6787\n",
      "INFO:tensorflow:loss = 1.5063912, step = 990 (0.424 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt.\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "not training 1 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-19-19:36:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-19-19:36:09\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9647, global_step = 1000, loss = 1.4972818\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: results/Models/Mnist/tf_1_12/estimator/ckpt/model.ckpt-1000\n",
      "DEBUG:tensorflow:Calling exporter with the `is_the_final_export=True`.\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 1.4747764.\n",
      "CPU times: user 2min 51s, sys: 19.2 s, total: 3min 11s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "# Delete both saved and checkpointed models\n",
    "shutil.rmtree(FLAGS.model_dir, ignore_errors=True)\n",
    "shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)\n",
    "# need if file are removed with previous event files\n",
    "tf.summary.FileWriterCache.clear()\n",
    "# Reset Keras\n",
    "tf.keras.backend.clear_session()\n",
    "# Fit the model (using estimator.train and data.Dataset)\n",
    "mnist_v1.train_and_evaluate(FLAGS, use_keras=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag: \"acc_train\"\n",
      "simple_value: 0.1640625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 2.302267074584961\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.1875\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 2.2738678455352783\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.2421875\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 2.218961000442505\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.298828125\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 2.1774611473083496\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.34062498807907104\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 2.092982292175293\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.37890625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 2.0276217460632324\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.4051339328289032\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 2.001504421234131\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.4267578125\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.9506754875183105\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.4418402910232544\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.9529244899749756\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.4507812559604645\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.9587446451187134\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 19.820924758911133\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.46164771914482117\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.9265530109405518\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.4694010317325592\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.9286441802978516\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.4813701808452606\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.8566515445709229\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.4888392984867096\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.8701744079589844\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5005208253860474\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.8014278411865234\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.50732421875\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.8390979766845703\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5197610259056091\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.7946304082870483\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5256076455116272\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.8436331748962402\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.53125\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.8385980129241943\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.540234386920929\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.7826778888702393\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 33.93213653564453\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5539434552192688\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6792603731155396\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5617897510528564\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.766556739807129\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5692934989929199\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.748150110244751\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5791015625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6975678205490112\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5859375\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.7378907203674316\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5919471383094788\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.7375483512878418\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.5989583134651184\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6881297826766968\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6065848469734192\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6758389472961426\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6134159564971924\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6583197116851807\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6177083253860474\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.7226260900497437\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.65291404724121\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6229838728904724\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6813325881958008\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6298828125\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6283996105194092\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6363636255264282\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6422253847122192\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6433823704719543\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.617095708847046\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6450892686843872\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.7640833854675293\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6493055820465088\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.656908631324768\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6539273858070374\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6510387659072876\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6564555764198303\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.7034028768539429\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.659254789352417\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6862571239471436\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6634765863418579\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6452820301055908\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 35.18067932128906\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6667301654815674\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6771377325057983\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6703869104385376\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6408636569976807\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6736918687820435\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6659085750579834\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6775568127632141\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6186814308166504\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6800346970558167\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6693408489227295\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.68308424949646\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6357975006103516\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6856715679168701\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6517419815063477\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6888020634651184\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6405305862426758\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6911671161651611\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.662652611732483\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6939062476158142\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6531403064727783\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 34.573463439941406\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.6973039507865906\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6051290035247803\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7008714079856873\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6184459924697876\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7038620114326477\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6170716285705566\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7055844664573669\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.674636721611023\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7085227370262146\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6183059215545654\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7114955186843872\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5808535814285278\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7136787176132202\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6270766258239746\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7147090435028076\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.68895423412323\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7172934412956238\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6025124788284302\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7188802361488342\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6685352325439453\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 35.48288345336914\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7211834192276001\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6069326400756836\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.723412275314331\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6197201013565063\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7260664701461792\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5763506889343262\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.72802734375\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.623539686203003\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7302884459495544\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5983424186706543\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7312973737716675\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6535106897354126\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7327425479888916\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6553778648376465\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7346047759056091\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6150224208831787\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7367526888847351\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5938442945480347\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7391741275787354\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5766854286193848\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 33.464534759521484\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7407570481300354\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6123676300048828\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7421875\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6229304075241089\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7448630332946777\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.540349006652832\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7468327879905701\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5854315757751465\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7488541603088379\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.566047191619873\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7496916055679321\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6364890336990356\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7519277334213257\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5604685544967651\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7538061141967773\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.56546151638031\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7553402185440063\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6035611629486084\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.75634765625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.617313265800476\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 24.178007125854492\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7581018805503845\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.575895071029663\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7596226930618286\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5918526649475098\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7610127925872803\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5933384895324707\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7626488208770752\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.556449294090271\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7643382549285889\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5630502700805664\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.766170084476471\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5630059242248535\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7676903605461121\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5744835138320923\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7689985632896423\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5842952728271484\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7703651785850525\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5762819051742554\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7721354365348816\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5452454090118408\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.493383407592773\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7728365659713745\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6367169618606567\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.774796187877655\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5231754779815674\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7762096524238586\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5571497678756714\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7776762247085571\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.560300588607788\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7786183953285217\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5892455577850342\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.779541015625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5891892910003662\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7807667255401611\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5638973712921143\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7818080186843872\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.578031063079834\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7830650210380554\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5718119144439697\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7844531536102295\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.554686188697815\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 2.784165143966675\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7859684228897095\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5403679609298706\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7870710492134094\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5754384994506836\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7883040308952332\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.558438777923584\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7895132303237915\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5580960512161255\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7903273701667786\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.590752124786377\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.791568398475647\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5578687191009521\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7922021150588989\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6037794351577759\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7931857705116272\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5762535333633423\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7941513657569885\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5707635879516602\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7950994372367859\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5750956535339355\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 33.417205810546875\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7964527010917664\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5436570644378662\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7978515625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5384477376937866\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.7992948293685913\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5092731714248657\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8000959157943726\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.569312572479248\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8008831739425659\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5746080875396729\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8018588423728943\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5542852878570557\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8026175498962402\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.575087070465088\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8038268089294434\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5169272422790527\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8044248819351196\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5827820301055908\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8051432371139526\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5737041234970093\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 36.456451416015625\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8063016533851624\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5251632928848267\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8068647384643555\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5928375720977783\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8078632950782776\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5393013954162598\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8083417415618896\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5959446430206299\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8090000152587891\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5664066076278687\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8097718358039856\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5590815544128418\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8104084730148315\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5778075456619263\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.81121826171875\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5662113428115845\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.812197208404541\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.537736415863037\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8125\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.608985424041748\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.524017333984375\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8134542107582092\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5228657722473145\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8138612508773804\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.60862398147583\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8146146535873413\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.543332815170288\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8154734373092651\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5409471988677979\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8157986402511597\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.6040867567062378\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8164637088775635\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.55147123336792\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8169479966163635\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5842316150665283\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8175384998321533\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.564357876777649\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8184577226638794\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5385011434555054\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.819140613079071\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5543365478515625\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.93695068359375\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8196476101875305\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5765798091888428\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8204225301742554\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5427649021148682\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8211320042610168\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5437350273132324\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8214518427848816\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5848658084869385\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8223060369491577\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5297377109527588\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8230950236320496\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.532072901725769\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.823820173740387\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5359466075897217\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8243243098258972\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5639324188232422\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8250839114189148\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.534346342086792\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8254166841506958\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5839468240737915\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.739999771118164\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8261589407920837\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.539748191833496\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8267372250556946\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5507503747940063\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8272569179534912\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5653012990951538\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8276177048683167\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5894265174865723\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8279737830162048\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5764329433441162\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8286257982254028\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5355172157287598\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8292197585105896\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5364291667938232\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8296083807945251\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.578020453453064\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8301395177841187\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5516622066497803\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.83056640625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5511925220489502\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.295995712280273\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8309879899024963\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5633940696716309\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8312114477157593\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5958324670791626\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8316717743873596\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.555694818496704\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8316977620124817\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.620509147644043\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8321496248245239\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5523005723953247\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8328313231468201\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5326560735702515\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8335516452789307\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5171897411346436\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8338448405265808\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5715440511703491\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8345044255256653\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5299291610717773\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8351103067398071\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5354454517364502\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.49536895751953\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8354349136352539\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5703120231628418\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8358920812606812\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.551086664199829\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8362535834312439\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5670349597930908\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8365660905838013\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.570109486579895\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.837098240852356\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5365533828735352\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8376686573028564\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.535987377166748\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8383651375770569\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5139943361282349\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8386586904525757\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5627965927124023\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8389926552772522\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5701727867126465\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8394531011581421\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5398249626159668\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.22584915161133\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8399948477745056\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5319955348968506\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8403588533401489\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5557920932769775\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8408470153808594\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5380237102508545\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.841159999370575\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5548999309539795\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8417652249336243\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5178353786468506\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8422378897666931\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.541038155555725\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8427055478096008\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5409960746765137\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8432098031044006\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.536697506904602\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8433366417884827\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5989556312561035\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8436266183853149\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5725215673446655\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 27.3612117767334\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8438317775726318\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5811090469360352\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8442789912223816\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5390645265579224\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8446000814437866\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5571095943450928\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8447970151901245\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5843920707702637\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8451522588729858\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.54669189453125\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8456234335899353\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5295780897140503\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8460501432418823\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.543013572692871\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.846275269985199\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5724143981933594\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8466944098472595\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5345265865325928\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8470703363418579\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.540317177772522\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 22.824317932128906\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.847481369972229\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.537116527557373\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8479269742965698\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5330638885498047\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8482142686843872\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5588972568511963\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8484221696853638\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5634647607803345\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8488566875457764\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5349721908569336\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8490215539932251\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5871739387512207\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8493735194206238\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5414525270462036\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.849534273147583\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5817594528198242\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8496561050415039\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.596495270729065\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8499255776405334\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.559105634689331\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 42.16385269165039\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8502665758132935\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5396385192871094\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8505306839942932\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.557271122932434\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.850902259349823\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5339338779449463\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8513434529304504\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.525550127029419\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8517441749572754\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.533456802368164\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8521050214767456\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.531080961227417\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8523905277252197\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.555082082748413\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8524584174156189\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5814861059188843\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8526684045791626\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5696228742599487\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8530184626579285\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5284751653671265\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 40.230430603027344\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.853223979473114\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5669970512390137\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8535332083702087\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.555316686630249\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8539097309112549\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5244858264923096\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.854248046875\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5404276847839355\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8544444441795349\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5627716779708862\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8547773957252502\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5312533378601074\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8549697399139404\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5669677257537842\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.855194628238678\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5691771507263184\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8553834557533264\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5651438236236572\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.855774462223053\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5322153568267822\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.12757682800293\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8559591174125671\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5616377592086792\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8562432527542114\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5368105173110962\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8566926121711731\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5091270208358765\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8571047186851501\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5152666568756104\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8573470711708069\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5598793029785156\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8575211763381958\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.568073034286499\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8576279282569885\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5819928646087646\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8579963445663452\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5165374279022217\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8582308888435364\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5450029373168945\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8586263060569763\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5193586349487305\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.580711364746094\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.858953595161438\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5420644283294678\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8592135906219482\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5341006517410278\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8596000671386719\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5121333599090576\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8598552942276001\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5419301986694336\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.860140323638916\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.531933069229126\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.860264241695404\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5837222337722778\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8604503870010376\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.55205237865448\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8607295751571655\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5489962100982666\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8610379099845886\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5278966426849365\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8610937595367432\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5713733434677124\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.327613830566406\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8613981604576111\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.538330078125\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8617931604385376\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5023224353790283\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.862185001373291\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5091062784194946\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8625122904777527\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5179238319396973\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8627451062202454\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5409409999847412\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.863128662109375\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5135811567306519\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8632964491844177\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.555694341659546\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8635537624359131\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5435988903045654\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8639599680900574\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5085684061050415\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8641225695610046\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5558713674545288\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.996444702148438\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8644636273384094\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5250263214111328\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8648616671562195\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.507981300354004\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8651675581932068\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5273542404174805\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8653823137283325\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5383381843566895\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8654776215553284\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.562329888343811\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8657777309417725\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.524977684020996\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8660171031951904\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.526700735092163\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8663421273231506\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5166748762130737\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8665195107460022\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5401633977890015\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8667245507240295\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5426924228668213\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.696836471557617\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8670145273208618\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5286498069763184\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8671013116836548\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5731796026229858\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8673592209815979\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5370250940322876\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8676437139511108\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5179928541183472\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8678408861160278\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5464755296707153\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8680933117866516\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5369701385498047\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8682874441146851\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5392146110534668\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8685645461082458\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.519106388092041\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8686996102333069\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5504543781280518\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.868945300579071\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5244308710098267\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.135433197021484\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8691336512565613\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5481581687927246\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8694592118263245\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5072407722473145\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8697548508644104\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5120248794555664\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8698283433914185\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5543186664581299\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8700109720230103\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.544543743133545\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8701103329658508\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5685759782791138\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8703451752662659\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5298535823822021\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8705241084098816\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5375068187713623\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8708369135856628\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5105940103530884\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8710668087005615\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.526144027709961\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 25.468753814697266\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.871321976184845\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5314356088638306\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.871548593044281\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5342295169830322\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8717470169067383\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.531495213508606\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.872050404548645\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5103440284729004\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.872272253036499\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.530438780784607\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8724662065505981\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5357308387756348\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8726325631141663\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5377874374389648\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8727978467941284\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5459849834442139\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8728835582733154\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5693488121032715\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8731510639190674\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.514947533607483\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 19.02446937561035\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8733648061752319\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.529306173324585\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8735771775245667\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5298597812652588\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.873891294002533\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.516904592514038\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8741005063056946\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5317988395690918\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8741803169250488\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5587759017944336\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8743617534637451\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5305964946746826\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8745419383049011\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5227711200714111\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8745688199996948\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5683181285858154\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.874721884727478\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.539407730102539\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.87494957447052\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5262086391448975\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 40.17190170288086\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.875150740146637\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5321738719940186\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8752754330635071\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.551774501800537\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8755241632461548\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.504511833190918\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8757215142250061\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5331125259399414\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8757688403129578\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5832111835479736\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8759889006614685\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.515275478363037\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8761582970619202\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5423758029937744\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.876400351524353\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.516348123550415\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8765918612480164\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5219510793685913\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8767334222793579\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5400645732879639\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 33.856075286865234\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8769470453262329\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.516345739364624\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8772563934326172\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4904366731643677\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8775396943092346\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.506212592124939\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8777488470077515\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5268890857696533\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8779807686805725\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.52591872215271\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8781393766403198\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5323898792266846\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8783209323883057\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.526381492614746\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8785251379013062\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5183748006820679\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8786806464195251\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.534978985786438\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8789535760879517\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.492477297782898\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.473758697509766\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8791776895523071\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5180200338363647\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8792827725410461\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5379321575164795\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8793871998786926\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5604321956634521\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8794910311698914\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5572044849395752\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8795709013938904\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.556995153427124\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.879696786403656\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5397049188613892\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8799610733985901\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4982945919036865\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8801543712615967\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.519103765487671\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8802544474601746\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5514297485351562\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8804227709770203\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5202465057373047\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 31.733943939208984\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8805443644523621\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.538051962852478\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8807565569877625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5164799690246582\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8809447884559631\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.510319709777832\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8810410499572754\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5436829328536987\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8811367750167847\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.556715726852417\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8812996745109558\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5296635627746582\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8815742135047913\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4872888326644897\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8817124366760254\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.534428596496582\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.881872296333313\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5331699848175049\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.882031261920929\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5185799598693848\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 25.822050094604492\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8821447491645813\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5402727127075195\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.88232421875\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5216518640518188\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8824583888053894\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5235319137573242\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8826359510421753\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5144598484039307\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8826804757118225\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5676642656326294\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8829222321510315\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4962025880813599\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8830751180648804\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5264673233032227\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8833144307136536\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4927527904510498\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8833783268928528\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.552410364151001\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8835286498069763\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5182337760925293\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 21.623912811279297\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8837647438049316\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4899861812591553\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8839131593704224\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5268423557281494\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8839961886405945\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.536452293395996\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8841002583503723\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5412341356277466\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8842251896858215\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5313271284103394\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8844134211540222\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.509749412536621\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8846645355224609\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4977751970291138\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.884871780872345\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.504206657409668\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8850355744361877\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5236300230026245\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8851351141929626\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5409003496170044\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.50025749206543\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8852552175521851\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.53085196018219\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8854166865348816\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5232739448547363\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8855981826782227\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.510169506072998\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8857578635215759\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5198216438293457\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.885895848274231\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5260810852050781\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8861369490623474\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4953813552856445\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.886273205280304\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5207589864730835\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8864087462425232\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5241180658340454\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8865023255348206\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.537522792816162\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8865748643875122\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5566415786743164\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.068946838378906\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8867495059967041\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5125948190689087\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8868414759635925\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.533431053161621\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8868921399116516\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5572998523712158\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.88702392578125\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5270309448242188\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8871955871582031\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5106199979782104\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8873056769371033\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5412287712097168\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8875161409378052\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4989287853240967\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8876047134399414\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.540061593055725\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8877128958702087\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.53690505027771\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8878806233406067\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5119643211364746\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 31.80189323425293\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8880274891853333\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5140137672424316\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8881536722183228\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.529691457748413\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8882991671562195\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.519281029701233\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8884438276290894\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5246691703796387\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8885878324508667\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5218253135681152\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8887113332748413\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.522263765335083\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8888342380523682\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.526620864868164\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8889761567115784\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5251212120056152\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8891369104385376\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5121591091156006\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8891797065734863\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.549666166305542\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 4.089420795440674\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8893001675605774\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5209081172943115\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8893812298774719\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.546752691268921\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8895394206047058\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5139667987823486\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8896967768669128\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5122461318969727\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8899112939834595\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4944583177566528\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8900284767150879\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5215544700622559\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8901451230049133\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5236806869506836\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8902803063392639\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5264241695404053\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8904339671134949\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.509065866470337\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8904535174369812\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5631264448165894\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 35.83753967285156\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8905869722366333\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5264952182769775\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8907577395439148\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4957716464996338\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8909465670585632\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5043967962265015\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8910401463508606\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5410268306732178\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8911897540092468\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5193908214569092\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8913386464118958\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5135102272033691\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8913556933403015\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.550452709197998\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8914660811424255\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5337600708007812\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8916504979133606\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.491747260093689\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8916666507720947\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5634084939956665\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.785419464111328\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8916085362434387\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5847011804580688\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8918098211288452\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4889373779296875\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8919732570648193\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5104100704193115\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8920437693595886\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5462684631347656\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.892113983631134\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5435736179351807\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8921471834182739\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5616934299468994\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8922168016433716\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5459554195404053\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8923773169517517\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5018888711929321\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8925371766090393\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5096783638000488\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8926780819892883\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.514636516571045\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 24.10695457458496\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8927639126777649\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.529466152191162\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8928855657577515\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5168178081512451\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8930246829986572\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5077013969421387\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8932531476020813\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4756519794464111\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8934446573257446\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4880986213684082\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8935636281967163\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5205166339874268\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8935033082962036\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5888445377349854\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8936572670936584\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5102053880691528\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8938283324241638\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4962334632873535\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8939630389213562\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.51686692237854\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 26.578794479370117\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.894061803817749\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5284812450408936\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8941954374313354\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.509031057357788\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8943813443183899\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4859296083450317\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8945136666297913\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5083069801330566\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8945927023887634\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5310537815093994\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8947414755821228\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5027483701705933\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8948196172714233\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5376737117767334\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8949846625328064\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5035184621810913\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8950793147087097\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5265347957611084\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8951562643051147\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5280636548995972\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.926843643188477\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8952674865722656\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5120089054107666\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8953263163566589\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5381618738174438\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8954883813858032\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4996051788330078\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8955637216567993\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.526310920715332\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8956730961799622\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5211728811264038\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8957648277282715\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5246467590332031\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8959074020385742\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.506249189376831\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8959811925888062\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5293140411376953\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8961226940155029\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5139451026916504\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.89622962474823\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.519301414489746\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.356590270996094\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8963360786437988\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5153696537017822\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8964421153068542\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5169761180877686\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.89653080701828\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.522412657737732\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.896602213382721\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5378389358520508\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8966901898384094\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.526071310043335\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8967945575714111\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5212591886520386\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8968816995620728\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5231342315673828\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8969184160232544\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5416560173034668\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8970715403556824\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.493118405342102\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8971908092498779\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.514078140258789\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 27.010761260986328\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8973427414894104\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5006471872329712\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8974609375\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5131134986877441\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8975620865821838\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.523315191268921\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8975474834442139\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5638957023620605\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.897680938243866\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.500586986541748\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8978137969970703\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5077050924301147\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8978806138038635\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5222792625427246\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8980289101600647\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.491819143295288\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8981765508651733\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4984263181686401\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8983072638511658\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5061079263687134\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 26.710956573486328\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8984375\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5063377618789673\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8985347747802734\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5142403841018677\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8986639380455017\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5025523900985718\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8987764716148376\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5117170810699463\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8989368677139282\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4876654148101807\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8990805149078369\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4909998178482056\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8992235660552979\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4984447956085205\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8992699980735779\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5394446849822998\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8993960618972778\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5013468265533447\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8995217084884644\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4942786693572998\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 31.392282485961914\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8996308445930481\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5080242156982422\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8997237086296082\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.513548731803894\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.8998795747756958\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.488729476928711\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9000031352043152\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5012997388839722\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.900063157081604\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5319132804870605\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9000756144523621\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5602515935897827\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9001980423927307\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5004605054855347\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9002258777618408\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5349204540252686\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9003632068634033\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4981093406677246\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9004687666893005\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5082201957702637\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 19.521556854248047\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9005270600318909\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5271530151367188\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9006162881851196\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5213667154312134\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9007051587104797\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5138881206512451\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9008246660232544\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4971227645874023\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9008972644805908\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5269551277160645\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.900892436504364\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5642626285552979\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9009800553321838\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5181159973144531\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9010980725288391\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5090603828430176\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9011389017105103\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5507246255874634\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9012408256530762\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5160751342773438\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 34.07014465332031\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9013270735740662\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5142444372177124\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.90142822265625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.506291389465332\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.901498556137085\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.521273136138916\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9015229940414429\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5447291135787964\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9016079902648926\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5141887664794922\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9016472697257996\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5422390699386597\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9017015099525452\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5331196784973145\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.901800811290741\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5156886577606201\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9018394947052002\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.534399390220642\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9019080400466919\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5333280563354492\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 35.15199279785156\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9020063877105713\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.50602126121521\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9021042585372925\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5119000673294067\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9021421074867249\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5401320457458496\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9022095799446106\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5280970335006714\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9022768139839172\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5188205242156982\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9023734331130981\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5109148025512695\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9024697542190552\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.506227731704712\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9025657176971436\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5114787817001343\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9026908278465271\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4993261098861694\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9027859568595886\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5019869804382324\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 24.237428665161133\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9029248952865601\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4903066158294678\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9030192494392395\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5089002847671509\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9030693173408508\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5387530326843262\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9031484127044678\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5128350257873535\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9032272100448608\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.514374017715454\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.90333491563797\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4995306730270386\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9034130573272705\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5240917205810547\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9035054445266724\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5150352716445923\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9036265015602112\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.497514009475708\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9036892652511597\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5224406719207764\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 25.68482780456543\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9037517309188843\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5271079540252686\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9038428068161011\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5222959518432617\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.903933584690094\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5159674882888794\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9040383696556091\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.507533311843872\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9041284322738647\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5157071352005005\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9042468070983887\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4960103034973145\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9043218493461609\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5108897686004639\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9044252038002014\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.50626802444458\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9044569730758667\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5353736877441406\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9045738577842712\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4983476400375366\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 27.063955307006836\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9047045111656189\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4885114431381226\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9048346877098083\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4961655139923096\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9049078822135925\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5171349048614502\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9050090312957764\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5097987651824951\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9051238894462585\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.50510573387146\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9051961302757263\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5255519151687622\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9052401185035706\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5303080081939697\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9053399562835693\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5009926557540894\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9054393768310547\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5034056901931763\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.905566394329071\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.495800256729126\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.127567291259766\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9057068824768066\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.483272910118103\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9057773351669312\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5115346908569336\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9058614373207092\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.500964641571045\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.905972957611084\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5058387517929077\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9060978889465332\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4865341186523438\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9061533808708191\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5193787813186646\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9061948657035828\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5292344093322754\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9062087535858154\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5370228290557861\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.906359851360321\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4716073274612427\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9064281582832336\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5220370292663574\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.530780792236328\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9065099358558655\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5217912197113037\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9065641164779663\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5264045000076294\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9066454172134399\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5106091499328613\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9066991209983826\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5375235080718994\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9068070650100708\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4985023736953735\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9068603515625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5291874408721924\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9069405198097229\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5116610527038574\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9070339798927307\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4953598976135254\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9071270227432251\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5061832666397095\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9072737097740173\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4784317016601562\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.201433181762695\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9073526263237\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.515244722366333\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9074178338050842\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5198858976364136\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9074828624725342\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5182409286499023\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.907547652721405\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.513153314590454\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9076122045516968\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5228040218353271\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9076365232467651\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5324734449386597\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9076607823371887\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5399951934814453\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9077513813972473\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5034233331680298\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9078549742698669\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4901572465896606\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9079316854476929\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.514259696006775\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.57754898071289\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9080213904380798\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.505906343460083\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9080843329429626\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5103107690811157\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9081603288650513\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5050885677337646\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9082096815109253\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5207350254058838\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9082720875740051\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5264620780944824\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9083210825920105\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.530874252319336\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9084354043006897\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4909559488296509\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9084839820861816\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5258148908615112\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9085585474967957\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5077210664749146\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9086588621139526\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4911476373672485\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 21.048294067382812\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9087198376655579\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5180671215057373\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9087936282157898\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5062782764434814\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9089059829711914\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4916884899139404\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9089921116828918\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5023387670516968\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9090650677680969\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5099146366119385\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9091377854347229\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.513851523399353\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9092360138893127\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.49747633934021\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9093210101127625\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5104577541351318\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9093929529190063\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.512800931930542\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9095031023025513\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4883378744125366\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 36.29549789428711\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.909600019454956\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4978678226470947\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9096328616142273\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5349106788635254\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9097293019294739\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.490828037261963\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9098635911941528\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4808276891708374\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9098831415176392\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5438024997711182\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9099152684211731\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.529611587524414\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9099599719047546\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5367066860198975\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9100424647331238\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5038758516311646\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9100868105888367\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5199675559997559\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.91013103723526\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.525363564491272\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 35.266639709472656\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9102380275726318\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4901964664459229\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9102818369865417\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5359702110290527\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9103255271911621\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5217951536178589\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9103816151618958\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5226030349731445\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.910462498664856\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5108375549316406\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9105556011199951\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.498539924621582\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.910561203956604\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5361418724060059\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9106538891792297\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.499122142791748\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9106965661048889\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.523796796798706\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9107763171195984\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.510549783706665\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 25.240617752075195\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.910855770111084\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.517549991607666\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9109350442886353\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.504936695098877\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9109646677970886\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5348531007766724\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9109695553779602\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5386786460876465\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.91103595495224\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5024558305740356\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9110898375511169\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5170283317565918\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9111435413360596\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5198614597320557\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9111971259117126\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5199933052062988\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9112871885299683\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4945108890533447\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9113525152206421\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5027029514312744\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 27.613780975341797\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9113689661026001\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.535607099533081\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9114096760749817\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5118930339813232\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.911450207233429\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5220246315002441\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9115270972251892\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.506951093673706\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.911579430103302\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5131080150604248\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.91163170337677\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.51833176612854\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9116595983505249\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.527794599533081\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9117597341537476\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4978320598602295\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9118234515190125\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5098555088043213\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.911886990070343\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.505578875541687\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.818273544311523\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9119983911514282\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4819743633270264\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9120854139328003\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4922376871109009\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9121602177619934\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5028371810913086\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9122347831726074\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4977877140045166\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.912285327911377\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5129187107086182\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.912311851978302\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5297998189926147\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9123382568359375\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5388952493667603\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.912412166595459\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.501021385192871\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9124739170074463\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5114686489105225\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9125592112541199\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4988391399383545\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.469482421875\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9126560091972351\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4918566942214966\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9127171635627747\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.512812852859497\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9127663373947144\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.527414321899414\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9128270745277405\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5090389251708984\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.912887692451477\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.504990577697754\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag: \"acc_train\"\n",
      "simple_value: 0.9129598140716553\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.499751329421997\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9129966497421265\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5264177322387695\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.913080096244812\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4993901252746582\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9131048917770386\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5272810459136963\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.913094699382782\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5546839237213135\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.579845428466797\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.913131058216095\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5161677598953247\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.913213849067688\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4986590147018433\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9132499098777771\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5275793075561523\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9132859110832214\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5270636081695557\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9133680462837219\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.499251365661621\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9134384393692017\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4990391731262207\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9135316610336304\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4872561693191528\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9135439991950989\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5401753187179565\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9135677218437195\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.527454137802124\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9135799407958984\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.537734031677246\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.223264694213867\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9136151075363159\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5205248594284058\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9136959314346313\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5067598819732666\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9137994050979614\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.476212978363037\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9138340353965759\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5155887603759766\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9138686060905457\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.524308681488037\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9139485955238342\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5025966167449951\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9140170216560364\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4961841106414795\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9140511155128479\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5233701467514038\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9141078591346741\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.514676809310913\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9141870737075806\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4930408000946045\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.72572898864746\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9142547249794006\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4979931116104126\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9143221378326416\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5020496845245361\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9143556356430054\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5297060012817383\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.914434015750885\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4895581007003784\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9144896864891052\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5198287963867188\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9145563840866089\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5027109384536743\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9146117568016052\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.509261965751648\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9146221280097961\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.541733741760254\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9146884083747864\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5063313245773315\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9146763682365417\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5541636943817139\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 4.017356872558594\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9147089123725891\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5255874395370483\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9147413372993469\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5198593139648438\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9147959351539612\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5126287937164307\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9148725867271423\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.497397780418396\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9149489998817444\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.503150224685669\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.914980947971344\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5201712846755981\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9150348901748657\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5095586776733398\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9150556325912476\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5327951908111572\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9151203036308289\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5179531574249268\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.915151834487915\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5229378938674927\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 37.22770309448242\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9151942729949951\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5208284854888916\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9152365922927856\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5233217477798462\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9153006672859192\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5027391910552979\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9153426885604858\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5121688842773438\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9154064655303955\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5023810863494873\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9154046177864075\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5443174839019775\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9154790043830872\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4954743385314941\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9155423045158386\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5080313682556152\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9155837297439575\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5177347660064697\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9156575798988342\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4950003623962402\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 37.47102355957031\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9157203435897827\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5030323266983032\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9158046245574951\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4887515306472778\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9158454537391663\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5223336219787598\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9159185290336609\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.501569151878357\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9159482717514038\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5280733108520508\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9159994721412659\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.505399227142334\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.916061282157898\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5141724348068237\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9161551594734192\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4849779605865479\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9161844253540039\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5225746631622314\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9162243008613586\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5123546123504639\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 33.10557174682617\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9162961840629578\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4849250316619873\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9163678288459778\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4953804016113281\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9164072871208191\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5226445198059082\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9164360761642456\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5314708948135376\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9164965748786926\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.500380039215088\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9165782332420349\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4960296154022217\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9166383743286133\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5046679973602295\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9167196154594421\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4880540370941162\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9167688488960266\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.509793996810913\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9168285727500916\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5008490085601807\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 39.455787658691406\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9168775081634521\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5118587017059326\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9169474244117737\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4907777309417725\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9170066714286804\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5088188648223877\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9170761704444885\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.500175952911377\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9171350598335266\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5107479095458984\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9172147512435913\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4876086711883545\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9172732830047607\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5085831880569458\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9172898530960083\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5314255952835083\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9173377156257629\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5128345489501953\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9174166917800903\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.492425560951233\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.387420654296875\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9174954295158386\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4839013814926147\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9175323843955994\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5145971775054932\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9175070524215698\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5518826246261597\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9175750017166138\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4979522228240967\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9176635146141052\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4793776273727417\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9177207350730896\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.502010464668274\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9177778363227844\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.493833065032959\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9178450703620911\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4946608543395996\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.917901873588562\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5007166862487793\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9179584980010986\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5017664432525635\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.453088760375977\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9180046916007996\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5196747779846191\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9180405139923096\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5111907720565796\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9180967211723328\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.500474214553833\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9181528091430664\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5033133029937744\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9181883335113525\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.513930082321167\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9182543158531189\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4909114837646484\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9183303713798523\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4919700622558594\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9183552861213684\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5165588855743408\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9184208512306213\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4956358671188354\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9184861779212952\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5020489692687988\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.401592254638672\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9185412526130676\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5090737342834473\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9186164140701294\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4899556636810303\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9186913967132568\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4863485097885132\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9187156558036804\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5284560918807983\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9187802672386169\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.496976613998413\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9188244938850403\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5184016227722168\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9188988208770752\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.487972378730774\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9189026355743408\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.539921522140503\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9189265370368958\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.523205280303955\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9189603328704834\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5297497510910034\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 31.041624069213867\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.918984055519104\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5214171409606934\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9190376996994019\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4990992546081543\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9190712571144104\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5197930335998535\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9191147089004517\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5067625045776367\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9191779494285583\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4964931011199951\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9192012548446655\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5227127075195312\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9192344546318054\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5173380374908447\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.919287383556366\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5025181770324707\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9193005561828613\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5301085710525513\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9193334579467773\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5156919956207275\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.374359130859375\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.919395923614502\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4918161630630493\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.919399082660675\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5364559888839722\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9194514751434326\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5041694641113281\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9194938540458679\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5117909908294678\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9195558428764343\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5067863464355469\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9196078181266785\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.505194902420044\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9196596741676331\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.504473328590393\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9197211861610413\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4962944984436035\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9197825193405151\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4997484683990479\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9198632836341858\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4791285991668701\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 16.924541473388672\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.919934093952179\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.485913634300232\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9199656844139099\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5262384414672852\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9200167059898376\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4999010562896729\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9200676083564758\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4966503381729126\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9201183915138245\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.500828742980957\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9201496839523315\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5170962810516357\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9202002286911011\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5076801776885986\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.920231282711029\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5163346529006958\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9202622771263123\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5181422233581543\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9203125238418579\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5049183368682861\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 32.91325378417969\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9203625917434692\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5025699138641357\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9204414486885071\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4806339740753174\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.920462429523468\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.532616138458252\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9205121397972107\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5060882568359375\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9205330014228821\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5313405990600586\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9205729365348816\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.504799723625183\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9206032156944275\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5134451389312744\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9206333756446838\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.51731538772583\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9206826090812683\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.501043677330017\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9207126498222351\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.519212245941162\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 26.93067169189453\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9207521080970764\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5160701274871826\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.920791506767273\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5169397592544556\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.920840322971344\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4972479343414307\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9208889603614807\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.513418436050415\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9209374785423279\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5050386190414429\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9209859371185303\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5032994747161865\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9210531115531921\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4863612651824951\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9211012721061707\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5070509910583496\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9211682081222534\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.491461992263794\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9212443232536316\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4842326641082764\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.196584701538086\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9213297367095947\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4774209260940552\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.921339750289917\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5309767723083496\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9213873147964478\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5029221773147583\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9214253425598145\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5124202966690063\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9214352369308472\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5321216583251953\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9214637875556946\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5112593173980713\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.921501636505127\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5106759071350098\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9215487241744995\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.503695011138916\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9216142892837524\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4872229099273682\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9216703772544861\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4940296411514282\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.66732406616211\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9216985106468201\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5211231708526611\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9217451214790344\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5006601810455322\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9218101501464844\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4887723922729492\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9218564629554749\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5036342144012451\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9219119548797607\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4920198917388916\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9219673275947571\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4958088397979736\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9220133423805237\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4949209690093994\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9220500588417053\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5021882057189941\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9220866560935974\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5145151615142822\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9221231341362\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5095138549804688\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 27.939990997314453\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9221596121788025\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5100293159484863\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9221867918968201\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5159704685211182\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9222322106361389\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5058176517486572\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9222500920295715\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.523348331451416\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.922295331954956\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.496742844581604\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9223222136497498\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5174916982650757\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9223946332931519\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4797539710998535\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9224122166633606\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5265252590179443\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9224388599395752\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5123531818389893\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9224927425384521\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.492801308631897\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 21.278764724731445\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9225646257400513\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4790412187576294\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9226272702217102\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4979784488677979\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9226897358894348\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4863687753677368\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9227069020271301\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5229159593582153\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9227691292762756\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4870473146438599\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9228132367134094\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5169823169708252\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9228481650352478\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5086112022399902\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.922838032245636\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5349111557006836\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9229089021682739\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4816007614135742\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9229615926742554\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4987764358520508\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 23.75190544128418\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9229872226715088\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5117337703704834\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9230038523674011\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5248874425888062\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9230741858482361\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4824039936065674\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9230906963348389\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5271466970443726\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9230892658233643\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5303221940994263\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9231146574020386\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5133192539215088\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9231399893760681\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5099718570709229\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.923183023929596\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.505539894104004\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9232348799705505\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4962046146392822\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9233043193817139\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4792777299880981\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.726133346557617\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.923320472240448\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5201761722564697\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9233453869819641\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5134512186050415\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9233525395393372\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.521131157875061\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9234039187431335\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4936827421188354\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9234463572502136\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4956374168395996\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9234886169433594\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5072883367538452\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9235220551490784\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5118316411972046\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9235641956329346\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.500604510307312\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.923615038394928\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.496241569519043\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9236745238304138\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4893832206726074\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.408493041992188\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9237338900566101\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4851279258728027\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9237755537033081\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4964227676391602\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9238172173500061\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5004069805145264\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9238499999046326\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5142110586166382\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9238826632499695\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5184168815612793\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9239153265953064\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.507930040359497\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.923956573009491\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5075736045837402\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9239977598190308\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4983915090560913\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9240388870239258\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5031957626342773\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9240451455116272\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.532362699508667\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 18.643505096435547\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9240860939025879\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4954105615615845\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9241442680358887\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4848225116729736\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9241936802864075\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4994779825210571\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9242516160011292\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4947080612182617\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9243007302284241\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4960548877716064\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9243670701980591\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.47736656665802\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9243729114532471\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.53533136844635\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9243959784507751\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.518808126449585\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9244276285171509\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5137054920196533\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.92448490858078\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.485909342765808\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 37.61174774169922\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9245249032974243\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5060242414474487\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9245819449424744\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4916882514953613\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9246046543121338\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.511041522026062\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9246529936790466\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4966981410980225\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9247011542320251\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4923515319824219\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9247322082519531\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5190694332122803\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9247375726699829\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5323615074157715\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9247515201568604\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5165338516235352\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.924799382686615\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.495413899421692\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.924855649471283\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4853887557983398\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 33.25421142578125\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9248863458633423\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5034162998199463\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.924908459186554\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.513395071029663\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9249559640884399\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4925293922424316\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9250034093856812\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5001907348632812\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9250253438949585\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5160466432571411\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9250556826591492\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5145766735076904\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9251028299331665\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.498136281967163\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9251329898834229\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5124120712280273\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9251799583435059\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4978537559509277\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9252268075942993\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4911658763885498\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.586149215698242\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9252567887306213\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5080060958862305\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.925311803817749\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4886770248413086\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9253667593002319\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4893802404403687\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9254215955734253\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.483856201171875\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9254595637321472\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5064330101013184\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9254891276359558\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5110265016555786\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9255519509315491\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4848510026931763\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.925564706325531\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5237692594528198\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9256106615066528\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.495476484298706\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9256399869918823\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5118358135223389\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 27.306062698364258\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9256691932678223\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5015203952789307\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9256983399391174\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5034434795379639\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9257522821426392\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4825925827026367\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9257895350456238\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5006884336471558\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9258184432983398\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5127068758010864\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9258638620376587\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4979780912399292\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.925917387008667\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4868723154067993\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9259707927703857\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4822371006011963\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9259911775588989\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5184394121170044\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9260197281837463\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5085887908935547\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 28.331430435180664\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9260892868041992\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4700534343719482\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9261094927787781\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5175659656524658\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9261542558670044\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4919967651367188\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9261988997459412\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4935097694396973\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9262270927429199\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5030403137207031\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9262715578079224\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.490437626838684\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9262996315956116\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5089095830917358\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9263684153556824\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4701714515686035\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.926388144493103\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.517064094543457\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9264241456985474\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.502380609512329\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.5977783203125\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9264844655990601\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4815857410430908\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.926536500453949\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4835494756698608\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9265884757041931\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4896636009216309\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9266079068183899\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5091214179992676\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.926643431186676\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4995681047439575\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9266546964645386\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5197248458862305\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9266901612281799\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5073853731155396\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9267497658729553\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4826440811157227\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9267850518226624\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4967732429504395\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9267880320549011\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5341343879699707\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 30.385822296142578\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9268312454223633\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.499337911605835\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9268583059310913\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5115667581558228\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9268853068351746\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.510969638824463\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9269042015075684\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.513427495956421\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9269631505012512\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4778995513916016\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9269819259643555\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5152184963226318\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9270086884498596\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5089770555496216\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9270513653755188\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4895973205566406\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9270939826965332\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.490553617477417\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.927144467830658\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4874262809753418\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 29.068166732788086\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9271629452705383\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5256032943725586\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9271655678749084\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5273165702819824\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.927191972732544\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5071470737457275\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9271944761276245\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5286965370178223\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9272208213806152\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5099135637283325\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9272629022598267\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4942702054977417\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.927249550819397\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5390827655792236\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9272836446762085\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.505412220954895\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9272939562797546\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5178130865097046\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9273200631141663\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5116087198257446\n",
      "\n",
      "tag: \"global_step/sec\"\n",
      "simple_value: 23.678667068481445\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9273461103439331\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.506391167640686\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9273799657821655\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4980614185333252\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9274137616157532\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4979528188705444\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.927447497844696\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.502733826637268\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9274811744689941\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5027469396591187\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.927538275718689\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4821503162384033\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9275639653205872\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5047630071640015\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9275895357131958\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5066184997558594\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9276151061058044\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.5162091255187988\n",
      "\n",
      "tag: \"acc_train\"\n",
      "simple_value: 0.9276718497276306\n",
      "\n",
      "tag: \"loss\"\n",
      "simple_value: 1.4747763872146606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for e in tf.train.summary_iterator('/tmp/mnist_convnet_model/events.out.tfevents.1553025053.Fabien-Tarrades-MacBook-Pro.local'):\n",
    "for e in tf.train.summary_iterator('results/Models/Mnist/tf_1_12/estimator/ckpt/events.out.tfevents.1553024123.Fabien-Tarrades-MacBook-Pro.local'):\n",
    "    for v in e.summary.value:\n",
    "        #if v.tag == 'accuracy':\n",
    "        #print(v.simple_value)\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import numpy as np\n",
    "\n",
    "def load_data_tensorboard(path):\n",
    "    event_acc = event_accumulator.EventAccumulator(path)\n",
    "    event_acc.Reload()\n",
    "    data = {}\n",
    "    \n",
    "    print('tag',event_acc.Tags())\n",
    "    \n",
    "    for tag in sorted(event_acc.Tags()[\"scalars\"]):\n",
    "        x, y = [], []\n",
    "        for scalar_event in event_acc.Scalars(tag):\n",
    "            x.append(scalar_event.step)\n",
    "            y.append(scalar_event.value)\n",
    "        data[tag] = (np.asarray(x), np.asarray(y))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Opening a record reader pointing at /tmp/mnist_convnet_model/events.out.tfevents.1553025053.Fabien-Tarrades-MacBook-Pro.local\n",
      "DEBUG:tensorflow:Loading events from /tmp/mnist_convnet_model/events.out.tfevents.1553025053.Fabien-Tarrades-MacBook-Pro.local\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "DEBUG:tensorflow:Cannot read more events: Read less bytes than requested\n",
      "DEBUG:tensorflow:No more events in /tmp/mnist_convnet_model/events.out.tfevents.1553025053.Fabien-Tarrades-MacBook-Pro.local\n",
      "INFO:tensorflow:No path found after /tmp/mnist_convnet_model/events.out.tfevents.1553025053.Fabien-Tarrades-MacBook-Pro.local\n",
      "tag {'images': [], 'audio': [], 'histograms': [], 'scalars': ['enqueue_input/queue/enqueue_input/random_shuffle_queuefraction_over_250_of_750_full', 'loss', 'global_step/sec'], 'distributions': [], 'tensors': [], 'graph': True, 'meta_graph': True, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "history=load_data_tensorboard('/tmp/mnist_convnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Opening a record reader pointing at results/Models/Mnist/tf_1_12/estimator/ckpt//eval/events.out.tfevents.1553024131.Fabien-Tarrades-MacBook-Pro.local\n",
      "DEBUG:tensorflow:Loading events from results/Models/Mnist/tf_1_12/estimator/ckpt//eval/events.out.tfevents.1553024131.Fabien-Tarrades-MacBook-Pro.local\n",
      "DEBUG:tensorflow:Cannot read more events: Read less bytes than requested\n",
      "DEBUG:tensorflow:No more events in results/Models/Mnist/tf_1_12/estimator/ckpt//eval/events.out.tfevents.1553024131.Fabien-Tarrades-MacBook-Pro.local\n",
      "INFO:tensorflow:No path found after results/Models/Mnist/tf_1_12/estimator/ckpt//eval/events.out.tfevents.1553024131.Fabien-Tarrades-MacBook-Pro.local\n",
      "tag {'images': [], 'audio': [], 'histograms': [], 'scalars': ['accuracy', 'loss'], 'distributions': [], 'tensors': ['checkpoint_path'], 'graph': True, 'meta_graph': True, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "history=load_data_tensorboard(FLAGS.model_dir+'/eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Opening a record reader pointing at results/Models/Mnist/tf_1_12/estimator/ckpt/events.out.tfevents.1553024123.Fabien-Tarrades-MacBook-Pro.local\n",
      "DEBUG:tensorflow:Loading events from results/Models/Mnist/tf_1_12/estimator/ckpt/events.out.tfevents.1553024123.Fabien-Tarrades-MacBook-Pro.local\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "DEBUG:tensorflow:Cannot read more events: Read less bytes than requested\n",
      "DEBUG:tensorflow:No more events in results/Models/Mnist/tf_1_12/estimator/ckpt/events.out.tfevents.1553024123.Fabien-Tarrades-MacBook-Pro.local\n",
      "INFO:tensorflow:No path found after results/Models/Mnist/tf_1_12/estimator/ckpt/events.out.tfevents.1553024123.Fabien-Tarrades-MacBook-Pro.local\n",
      "{'acc_train': (array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
      "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
      "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
      "         34,   35,   36,   37,   38,   39,   40,   41,   42,   43,   44,\n",
      "         45,   46,   47,   48,   49,   50,   51,   52,   53,   54,   55,\n",
      "         56,   57,   58,   59,   60,   61,   62,   63,   64,   65,   66,\n",
      "         67,   68,   69,   70,   71,   72,   73,   74,   75,   76,   77,\n",
      "         78,   79,   80,   81,   82,   83,   84,   85,   86,   87,   88,\n",
      "         89,   90,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
      "        100,  101,  102,  103,  104,  105,  106,  107,  108,  109,  110,\n",
      "        111,  112,  113,  114,  115,  116,  117,  118,  119,  120,  121,\n",
      "        122,  123,  124,  125,  126,  127,  128,  129,  130,  131,  132,\n",
      "        133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
      "        144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,\n",
      "        155,  156,  157,  158,  159,  160,  161,  162,  163,  164,  165,\n",
      "        166,  167,  168,  169,  170,  171,  172,  173,  174,  175,  176,\n",
      "        177,  178,  179,  180,  181,  182,  183,  184,  185,  186,  187,\n",
      "        188,  189,  190,  191,  192,  193,  194,  195,  196,  197,  198,\n",
      "        199,  200,  201,  202,  203,  204,  205,  206,  207,  208,  209,\n",
      "        210,  211,  212,  213,  214,  215,  216,  217,  218,  219,  220,\n",
      "        221,  222,  223,  224,  225,  226,  227,  228,  229,  230,  231,\n",
      "        232,  233,  234,  235,  236,  237,  238,  239,  240,  241,  242,\n",
      "        243,  244,  245,  246,  247,  248,  249,  250,  251,  252,  253,\n",
      "        254,  255,  256,  257,  258,  259,  260,  261,  262,  263,  264,\n",
      "        265,  266,  267,  268,  269,  270,  271,  272,  273,  274,  275,\n",
      "        276,  277,  278,  279,  280,  281,  282,  283,  284,  285,  286,\n",
      "        287,  288,  289,  290,  291,  292,  293,  294,  295,  296,  297,\n",
      "        298,  299,  300,  301,  302,  303,  304,  305,  306,  307,  308,\n",
      "        309,  310,  311,  312,  313,  314,  315,  316,  317,  318,  319,\n",
      "        320,  321,  322,  323,  324,  325,  326,  327,  328,  329,  330,\n",
      "        331,  332,  333,  334,  335,  336,  337,  338,  339,  340,  341,\n",
      "        342,  343,  344,  345,  346,  347,  348,  349,  350,  351,  352,\n",
      "        353,  354,  355,  356,  357,  358,  359,  360,  361,  362,  363,\n",
      "        364,  365,  366,  367,  368,  369,  370,  371,  372,  373,  374,\n",
      "        375,  376,  377,  378,  379,  380,  381,  382,  383,  384,  385,\n",
      "        386,  387,  388,  389,  390,  391,  392,  393,  394,  395,  396,\n",
      "        397,  398,  399,  400,  401,  402,  403,  404,  405,  406,  407,\n",
      "        408,  409,  410,  411,  412,  413,  414,  415,  416,  417,  418,\n",
      "        419,  420,  421,  422,  423,  424,  425,  426,  427,  428,  429,\n",
      "        430,  431,  432,  433,  434,  435,  436,  437,  438,  439,  440,\n",
      "        441,  442,  443,  444,  445,  446,  447,  448,  449,  450,  451,\n",
      "        452,  453,  454,  455,  456,  457,  458,  459,  460,  461,  462,\n",
      "        463,  464,  465,  466,  467,  468,  469,  470,  471,  472,  473,\n",
      "        474,  475,  476,  477,  478,  479,  480,  481,  482,  483,  484,\n",
      "        485,  486,  487,  488,  489,  490,  491,  492,  493,  494,  495,\n",
      "        496,  497,  498,  499,  500,  501,  502,  503,  504,  505,  506,\n",
      "        507,  508,  509,  510,  511,  512,  513,  514,  515,  516,  517,\n",
      "        518,  519,  520,  521,  522,  523,  524,  525,  526,  527,  528,\n",
      "        529,  530,  531,  532,  533,  534,  535,  536,  537,  538,  539,\n",
      "        540,  541,  542,  543,  544,  545,  546,  547,  548,  549,  550,\n",
      "        551,  552,  553,  554,  555,  556,  557,  558,  559,  560,  561,\n",
      "        562,  563,  564,  565,  566,  567,  568,  569,  570,  571,  572,\n",
      "        573,  574,  575,  576,  577,  578,  579,  580,  581,  582,  583,\n",
      "        584,  585,  586,  587,  588,  589,  590,  591,  592,  593,  594,\n",
      "        595,  596,  597,  598,  599,  600,  601,  602,  603,  604,  605,\n",
      "        606,  607,  608,  609,  610,  611,  612,  613,  614,  615,  616,\n",
      "        617,  618,  619,  620,  621,  622,  623,  624,  625,  626,  627,\n",
      "        628,  629,  630,  631,  632,  633,  634,  635,  636,  637,  638,\n",
      "        639,  640,  641,  642,  643,  644,  645,  646,  647,  648,  649,\n",
      "        650,  651,  652,  653,  654,  655,  656,  657,  658,  659,  660,\n",
      "        661,  662,  663,  664,  665,  666,  667,  668,  669,  670,  671,\n",
      "        672,  673,  674,  675,  676,  677,  678,  679,  680,  681,  682,\n",
      "        683,  684,  685,  686,  687,  688,  689,  690,  691,  692,  693,\n",
      "        694,  695,  696,  697,  698,  699,  700,  701,  702,  703,  704,\n",
      "        705,  706,  707,  708,  709,  710,  711,  712,  713,  714,  715,\n",
      "        716,  717,  718,  719,  720,  721,  722,  723,  724,  725,  726,\n",
      "        727,  728,  729,  730,  731,  732,  733,  734,  735,  736,  737,\n",
      "        738,  739,  740,  741,  742,  743,  744,  745,  746,  747,  748,\n",
      "        749,  750,  751,  752,  753,  754,  755,  756,  757,  758,  759,\n",
      "        760,  761,  762,  763,  764,  765,  766,  767,  768,  769,  770,\n",
      "        771,  772,  773,  774,  775,  776,  777,  778,  779,  780,  781,\n",
      "        782,  783,  784,  785,  786,  787,  788,  789,  790,  791,  792,\n",
      "        793,  794,  795,  796,  797,  798,  799,  800,  801,  802,  803,\n",
      "        804,  805,  806,  807,  808,  809,  810,  811,  812,  813,  814,\n",
      "        815,  816,  817,  818,  819,  820,  821,  822,  823,  824,  825,\n",
      "        826,  827,  828,  829,  830,  831,  832,  833,  834,  835,  836,\n",
      "        837,  838,  839,  840,  841,  842,  843,  844,  845,  846,  847,\n",
      "        848,  849,  850,  851,  852,  853,  854,  855,  856,  857,  858,\n",
      "        859,  860,  861,  862,  863,  864,  865,  866,  867,  868,  869,\n",
      "        870,  871,  872,  873,  874,  875,  876,  877,  878,  879,  880,\n",
      "        881,  882,  883,  884,  885,  886,  887,  888,  889,  890,  891,\n",
      "        892,  893,  894,  895,  896,  897,  898,  899,  900,  901,  902,\n",
      "        903,  904,  905,  906,  907,  908,  909,  910,  911,  912,  913,\n",
      "        914,  915,  916,  917,  918,  919,  920,  921,  922,  923,  924,\n",
      "        925,  926,  927,  928,  929,  930,  931,  932,  933,  934,  935,\n",
      "        936,  937,  938,  939,  940,  941,  942,  943,  944,  945,  946,\n",
      "        947,  948,  949,  950,  951,  952,  953,  954,  955,  956,  957,\n",
      "        958,  959,  960,  961,  962,  963,  964,  965,  966,  967,  968,\n",
      "        969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
      "        980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,\n",
      "        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000]), array([0.1640625 , 0.1875    , 0.2421875 , 0.29882812, 0.34062499,\n",
      "       0.37890625, 0.40513393, 0.42675781, 0.44184029, 0.45078126,\n",
      "       0.46164772, 0.46940103, 0.48137018, 0.4888393 , 0.50052083,\n",
      "       0.50732422, 0.51976103, 0.52560765, 0.53125   , 0.54023439,\n",
      "       0.55394346, 0.56178975, 0.5692935 , 0.57910156, 0.5859375 ,\n",
      "       0.59194714, 0.59895831, 0.60658485, 0.61341596, 0.61770833,\n",
      "       0.62298387, 0.62988281, 0.63636363, 0.64338237, 0.64508927,\n",
      "       0.64930558, 0.65392739, 0.65645558, 0.65925479, 0.66347659,\n",
      "       0.66673017, 0.67038691, 0.67369187, 0.67755681, 0.6800347 ,\n",
      "       0.68308425, 0.68567157, 0.68880206, 0.69116712, 0.69390625,\n",
      "       0.69730395, 0.70087141, 0.70386201, 0.70558447, 0.70852274,\n",
      "       0.71149552, 0.71367872, 0.71470904, 0.71729344, 0.71888024,\n",
      "       0.72118342, 0.72341228, 0.72606647, 0.72802734, 0.73028845,\n",
      "       0.73129737, 0.73274255, 0.73460478, 0.73675269, 0.73917413,\n",
      "       0.74075705, 0.7421875 , 0.74486303, 0.74683279, 0.74885416,\n",
      "       0.74969161, 0.75192773, 0.75380611, 0.75534022, 0.75634766,\n",
      "       0.75810188, 0.75962269, 0.76101279, 0.76264882, 0.76433825,\n",
      "       0.76617008, 0.76769036, 0.76899856, 0.77036518, 0.77213544,\n",
      "       0.77283657, 0.77479619, 0.77620965, 0.77767622, 0.7786184 ,\n",
      "       0.77954102, 0.78076673, 0.78180802, 0.78306502, 0.78445315,\n",
      "       0.78596842, 0.78707105, 0.78830403, 0.78951323, 0.79032737,\n",
      "       0.7915684 , 0.79220212, 0.79318577, 0.79415137, 0.79509944,\n",
      "       0.7964527 , 0.79785156, 0.79929483, 0.80009592, 0.80088317,\n",
      "       0.80185884, 0.80261755, 0.80382681, 0.80442488, 0.80514324,\n",
      "       0.80630165, 0.80686474, 0.8078633 , 0.80834174, 0.80900002,\n",
      "       0.80977184, 0.81040847, 0.81121826, 0.81219721, 0.8125    ,\n",
      "       0.81345421, 0.81386125, 0.81461465, 0.81547344, 0.81579864,\n",
      "       0.81646371, 0.816948  , 0.8175385 , 0.81845772, 0.81914061,\n",
      "       0.81964761, 0.82042253, 0.821132  , 0.82145184, 0.82230604,\n",
      "       0.82309502, 0.82382017, 0.82432431, 0.82508391, 0.82541668,\n",
      "       0.82615894, 0.82673723, 0.82725692, 0.8276177 , 0.82797378,\n",
      "       0.8286258 , 0.82921976, 0.82960838, 0.83013952, 0.83056641,\n",
      "       0.83098799, 0.83121145, 0.83167177, 0.83169776, 0.83214962,\n",
      "       0.83283132, 0.83355165, 0.83384484, 0.83450443, 0.83511031,\n",
      "       0.83543491, 0.83589208, 0.83625358, 0.83656609, 0.83709824,\n",
      "       0.83766866, 0.83836514, 0.83865869, 0.83899266, 0.8394531 ,\n",
      "       0.83999485, 0.84035885, 0.84084702, 0.84116   , 0.84176522,\n",
      "       0.84223789, 0.84270555, 0.8432098 , 0.84333664, 0.84362662,\n",
      "       0.84383178, 0.84427899, 0.84460008, 0.84479702, 0.84515226,\n",
      "       0.84562343, 0.84605014, 0.84627527, 0.84669441, 0.84707034,\n",
      "       0.84748137, 0.84792697, 0.84821427, 0.84842217, 0.84885669,\n",
      "       0.84902155, 0.84937352, 0.84953427, 0.84965611, 0.84992558,\n",
      "       0.85026658, 0.85053068, 0.85090226, 0.85134345, 0.85174417,\n",
      "       0.85210502, 0.85239053, 0.85245842, 0.8526684 , 0.85301846,\n",
      "       0.85322398, 0.85353321, 0.85390973, 0.85424805, 0.85444444,\n",
      "       0.8547774 , 0.85496974, 0.85519463, 0.85538346, 0.85577446,\n",
      "       0.85595912, 0.85624325, 0.85669261, 0.85710472, 0.85734707,\n",
      "       0.85752118, 0.85762793, 0.85799634, 0.85823089, 0.85862631,\n",
      "       0.8589536 , 0.85921359, 0.85960007, 0.85985529, 0.86014032,\n",
      "       0.86026424, 0.86045039, 0.86072958, 0.86103791, 0.86109376,\n",
      "       0.86139816, 0.86179316, 0.862185  , 0.86251229, 0.86274511,\n",
      "       0.86312866, 0.86329645, 0.86355376, 0.86395997, 0.86412257,\n",
      "       0.86446363, 0.86486167, 0.86516756, 0.86538231, 0.86547762,\n",
      "       0.86577773, 0.8660171 , 0.86634213, 0.86651951, 0.86672455,\n",
      "       0.86701453, 0.86710131, 0.86735922, 0.86764371, 0.86784089,\n",
      "       0.86809331, 0.86828744, 0.86856455, 0.86869961, 0.8689453 ,\n",
      "       0.86913365, 0.86945921, 0.86975485, 0.86982834, 0.87001097,\n",
      "       0.87011033, 0.87034518, 0.87052411, 0.87083691, 0.87106681,\n",
      "       0.87132198, 0.87154859, 0.87174702, 0.8720504 , 0.87227225,\n",
      "       0.87246621, 0.87263256, 0.87279785, 0.87288356, 0.87315106,\n",
      "       0.87336481, 0.87357718, 0.87389129, 0.87410051, 0.87418032,\n",
      "       0.87436175, 0.87454194, 0.87456882, 0.87472188, 0.87494957,\n",
      "       0.87515074, 0.87527543, 0.87552416, 0.87572151, 0.87576884,\n",
      "       0.8759889 , 0.8761583 , 0.87640035, 0.87659186, 0.87673342,\n",
      "       0.87694705, 0.87725639, 0.87753969, 0.87774885, 0.87798077,\n",
      "       0.87813938, 0.87832093, 0.87852514, 0.87868065, 0.87895358,\n",
      "       0.87917769, 0.87928277, 0.8793872 , 0.87949103, 0.8795709 ,\n",
      "       0.87969679, 0.87996107, 0.88015437, 0.88025445, 0.88042277,\n",
      "       0.88054436, 0.88075656, 0.88094479, 0.88104105, 0.88113678,\n",
      "       0.88129967, 0.88157421, 0.88171244, 0.8818723 , 0.88203126,\n",
      "       0.88214475, 0.88232422, 0.88245839, 0.88263595, 0.88268048,\n",
      "       0.88292223, 0.88307512, 0.88331443, 0.88337833, 0.88352865,\n",
      "       0.88376474, 0.88391316, 0.88399619, 0.88410026, 0.88422519,\n",
      "       0.88441342, 0.88466454, 0.88487178, 0.88503557, 0.88513511,\n",
      "       0.88525522, 0.88541669, 0.88559818, 0.88575786, 0.88589585,\n",
      "       0.88613695, 0.88627321, 0.88640875, 0.88650233, 0.88657486,\n",
      "       0.88674951, 0.88684148, 0.88689214, 0.88702393, 0.88719559,\n",
      "       0.88730568, 0.88751614, 0.88760471, 0.8877129 , 0.88788062,\n",
      "       0.88802749, 0.88815367, 0.88829917, 0.88844383, 0.88858783,\n",
      "       0.88871133, 0.88883424, 0.88897616, 0.88913691, 0.88917971,\n",
      "       0.88930017, 0.88938123, 0.88953942, 0.88969678, 0.88991129,\n",
      "       0.89002848, 0.89014512, 0.89028031, 0.89043397, 0.89045352,\n",
      "       0.89058697, 0.89075774, 0.89094657, 0.89104015, 0.89118975,\n",
      "       0.89133865, 0.89135569, 0.89146608, 0.8916505 , 0.89166665,\n",
      "       0.89160854, 0.89180982, 0.89197326, 0.89204377, 0.89211398,\n",
      "       0.89214718, 0.8922168 , 0.89237732, 0.89253718, 0.89267808,\n",
      "       0.89276391, 0.89288557, 0.89302468, 0.89325315, 0.89344466,\n",
      "       0.89356363, 0.89350331, 0.89365727, 0.89382833, 0.89396304,\n",
      "       0.8940618 , 0.89419544, 0.89438134, 0.89451367, 0.8945927 ,\n",
      "       0.89474148, 0.89481962, 0.89498466, 0.89507931, 0.89515626,\n",
      "       0.89526749, 0.89532632, 0.89548838, 0.89556372, 0.8956731 ,\n",
      "       0.89576483, 0.8959074 , 0.89598119, 0.89612269, 0.89622962,\n",
      "       0.89633608, 0.89644212, 0.89653081, 0.89660221, 0.89669019,\n",
      "       0.89679456, 0.8968817 , 0.89691842, 0.89707154, 0.89719081,\n",
      "       0.89734274, 0.89746094, 0.89756209, 0.89754748, 0.89768094,\n",
      "       0.8978138 , 0.89788061, 0.89802891, 0.89817655, 0.89830726,\n",
      "       0.8984375 , 0.89853477, 0.89866394, 0.89877647, 0.89893687,\n",
      "       0.89908051, 0.89922357, 0.89927   , 0.89939606, 0.89952171,\n",
      "       0.89963084, 0.89972371, 0.89987957, 0.90000314, 0.90006316,\n",
      "       0.90007561, 0.90019804, 0.90022588, 0.90036321, 0.90046877,\n",
      "       0.90052706, 0.90061629, 0.90070516, 0.90082467, 0.90089726,\n",
      "       0.90089244, 0.90098006, 0.90109807, 0.9011389 , 0.90124083,\n",
      "       0.90132707, 0.90142822, 0.90149856, 0.90152299, 0.90160799,\n",
      "       0.90164727, 0.90170151, 0.90180081, 0.90183949, 0.90190804,\n",
      "       0.90200639, 0.90210426, 0.90214211, 0.90220958, 0.90227681,\n",
      "       0.90237343, 0.90246975, 0.90256572, 0.90269083, 0.90278596,\n",
      "       0.9029249 , 0.90301925, 0.90306932, 0.90314841, 0.90322721,\n",
      "       0.90333492, 0.90341306, 0.90350544, 0.9036265 , 0.90368927,\n",
      "       0.90375173, 0.90384281, 0.90393358, 0.90403837, 0.90412843,\n",
      "       0.90424681, 0.90432185, 0.9044252 , 0.90445697, 0.90457386,\n",
      "       0.90470451, 0.90483469, 0.90490788, 0.90500903, 0.90512389,\n",
      "       0.90519613, 0.90524012, 0.90533996, 0.90543938, 0.90556639,\n",
      "       0.90570688, 0.90577734, 0.90586144, 0.90597296, 0.90609789,\n",
      "       0.90615338, 0.90619487, 0.90620875, 0.90635985, 0.90642816,\n",
      "       0.90650994, 0.90656412, 0.90664542, 0.90669912, 0.90680707,\n",
      "       0.90686035, 0.90694052, 0.90703398, 0.90712702, 0.90727371,\n",
      "       0.90735263, 0.90741783, 0.90748286, 0.90754765, 0.9076122 ,\n",
      "       0.90763652, 0.90766078, 0.90775138, 0.90785497, 0.90793169,\n",
      "       0.90802139, 0.90808433, 0.90816033, 0.90820968, 0.90827209,\n",
      "       0.90832108, 0.9084354 , 0.90848398, 0.90855855, 0.90865886,\n",
      "       0.90871984, 0.90879363, 0.90890598, 0.90899211, 0.90906507,\n",
      "       0.90913779, 0.90923601, 0.90932101, 0.90939295, 0.9095031 ,\n",
      "       0.90960002, 0.90963286, 0.9097293 , 0.90986359, 0.90988314,\n",
      "       0.90991527, 0.90995997, 0.91004246, 0.91008681, 0.91013104,\n",
      "       0.91023803, 0.91028184, 0.91032553, 0.91038162, 0.9104625 ,\n",
      "       0.9105556 , 0.9105612 , 0.91065389, 0.91069657, 0.91077632,\n",
      "       0.91085577, 0.91093504, 0.91096467, 0.91096956, 0.91103595,\n",
      "       0.91108984, 0.91114354, 0.91119713, 0.91128719, 0.91135252,\n",
      "       0.91136897, 0.91140968, 0.91145021, 0.9115271 , 0.91157943,\n",
      "       0.9116317 , 0.9116596 , 0.91175973, 0.91182345, 0.91188699,\n",
      "       0.91199839, 0.91208541, 0.91216022, 0.91223478, 0.91228533,\n",
      "       0.91231185, 0.91233826, 0.91241217, 0.91247392, 0.91255921,\n",
      "       0.91265601, 0.91271716, 0.91276634, 0.91282707, 0.91288769,\n",
      "       0.91295981, 0.91299665, 0.9130801 , 0.91310489, 0.9130947 ,\n",
      "       0.91313106, 0.91321385, 0.91324991, 0.91328591, 0.91336805,\n",
      "       0.91343844, 0.91353166, 0.913544  , 0.91356772, 0.91357994,\n",
      "       0.91361511, 0.91369593, 0.91379941, 0.91383404, 0.91386861,\n",
      "       0.9139486 , 0.91401702, 0.91405112, 0.91410786, 0.91418707,\n",
      "       0.91425472, 0.91432214, 0.91435564, 0.91443402, 0.91448969,\n",
      "       0.91455638, 0.91461176, 0.91462213, 0.91468841, 0.91467637,\n",
      "       0.91470891, 0.91474134, 0.91479594, 0.91487259, 0.914949  ,\n",
      "       0.91498095, 0.91503489, 0.91505563, 0.9151203 , 0.91515183,\n",
      "       0.91519427, 0.91523659, 0.91530067, 0.91534269, 0.91540647,\n",
      "       0.91540462, 0.915479  , 0.9155423 , 0.91558373, 0.91565758,\n",
      "       0.91572034, 0.91580462, 0.91584545, 0.91591853, 0.91594827,\n",
      "       0.91599947, 0.91606128, 0.91615516, 0.91618443, 0.9162243 ,\n",
      "       0.91629618, 0.91636783, 0.91640729, 0.91643608, 0.91649657,\n",
      "       0.91657823, 0.91663837, 0.91671962, 0.91676885, 0.91682857,\n",
      "       0.91687751, 0.91694742, 0.91700667, 0.91707617, 0.91713506,\n",
      "       0.91721475, 0.91727328, 0.91728985, 0.91733772, 0.91741669,\n",
      "       0.91749543, 0.91753238, 0.91750705, 0.917575  , 0.91766351,\n",
      "       0.91772074, 0.91777784, 0.91784507, 0.91790187, 0.9179585 ,\n",
      "       0.91800469, 0.91804051, 0.91809672, 0.91815281, 0.91818833,\n",
      "       0.91825432, 0.91833037, 0.91835529, 0.91842085, 0.91848618,\n",
      "       0.91854125, 0.91861641, 0.9186914 , 0.91871566, 0.91878027,\n",
      "       0.91882449, 0.91889882, 0.91890264, 0.91892654, 0.91896033,\n",
      "       0.91898406, 0.9190377 , 0.91907126, 0.91911471, 0.91917795,\n",
      "       0.91920125, 0.91923445, 0.91928738, 0.91930056, 0.91933346,\n",
      "       0.91939592, 0.91939908, 0.91945148, 0.91949385, 0.91955584,\n",
      "       0.91960782, 0.91965967, 0.91972119, 0.91978252, 0.91986328,\n",
      "       0.91993409, 0.91996568, 0.92001671, 0.92006761, 0.92011839,\n",
      "       0.92014968, 0.92020023, 0.92023128, 0.92026228, 0.92031252,\n",
      "       0.92036259, 0.92044145, 0.92046243, 0.92051214, 0.920533  ,\n",
      "       0.92057294, 0.92060322, 0.92063338, 0.92068261, 0.92071265,\n",
      "       0.92075211, 0.92079151, 0.92084032, 0.92088896, 0.92093748,\n",
      "       0.92098594, 0.92105311, 0.92110127, 0.92116821, 0.92124432,\n",
      "       0.92132974, 0.92133975, 0.92138731, 0.92142534, 0.92143524,\n",
      "       0.92146379, 0.92150164, 0.92154872, 0.92161429, 0.92167038,\n",
      "       0.92169851, 0.92174512, 0.92181015, 0.92185646, 0.92191195,\n",
      "       0.92196733, 0.92201334, 0.92205006, 0.92208666, 0.92212313,\n",
      "       0.92215961, 0.92218679, 0.92223221, 0.92225009, 0.92229533,\n",
      "       0.92232221, 0.92239463, 0.92241222, 0.92243886, 0.92249274,\n",
      "       0.92256463, 0.92262727, 0.92268974, 0.9227069 , 0.92276913,\n",
      "       0.92281324, 0.92284817, 0.92283803, 0.9229089 , 0.92296159,\n",
      "       0.92298722, 0.92300385, 0.92307419, 0.9230907 , 0.92308927,\n",
      "       0.92311466, 0.92313999, 0.92318302, 0.92323488, 0.92330432,\n",
      "       0.92332047, 0.92334539, 0.92335254, 0.92340392, 0.92344636,\n",
      "       0.92348862, 0.92352206, 0.9235642 , 0.92361504, 0.92367452,\n",
      "       0.92373389, 0.92377555, 0.92381722, 0.92385   , 0.92388266,\n",
      "       0.92391533, 0.92395657, 0.92399776, 0.92403889, 0.92404515,\n",
      "       0.92408609, 0.92414427, 0.92419368, 0.92425162, 0.92430073,\n",
      "       0.92436707, 0.92437291, 0.92439598, 0.92442763, 0.92448491,\n",
      "       0.9245249 , 0.92458194, 0.92460465, 0.92465299, 0.92470115,\n",
      "       0.92473221, 0.92473757, 0.92475152, 0.92479938, 0.92485565,\n",
      "       0.92488635, 0.92490846, 0.92495596, 0.92500341, 0.92502534,\n",
      "       0.92505568, 0.92510283, 0.92513299, 0.92517996, 0.92522681,\n",
      "       0.92525679, 0.9253118 , 0.92536676, 0.9254216 , 0.92545956,\n",
      "       0.92548913, 0.92555195, 0.92556471, 0.92561066, 0.92563999,\n",
      "       0.92566919, 0.92569834, 0.92575228, 0.92578954, 0.92581844,\n",
      "       0.92586386, 0.92591739, 0.92597079, 0.92599118, 0.92601973,\n",
      "       0.92608929, 0.92610949, 0.92615426, 0.9261989 , 0.92622709,\n",
      "       0.92627156, 0.92629963, 0.92636842, 0.92638814, 0.92642415,\n",
      "       0.92648447, 0.9265365 , 0.92658848, 0.92660791, 0.92664343,\n",
      "       0.9266547 , 0.92669016, 0.92674977, 0.92678505, 0.92678803,\n",
      "       0.92683125, 0.92685831, 0.92688531, 0.9269042 , 0.92696315,\n",
      "       0.92698193, 0.92700869, 0.92705137, 0.92709398, 0.92714447,\n",
      "       0.92716295, 0.92716557, 0.92719197, 0.92719448, 0.92722082,\n",
      "       0.9272629 , 0.92724955, 0.92728364, 0.92729396, 0.92732006,\n",
      "       0.92734611, 0.92737997, 0.92741376, 0.9274475 , 0.92748117,\n",
      "       0.92753828, 0.92756397, 0.92758954, 0.92761511, 0.92767185])), 'global_step/sec': (array([ 11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121, 131,\n",
      "       141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251, 261,\n",
      "       271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381, 391,\n",
      "       401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511, 521,\n",
      "       531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641, 651,\n",
      "       661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771, 781,\n",
      "       791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901, 911,\n",
      "       921, 931, 941, 951, 961, 971, 981, 991]), array([19.82092476, 33.93213654, 29.65291405, 35.18067932, 34.57346344,\n",
      "       35.48288345, 33.46453476, 24.17800713, 30.49338341,  2.78416514,\n",
      "       33.41720581, 36.45645142, 32.52401733, 28.93695068, 28.73999977,\n",
      "       28.29599571, 32.49536896, 32.22584915, 27.36121178, 22.82431793,\n",
      "       42.16385269, 40.2304306 , 30.12757683, 32.58071136, 32.32761383,\n",
      "       29.9964447 , 29.69683647, 32.1354332 , 25.46875381, 19.02446938,\n",
      "       40.1719017 , 33.85607529, 32.4737587 , 31.73394394, 25.82205009,\n",
      "       21.62391281, 30.50025749, 32.06894684, 31.80189323,  4.0894208 ,\n",
      "       35.83753967, 30.78541946, 24.10695457, 26.57879448, 29.92684364,\n",
      "       32.35659027, 27.01076126, 26.71095657, 31.39228249, 19.52155685,\n",
      "       34.07014465, 35.1519928 , 24.23742867, 25.6848278 , 27.06395531,\n",
      "       28.12756729, 29.53078079, 29.20143318, 28.57754898, 21.04829407,\n",
      "       36.29549789, 35.26663971, 25.24061775, 27.61378098, 29.81827354,\n",
      "       30.46948242, 30.57984543, 29.22326469, 28.72572899,  4.01735687,\n",
      "       37.22770309, 37.47102356, 33.10557175, 39.45578766, 32.38742065,\n",
      "       30.45308876, 30.40159225, 31.04162407, 30.37435913, 16.92454147,\n",
      "       32.91325378, 26.93067169, 28.1965847 , 29.66732407, 27.939991  ,\n",
      "       21.27876472, 23.75190544, 29.72613335, 29.40849304, 18.6435051 ,\n",
      "       37.61174774, 33.25421143, 29.58614922, 27.3060627 , 28.33143044,\n",
      "       29.59777832, 30.3858223 , 29.06816673, 23.67866707])), 'loss': (array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
      "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
      "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
      "         34,   35,   36,   37,   38,   39,   40,   41,   42,   43,   44,\n",
      "         45,   46,   47,   48,   49,   50,   51,   52,   53,   54,   55,\n",
      "         56,   57,   58,   59,   60,   61,   62,   63,   64,   65,   66,\n",
      "         67,   68,   69,   70,   71,   72,   73,   74,   75,   76,   77,\n",
      "         78,   79,   80,   81,   82,   83,   84,   85,   86,   87,   88,\n",
      "         89,   90,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
      "        100,  101,  102,  103,  104,  105,  106,  107,  108,  109,  110,\n",
      "        111,  112,  113,  114,  115,  116,  117,  118,  119,  120,  121,\n",
      "        122,  123,  124,  125,  126,  127,  128,  129,  130,  131,  132,\n",
      "        133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
      "        144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,\n",
      "        155,  156,  157,  158,  159,  160,  161,  162,  163,  164,  165,\n",
      "        166,  167,  168,  169,  170,  171,  172,  173,  174,  175,  176,\n",
      "        177,  178,  179,  180,  181,  182,  183,  184,  185,  186,  187,\n",
      "        188,  189,  190,  191,  192,  193,  194,  195,  196,  197,  198,\n",
      "        199,  200,  201,  202,  203,  204,  205,  206,  207,  208,  209,\n",
      "        210,  211,  212,  213,  214,  215,  216,  217,  218,  219,  220,\n",
      "        221,  222,  223,  224,  225,  226,  227,  228,  229,  230,  231,\n",
      "        232,  233,  234,  235,  236,  237,  238,  239,  240,  241,  242,\n",
      "        243,  244,  245,  246,  247,  248,  249,  250,  251,  252,  253,\n",
      "        254,  255,  256,  257,  258,  259,  260,  261,  262,  263,  264,\n",
      "        265,  266,  267,  268,  269,  270,  271,  272,  273,  274,  275,\n",
      "        276,  277,  278,  279,  280,  281,  282,  283,  284,  285,  286,\n",
      "        287,  288,  289,  290,  291,  292,  293,  294,  295,  296,  297,\n",
      "        298,  299,  300,  301,  302,  303,  304,  305,  306,  307,  308,\n",
      "        309,  310,  311,  312,  313,  314,  315,  316,  317,  318,  319,\n",
      "        320,  321,  322,  323,  324,  325,  326,  327,  328,  329,  330,\n",
      "        331,  332,  333,  334,  335,  336,  337,  338,  339,  340,  341,\n",
      "        342,  343,  344,  345,  346,  347,  348,  349,  350,  351,  352,\n",
      "        353,  354,  355,  356,  357,  358,  359,  360,  361,  362,  363,\n",
      "        364,  365,  366,  367,  368,  369,  370,  371,  372,  373,  374,\n",
      "        375,  376,  377,  378,  379,  380,  381,  382,  383,  384,  385,\n",
      "        386,  387,  388,  389,  390,  391,  392,  393,  394,  395,  396,\n",
      "        397,  398,  399,  400,  401,  402,  403,  404,  405,  406,  407,\n",
      "        408,  409,  410,  411,  412,  413,  414,  415,  416,  417,  418,\n",
      "        419,  420,  421,  422,  423,  424,  425,  426,  427,  428,  429,\n",
      "        430,  431,  432,  433,  434,  435,  436,  437,  438,  439,  440,\n",
      "        441,  442,  443,  444,  445,  446,  447,  448,  449,  450,  451,\n",
      "        452,  453,  454,  455,  456,  457,  458,  459,  460,  461,  462,\n",
      "        463,  464,  465,  466,  467,  468,  469,  470,  471,  472,  473,\n",
      "        474,  475,  476,  477,  478,  479,  480,  481,  482,  483,  484,\n",
      "        485,  486,  487,  488,  489,  490,  491,  492,  493,  494,  495,\n",
      "        496,  497,  498,  499,  500,  501,  502,  503,  504,  505,  506,\n",
      "        507,  508,  509,  510,  511,  512,  513,  514,  515,  516,  517,\n",
      "        518,  519,  520,  521,  522,  523,  524,  525,  526,  527,  528,\n",
      "        529,  530,  531,  532,  533,  534,  535,  536,  537,  538,  539,\n",
      "        540,  541,  542,  543,  544,  545,  546,  547,  548,  549,  550,\n",
      "        551,  552,  553,  554,  555,  556,  557,  558,  559,  560,  561,\n",
      "        562,  563,  564,  565,  566,  567,  568,  569,  570,  571,  572,\n",
      "        573,  574,  575,  576,  577,  578,  579,  580,  581,  582,  583,\n",
      "        584,  585,  586,  587,  588,  589,  590,  591,  592,  593,  594,\n",
      "        595,  596,  597,  598,  599,  600,  601,  602,  603,  604,  605,\n",
      "        606,  607,  608,  609,  610,  611,  612,  613,  614,  615,  616,\n",
      "        617,  618,  619,  620,  621,  622,  623,  624,  625,  626,  627,\n",
      "        628,  629,  630,  631,  632,  633,  634,  635,  636,  637,  638,\n",
      "        639,  640,  641,  642,  643,  644,  645,  646,  647,  648,  649,\n",
      "        650,  651,  652,  653,  654,  655,  656,  657,  658,  659,  660,\n",
      "        661,  662,  663,  664,  665,  666,  667,  668,  669,  670,  671,\n",
      "        672,  673,  674,  675,  676,  677,  678,  679,  680,  681,  682,\n",
      "        683,  684,  685,  686,  687,  688,  689,  690,  691,  692,  693,\n",
      "        694,  695,  696,  697,  698,  699,  700,  701,  702,  703,  704,\n",
      "        705,  706,  707,  708,  709,  710,  711,  712,  713,  714,  715,\n",
      "        716,  717,  718,  719,  720,  721,  722,  723,  724,  725,  726,\n",
      "        727,  728,  729,  730,  731,  732,  733,  734,  735,  736,  737,\n",
      "        738,  739,  740,  741,  742,  743,  744,  745,  746,  747,  748,\n",
      "        749,  750,  751,  752,  753,  754,  755,  756,  757,  758,  759,\n",
      "        760,  761,  762,  763,  764,  765,  766,  767,  768,  769,  770,\n",
      "        771,  772,  773,  774,  775,  776,  777,  778,  779,  780,  781,\n",
      "        782,  783,  784,  785,  786,  787,  788,  789,  790,  791,  792,\n",
      "        793,  794,  795,  796,  797,  798,  799,  800,  801,  802,  803,\n",
      "        804,  805,  806,  807,  808,  809,  810,  811,  812,  813,  814,\n",
      "        815,  816,  817,  818,  819,  820,  821,  822,  823,  824,  825,\n",
      "        826,  827,  828,  829,  830,  831,  832,  833,  834,  835,  836,\n",
      "        837,  838,  839,  840,  841,  842,  843,  844,  845,  846,  847,\n",
      "        848,  849,  850,  851,  852,  853,  854,  855,  856,  857,  858,\n",
      "        859,  860,  861,  862,  863,  864,  865,  866,  867,  868,  869,\n",
      "        870,  871,  872,  873,  874,  875,  876,  877,  878,  879,  880,\n",
      "        881,  882,  883,  884,  885,  886,  887,  888,  889,  890,  891,\n",
      "        892,  893,  894,  895,  896,  897,  898,  899,  900,  901,  902,\n",
      "        903,  904,  905,  906,  907,  908,  909,  910,  911,  912,  913,\n",
      "        914,  915,  916,  917,  918,  919,  920,  921,  922,  923,  924,\n",
      "        925,  926,  927,  928,  929,  930,  931,  932,  933,  934,  935,\n",
      "        936,  937,  938,  939,  940,  941,  942,  943,  944,  945,  946,\n",
      "        947,  948,  949,  950,  951,  952,  953,  954,  955,  956,  957,\n",
      "        958,  959,  960,  961,  962,  963,  964,  965,  966,  967,  968,\n",
      "        969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
      "        980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,\n",
      "        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000]), array([2.30226707, 2.27386785, 2.218961  , 2.17746115, 2.09298229,\n",
      "       2.02762175, 2.00150442, 1.95067549, 1.95292449, 1.95874465,\n",
      "       1.92655301, 1.92864418, 1.85665154, 1.87017441, 1.80142784,\n",
      "       1.83909798, 1.79463041, 1.84363317, 1.83859801, 1.78267789,\n",
      "       1.67926037, 1.76655674, 1.74815011, 1.69756782, 1.73789072,\n",
      "       1.73754835, 1.68812978, 1.67583895, 1.65831971, 1.72262609,\n",
      "       1.68133259, 1.62839961, 1.64222538, 1.61709571, 1.76408339,\n",
      "       1.65690863, 1.65103877, 1.70340288, 1.68625712, 1.64528203,\n",
      "       1.67713773, 1.64086366, 1.66590858, 1.61868143, 1.66934085,\n",
      "       1.6357975 , 1.65174198, 1.64053059, 1.66265261, 1.65314031,\n",
      "       1.605129  , 1.61844599, 1.61707163, 1.67463672, 1.61830592,\n",
      "       1.58085358, 1.62707663, 1.68895423, 1.60251248, 1.66853523,\n",
      "       1.60693264, 1.6197201 , 1.57635069, 1.62353969, 1.59834242,\n",
      "       1.65351069, 1.65537786, 1.61502242, 1.59384429, 1.57668543,\n",
      "       1.61236763, 1.62293041, 1.54034901, 1.58543158, 1.56604719,\n",
      "       1.63648903, 1.56046855, 1.56546152, 1.60356116, 1.61731327,\n",
      "       1.57589507, 1.59185266, 1.59333849, 1.55644929, 1.56305027,\n",
      "       1.56300592, 1.57448351, 1.58429527, 1.57628191, 1.54524541,\n",
      "       1.63671696, 1.52317548, 1.55714977, 1.56030059, 1.58924556,\n",
      "       1.58918929, 1.56389737, 1.57803106, 1.57181191, 1.55468619,\n",
      "       1.54036796, 1.5754385 , 1.55843878, 1.55809605, 1.59075212,\n",
      "       1.55786872, 1.60377944, 1.57625353, 1.57076359, 1.57509565,\n",
      "       1.54365706, 1.53844774, 1.50927317, 1.56931257, 1.57460809,\n",
      "       1.55428529, 1.57508707, 1.51692724, 1.58278203, 1.57370412,\n",
      "       1.52516329, 1.59283757, 1.5393014 , 1.59594464, 1.56640661,\n",
      "       1.55908155, 1.57780755, 1.56621134, 1.53773642, 1.60898542,\n",
      "       1.52286577, 1.60862398, 1.54333282, 1.5409472 , 1.60408676,\n",
      "       1.55147123, 1.58423162, 1.56435788, 1.53850114, 1.55433655,\n",
      "       1.57657981, 1.5427649 , 1.54373503, 1.58486581, 1.52973771,\n",
      "       1.5320729 , 1.53594661, 1.56393242, 1.53434634, 1.58394682,\n",
      "       1.53974819, 1.55075037, 1.5653013 , 1.58942652, 1.57643294,\n",
      "       1.53551722, 1.53642917, 1.57802045, 1.55166221, 1.55119252,\n",
      "       1.56339407, 1.59583247, 1.55569482, 1.62050915, 1.55230057,\n",
      "       1.53265607, 1.51718974, 1.57154405, 1.52992916, 1.53544545,\n",
      "       1.57031202, 1.55108666, 1.56703496, 1.57010949, 1.53655338,\n",
      "       1.53598738, 1.51399434, 1.56279659, 1.57017279, 1.53982496,\n",
      "       1.53199553, 1.55579209, 1.53802371, 1.55489993, 1.51783538,\n",
      "       1.54103816, 1.54099607, 1.53669751, 1.59895563, 1.57252157,\n",
      "       1.58110905, 1.53906453, 1.55710959, 1.58439207, 1.54669189,\n",
      "       1.52957809, 1.54301357, 1.5724144 , 1.53452659, 1.54031718,\n",
      "       1.53711653, 1.53306389, 1.55889726, 1.56346476, 1.53497219,\n",
      "       1.58717394, 1.54145253, 1.58175945, 1.59649527, 1.55910563,\n",
      "       1.53963852, 1.55727112, 1.53393388, 1.52555013, 1.5334568 ,\n",
      "       1.53108096, 1.55508208, 1.58148611, 1.56962287, 1.52847517,\n",
      "       1.56699705, 1.55531669, 1.52448583, 1.54042768, 1.56277168,\n",
      "       1.53125334, 1.56696773, 1.56917715, 1.56514382, 1.53221536,\n",
      "       1.56163776, 1.53681052, 1.50912702, 1.51526666, 1.5598793 ,\n",
      "       1.56807303, 1.58199286, 1.51653743, 1.54500294, 1.51935863,\n",
      "       1.54206443, 1.53410065, 1.51213336, 1.5419302 , 1.53193307,\n",
      "       1.58372223, 1.55205238, 1.54899621, 1.52789664, 1.57137334,\n",
      "       1.53833008, 1.50232244, 1.50910628, 1.51792383, 1.540941  ,\n",
      "       1.51358116, 1.55569434, 1.54359889, 1.50856841, 1.55587137,\n",
      "       1.52502632, 1.5079813 , 1.52735424, 1.53833818, 1.56232989,\n",
      "       1.52497768, 1.52670074, 1.51667488, 1.5401634 , 1.54269242,\n",
      "       1.52864981, 1.5731796 , 1.53702509, 1.51799285, 1.54647553,\n",
      "       1.53697014, 1.53921461, 1.51910639, 1.55045438, 1.52443087,\n",
      "       1.54815817, 1.50724077, 1.51202488, 1.55431867, 1.54454374,\n",
      "       1.56857598, 1.52985358, 1.53750682, 1.51059401, 1.52614403,\n",
      "       1.53143561, 1.53422952, 1.53149521, 1.51034403, 1.53043878,\n",
      "       1.53573084, 1.53778744, 1.54598498, 1.56934881, 1.51494753,\n",
      "       1.52930617, 1.52985978, 1.51690459, 1.53179884, 1.5587759 ,\n",
      "       1.53059649, 1.52277112, 1.56831813, 1.53940773, 1.52620864,\n",
      "       1.53217387, 1.5517745 , 1.50451183, 1.53311253, 1.58321118,\n",
      "       1.51527548, 1.5423758 , 1.51634812, 1.52195108, 1.54006457,\n",
      "       1.51634574, 1.49043667, 1.50621259, 1.52688909, 1.52591872,\n",
      "       1.53238988, 1.52638149, 1.5183748 , 1.53497899, 1.4924773 ,\n",
      "       1.51802003, 1.53793216, 1.5604322 , 1.55720448, 1.55699515,\n",
      "       1.53970492, 1.49829459, 1.51910377, 1.55142975, 1.52024651,\n",
      "       1.53805196, 1.51647997, 1.51031971, 1.54368293, 1.55671573,\n",
      "       1.52966356, 1.48728883, 1.5344286 , 1.53316998, 1.51857996,\n",
      "       1.54027271, 1.52165186, 1.52353191, 1.51445985, 1.56766427,\n",
      "       1.49620259, 1.52646732, 1.49275279, 1.55241036, 1.51823378,\n",
      "       1.48998618, 1.52684236, 1.53645229, 1.54123414, 1.53132713,\n",
      "       1.50974941, 1.4977752 , 1.50420666, 1.52363002, 1.54090035,\n",
      "       1.53085196, 1.52327394, 1.51016951, 1.51982164, 1.52608109,\n",
      "       1.49538136, 1.52075899, 1.52411807, 1.53752279, 1.55664158,\n",
      "       1.51259482, 1.53343105, 1.55729985, 1.52703094, 1.51062   ,\n",
      "       1.54122877, 1.49892879, 1.54006159, 1.53690505, 1.51196432,\n",
      "       1.51401377, 1.52969146, 1.51928103, 1.52466917, 1.52182531,\n",
      "       1.52226377, 1.52662086, 1.52512121, 1.51215911, 1.54966617,\n",
      "       1.52090812, 1.54675269, 1.5139668 , 1.51224613, 1.49445832,\n",
      "       1.52155447, 1.52368069, 1.52642417, 1.50906587, 1.56312644,\n",
      "       1.52649522, 1.49577165, 1.5043968 , 1.54102683, 1.51939082,\n",
      "       1.51351023, 1.55045271, 1.53376007, 1.49174726, 1.56340849,\n",
      "       1.58470118, 1.48893738, 1.51041007, 1.54626846, 1.54357362,\n",
      "       1.56169343, 1.54595542, 1.50188887, 1.50967836, 1.51463652,\n",
      "       1.52946615, 1.51681781, 1.5077014 , 1.47565198, 1.48809862,\n",
      "       1.52051663, 1.58884454, 1.51020539, 1.49623346, 1.51686692,\n",
      "       1.52848125, 1.50903106, 1.48592961, 1.50830698, 1.53105378,\n",
      "       1.50274837, 1.53767371, 1.50351846, 1.5265348 , 1.52806365,\n",
      "       1.51200891, 1.53816187, 1.49960518, 1.52631092, 1.52117288,\n",
      "       1.52464676, 1.50624919, 1.52931404, 1.5139451 , 1.51930141,\n",
      "       1.51536965, 1.51697612, 1.52241266, 1.53783894, 1.52607131,\n",
      "       1.52125919, 1.52313423, 1.54165602, 1.49311841, 1.51407814,\n",
      "       1.50064719, 1.5131135 , 1.52331519, 1.5638957 , 1.50058699,\n",
      "       1.50770509, 1.52227926, 1.49181914, 1.49842632, 1.50610793,\n",
      "       1.50633776, 1.51424038, 1.50255239, 1.51171708, 1.48766541,\n",
      "       1.49099982, 1.4984448 , 1.53944468, 1.50134683, 1.49427867,\n",
      "       1.50802422, 1.51354873, 1.48872948, 1.50129974, 1.53191328,\n",
      "       1.56025159, 1.50046051, 1.53492045, 1.49810934, 1.5082202 ,\n",
      "       1.52715302, 1.52136672, 1.51388812, 1.49712276, 1.52695513,\n",
      "       1.56426263, 1.518116  , 1.50906038, 1.55072463, 1.51607513,\n",
      "       1.51424444, 1.50629139, 1.52127314, 1.54472911, 1.51418877,\n",
      "       1.54223907, 1.53311968, 1.51568866, 1.53439939, 1.53332806,\n",
      "       1.50602126, 1.51190007, 1.54013205, 1.52809703, 1.51882052,\n",
      "       1.5109148 , 1.50622773, 1.51147878, 1.49932611, 1.50198698,\n",
      "       1.49030662, 1.50890028, 1.53875303, 1.51283503, 1.51437402,\n",
      "       1.49953067, 1.52409172, 1.51503527, 1.49751401, 1.52244067,\n",
      "       1.52710795, 1.52229595, 1.51596749, 1.50753331, 1.51570714,\n",
      "       1.4960103 , 1.51088977, 1.50626802, 1.53537369, 1.49834764,\n",
      "       1.48851144, 1.49616551, 1.5171349 , 1.50979877, 1.50510573,\n",
      "       1.52555192, 1.53030801, 1.50099266, 1.50340569, 1.49580026,\n",
      "       1.48327291, 1.51153469, 1.50096464, 1.50583875, 1.48653412,\n",
      "       1.51937878, 1.52923441, 1.53702283, 1.47160733, 1.52203703,\n",
      "       1.52179122, 1.5264045 , 1.51060915, 1.53752351, 1.49850237,\n",
      "       1.52918744, 1.51166105, 1.4953599 , 1.50618327, 1.4784317 ,\n",
      "       1.51524472, 1.5198859 , 1.51824093, 1.51315331, 1.52280402,\n",
      "       1.53247344, 1.53999519, 1.50342333, 1.49015725, 1.5142597 ,\n",
      "       1.50590634, 1.51031077, 1.50508857, 1.52073503, 1.52646208,\n",
      "       1.53087425, 1.49095595, 1.52581489, 1.50772107, 1.49114764,\n",
      "       1.51806712, 1.50627828, 1.49168849, 1.50233877, 1.50991464,\n",
      "       1.51385152, 1.49747634, 1.51045775, 1.51280093, 1.48833787,\n",
      "       1.49786782, 1.53491068, 1.49082804, 1.48082769, 1.5438025 ,\n",
      "       1.52961159, 1.53670669, 1.50387585, 1.51996756, 1.52536356,\n",
      "       1.49019647, 1.53597021, 1.52179515, 1.52260303, 1.51083755,\n",
      "       1.49853992, 1.53614187, 1.49912214, 1.5237968 , 1.51054978,\n",
      "       1.51754999, 1.5049367 , 1.5348531 , 1.53867865, 1.50245583,\n",
      "       1.51702833, 1.51986146, 1.51999331, 1.49451089, 1.50270295,\n",
      "       1.5356071 , 1.51189303, 1.52202463, 1.50695109, 1.51310802,\n",
      "       1.51833177, 1.5277946 , 1.49783206, 1.50985551, 1.50557888,\n",
      "       1.48197436, 1.49223769, 1.50283718, 1.49778771, 1.51291871,\n",
      "       1.52979982, 1.53889525, 1.50102139, 1.51146865, 1.49883914,\n",
      "       1.49185669, 1.51281285, 1.52741432, 1.50903893, 1.50499058,\n",
      "       1.49975133, 1.52641773, 1.49939013, 1.52728105, 1.55468392,\n",
      "       1.51616776, 1.49865901, 1.52757931, 1.52706361, 1.49925137,\n",
      "       1.49903917, 1.48725617, 1.54017532, 1.52745414, 1.53773403,\n",
      "       1.52052486, 1.50675988, 1.47621298, 1.51558876, 1.52430868,\n",
      "       1.50259662, 1.49618411, 1.52337015, 1.51467681, 1.4930408 ,\n",
      "       1.49799311, 1.50204968, 1.529706  , 1.4895581 , 1.5198288 ,\n",
      "       1.50271094, 1.50926197, 1.54173374, 1.50633132, 1.55416369,\n",
      "       1.52558744, 1.51985931, 1.51262879, 1.49739778, 1.50315022,\n",
      "       1.52017128, 1.50955868, 1.53279519, 1.51795316, 1.52293789,\n",
      "       1.52082849, 1.52332175, 1.50273919, 1.51216888, 1.50238109,\n",
      "       1.54431748, 1.49547434, 1.50803137, 1.51773477, 1.49500036,\n",
      "       1.50303233, 1.48875153, 1.52233362, 1.50156915, 1.52807331,\n",
      "       1.50539923, 1.51417243, 1.48497796, 1.52257466, 1.51235461,\n",
      "       1.48492503, 1.4953804 , 1.52264452, 1.53147089, 1.50038004,\n",
      "       1.49602962, 1.504668  , 1.48805404, 1.509794  , 1.50084901,\n",
      "       1.5118587 , 1.49077773, 1.50881886, 1.50017595, 1.51074791,\n",
      "       1.48760867, 1.50858319, 1.5314256 , 1.51283455, 1.49242556,\n",
      "       1.48390138, 1.51459718, 1.55188262, 1.49795222, 1.47937763,\n",
      "       1.50201046, 1.49383307, 1.49466085, 1.50071669, 1.50176644,\n",
      "       1.51967478, 1.51119077, 1.50047421, 1.5033133 , 1.51393008,\n",
      "       1.49091148, 1.49197006, 1.51655889, 1.49563587, 1.50204897,\n",
      "       1.50907373, 1.48995566, 1.48634851, 1.52845609, 1.49697661,\n",
      "       1.51840162, 1.48797238, 1.53992152, 1.52320528, 1.52974975,\n",
      "       1.52141714, 1.49909925, 1.51979303, 1.5067625 , 1.4964931 ,\n",
      "       1.52271271, 1.51733804, 1.50251818, 1.53010857, 1.515692  ,\n",
      "       1.49181616, 1.53645599, 1.50416946, 1.51179099, 1.50678635,\n",
      "       1.5051949 , 1.50447333, 1.4962945 , 1.49974847, 1.4791286 ,\n",
      "       1.48591363, 1.52623844, 1.49990106, 1.49665034, 1.50082874,\n",
      "       1.51709628, 1.50768018, 1.51633465, 1.51814222, 1.50491834,\n",
      "       1.50256991, 1.48063397, 1.53261614, 1.50608826, 1.5313406 ,\n",
      "       1.50479972, 1.51344514, 1.51731539, 1.50104368, 1.51921225,\n",
      "       1.51607013, 1.51693976, 1.49724793, 1.51341844, 1.50503862,\n",
      "       1.50329947, 1.48636127, 1.50705099, 1.49146199, 1.48423266,\n",
      "       1.47742093, 1.53097677, 1.50292218, 1.5124203 , 1.53212166,\n",
      "       1.51125932, 1.51067591, 1.50369501, 1.48722291, 1.49402964,\n",
      "       1.52112317, 1.50066018, 1.48877239, 1.50363421, 1.49201989,\n",
      "       1.49580884, 1.49492097, 1.50218821, 1.51451516, 1.50951385,\n",
      "       1.51002932, 1.51597047, 1.50581765, 1.52334833, 1.49674284,\n",
      "       1.5174917 , 1.47975397, 1.52652526, 1.51235318, 1.49280131,\n",
      "       1.47904122, 1.49797845, 1.48636878, 1.52291596, 1.48704731,\n",
      "       1.51698232, 1.5086112 , 1.53491116, 1.48160076, 1.49877644,\n",
      "       1.51173377, 1.52488744, 1.48240399, 1.5271467 , 1.53032219,\n",
      "       1.51331925, 1.50997186, 1.50553989, 1.49620461, 1.47927773,\n",
      "       1.52017617, 1.51345122, 1.52113116, 1.49368274, 1.49563742,\n",
      "       1.50728834, 1.51183164, 1.50060451, 1.49624157, 1.48938322,\n",
      "       1.48512793, 1.49642277, 1.50040698, 1.51421106, 1.51841688,\n",
      "       1.50793004, 1.5075736 , 1.49839151, 1.50319576, 1.5323627 ,\n",
      "       1.49541056, 1.48482251, 1.49947798, 1.49470806, 1.49605489,\n",
      "       1.47736657, 1.53533137, 1.51880813, 1.51370549, 1.48590934,\n",
      "       1.50602424, 1.49168825, 1.51104152, 1.49669814, 1.49235153,\n",
      "       1.51906943, 1.53236151, 1.51653385, 1.4954139 , 1.48538876,\n",
      "       1.5034163 , 1.51339507, 1.49252939, 1.50019073, 1.51604664,\n",
      "       1.51457667, 1.49813628, 1.51241207, 1.49785376, 1.49116588,\n",
      "       1.5080061 , 1.48867702, 1.48938024, 1.4838562 , 1.50643301,\n",
      "       1.5110265 , 1.484851  , 1.52376926, 1.49547648, 1.51183581,\n",
      "       1.5015204 , 1.50344348, 1.48259258, 1.50068843, 1.51270688,\n",
      "       1.49797809, 1.48687232, 1.4822371 , 1.51843941, 1.50858879,\n",
      "       1.47005343, 1.51756597, 1.49199677, 1.49350977, 1.50304031,\n",
      "       1.49043763, 1.50890958, 1.47017145, 1.51706409, 1.50238061,\n",
      "       1.48158574, 1.48354948, 1.4896636 , 1.50912142, 1.4995681 ,\n",
      "       1.51972485, 1.50738537, 1.48264408, 1.49677324, 1.53413439,\n",
      "       1.49933791, 1.51156676, 1.51096964, 1.5134275 , 1.47789955,\n",
      "       1.5152185 , 1.50897706, 1.48959732, 1.49055362, 1.48742628,\n",
      "       1.52560329, 1.52731657, 1.50714707, 1.52869654, 1.50991356,\n",
      "       1.49427021, 1.53908277, 1.50541222, 1.51781309, 1.51160872,\n",
      "       1.50639117, 1.49806142, 1.49795282, 1.50273383, 1.50274694,\n",
      "       1.48215032, 1.50476301, 1.5066185 , 1.51620913, 1.47477639]))}\n"
     ]
    }
   ],
   "source": [
    "print(load_data_tensorboard(FLAGS.model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss'])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history['loss'][1]), len(history['acc_train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9, 3), dpi=100)\n",
    "plt.subplots_adjust(wspace=0.6)\n",
    "ax1 = plt.subplot(122)\n",
    "ax2 = plt.subplot(121)\n",
    "ax1.plot(history['loss'][0], history['loss'][1], 'b', label='training loss')\n",
    "ax2.plot(history['acc_train'][0], history['acc_train'][1], 'r', label='validation accuracy');\n",
    "ax1.set_title('Loss')\n",
    "ax1.set_xlabel(\"Number of steps\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9, 3), dpi=100)\n",
    "plt.subplots_adjust(wspace=0.6)\n",
    "ax1 = plt.subplot(122)\n",
    "ax2 = plt.subplot(121)\n",
    "ax1.plot(history['loss_1'][0], history['loss_1'][1], 'b', label='training loss')\n",
    "#ax1.plot(np.arange(0, epochs), history['loss_1'][1], 'r', label='validation accuracy');\n",
    "ax1.set_title('Loss')\n",
    "ax1.set_xlabel(\"Number of steps\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the output created during the training\n",
    "https://medium.com/@prasadpal107/saving-freezing-optimizing-for-inference-restoring-of-tensorflow-models-b4146deb21b5  \n",
    "- creating a keras model will create the **keras** folder \n",
    "- **checkpoint**, text file that contain all checkpoint information, like model ckpt file name and path\n",
    "- **model.ckpt-xxx.meta** and **model.ckpt-xxx.data-yyyyy-of-zzzzz** and **model.ckpt-xxx.index** file created for each model  \n",
    "  .ckpt-xxx.meta contains the complete graph. It includes GraphDef, SaverDef, and so on  \n",
    "  .ckpt-xxx.data contains the values of variables(weights, biases, placeholders, gradients, hyper-parameters etc)   \n",
    "  .ckpt-xxx.index is a table where each key is the name of a tensor and its value is a serialized BundleEntryProto \n",
    "- **graph.pbtxt** holds a network of nodes, each representing one operation, connected to each other as inputs and outputs (graph structure)\n",
    "- **events.out.tfevents.xxxxxxxxxx** which contain information that TensorBoard uses to create visualizations\n",
    "\n",
    "Meta files holds ,more than just the structure of the graph like MetaInfoDef , GraphDef SaverDef , CollectionDef . Whereas .pbtxt files holds only the structure of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras\n",
      "checkpoint\n",
      "model.ckpt-940.data-00000-of-00001\n",
      "model.ckpt-1000.data-00000-of-00001\n",
      "model.ckpt-920.meta\n",
      "model.ckpt-940.meta\n",
      "model.ckpt-1000.meta\n",
      "model.ckpt-960.meta\n",
      "events.out.tfevents.1552739145.Fabien-Tarrades-MacBook-Pro.local\n",
      "graph.pbtxt\n",
      "model.ckpt-980.meta\n",
      "model.ckpt-960.data-00000-of-00001\n",
      "model.ckpt-920.index\n",
      "model.ckpt-920.data-00000-of-00001\n",
      "eval\n",
      "model.ckpt-980.data-00000-of-00001\n",
      "export\n",
      "model.ckpt-960.index\n",
      "model.ckpt-980.index\n",
      "model.ckpt-940.index\n",
      "model.ckpt-1000.index\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(FLAGS.model_dir+'*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow logs will be saved here:\n",
      " results/Models/Mnist/tf_1_12/estimator/ckpt/\n"
     ]
    }
   ],
   "source": [
    "print('Tensorflow logs will be saved here:\\n',FLAGS.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1553024123.Fabien-Tarrades-MacBook-Pro.local\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(FLAGS.model_dir+'*events.out.tfevents.*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_command='tensorboard --logdir \"'+FLAGS.model_dir+'\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a separate shell with the same env activated (need Tensoflow and TensorBoard)\n",
      "  copy and pate the command below without \">>\":\n",
      "  >> tensorboard --logdir \"results/Models/Mnist/tf_1_12/estimator/ckpt/\"\n"
     ]
    }
   ],
   "source": [
    "print('In a separate shell with the same env activated (need Tensoflow and TensorBoard)')\n",
    "print('  copy and pate the command below without \">>\":')\n",
    "print('  >>',tensorboard_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the output of the TimeHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = sum(time_hist.times)\n",
    "print(f\"total time with the current strategy: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_time_per_batch = np.mean(time_hist.times)\n",
    "print(f\"{BATCH_SIZE/avg_time_per_batch} images/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and losses"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# method and arguments\n",
    "evaluate(\n",
    "    input_fn,\n",
    "    steps=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(glob.glob(path_train_tfrecords+'/train*.tfrecords'),\n",
    "                                                                                              FLAGS,\n",
    "                                                                                              mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                                                                                              batch_size=FLAGS.batch_size),\n",
    "                                     steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test accuracy\n",
    "print('Loss:')\n",
    "print('  - loss [training dataset]: {0:.3f}'.format(score['loss']))\n",
    "print('')\n",
    "print('Accuracy:')\n",
    "print('  - accuracy [training dataset]: {:.2f}%'.format(100*score['accuracy']))\n",
    "print('')\n",
    "print('Number of steps:')\n",
    "print('  - number of steps [training dataset]: {}'.format(score['global_step']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(glob.glob(path_test_tfrecords+'/test*.tfrecords'),\n",
    "                                                                                              FLAGS,\n",
    "                                                                                              mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                                                                              batch_size=FLAGS.batch_size),\n",
    "                                     steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test accuracy\n",
    "print('Loss:')\n",
    "print('  - loss [testing dataset]: {0:.3f}'.format(score['loss']))\n",
    "print('')\n",
    "print('Accuracy:')\n",
    "print('  - accuracy [testing dataset]: {:.2f}%'.format(100*score['accuracy']))\n",
    "print('')\n",
    "print('Number of steps:')\n",
    "print('  - number of steps [testing dataset]: {}'.format(score['global_step']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the model\n",
    "predictions = model_fn(features, labels, tf.estimator.ModeKeys.EVAL).predictions\n",
    "\n",
    "# Manually load the latest checkpoint\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state('/my/directory')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    # Loop through the batches and store predictions and labels\n",
    "    prediction_values = []\n",
    "    label_values = []\n",
    "    while True:\n",
    "        try:\n",
    "            preds, lbls = sess.run([predictions, labels])\n",
    "            prediction_values += preds\n",
    "            label_values += lbls\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    # store prediction_values and label_values somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# method and arguments\n",
    "predict(\n",
    "    input_fn,\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    yield_single_examples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = mnist_v1.input_mnist_tfrecord_dataset_fn(sorted(glob.glob(path_test_tfrecords+'/test*.tfrecords'), key=os.path.getmtime),\n",
    "                                                           FLAGS,\n",
    "                                                           mode=tf.estimator.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = testing_dataset.make_one_shot_iterator()\n",
    "# next_element\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "\n",
    "n_iter=10\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time.clock()\n",
    "            x,y = sess.run([features, labels])\n",
    "            print('iteration n:', n, 'execution time:', time.clock() - start_time, 'seconds')\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print('first label of the batch',np.argmax(y[0]),'\\n')\n",
    "            n+=1\n",
    "            if n>=n_iter:\n",
    "                print('number of iteration reached')\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('tf.errors.OutOfRangeError')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=list(estimator_train_model.predict(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(sorted(glob.glob(path_test_tfrecords+'/test*.tfrecords'), key=os.path.getmtime),\n",
    "                                                                                                  FLAGS,\n",
    "                                                                                                  mode=tf.estimator.ModeKeys.PREDICT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer=model_opt_tf.output_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    prediction_array = predictions[i][output_layer]\n",
    "    predicted_label = np.argmax(prediction_array)\n",
    "    print('Actual label:', y_test[i])\n",
    "    print(\"Predicted label: \", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_iter=estimator_train_model.predict(input_fn=lambda:mnist_v1.input_mnist_tfrecord_dataset_fn(sorted(glob.glob(path_test_tfrecords+'/test*.tfrecords'), key=os.path.getmtime),\n",
    "                                                                                                  FLAGS,\n",
    "                                                                                                  mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                                                                                  batch_size=len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for pred in list(itertools.islice(preds_iter, 5)):\n",
    "    prediction_array = pred['dense_2']\n",
    "    predicted_label = np.argmax(prediction_array)\n",
    "    print(prediction_array)\n",
    "    print(i)\n",
    "    if i==0:\n",
    "        print('--> ',pred.keys())\n",
    "    print()\n",
    "    print('Actual label:', y_test[i])\n",
    "    print(\"Predicted label: \", predicted_label)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras's model checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer=model_opt_tf.output_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator's model checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.get_variable_value(estimator_train_model.get_variable_names()[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.get_variable_value(estimator_train_model.get_variable_names()[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_model.latest_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model serving using Keras, tf.estimator and tf.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(FLAGS.saved_dir+'*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(FLAGS.saved_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_tf.input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    \"\"\"Serving input_fn that builds features from placeholders#\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.estimator.export.ServingInputReceiver\n",
    "    \"\"\"\n",
    "    input_images = tf.placeholder(tf.float32, [None, 784])\n",
    "    features = {'dense_2_input' : input_images} # this is the dict that is then passed as \"features\" parameter to your model_fn\n",
    "    receiver_tensors = {'dense_2_input': input_images} # As far as I understand this is needed to map the input to a name you can retrieve later\n",
    "   \n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FLAGS.saved_dir):\n",
    "    os.makedirs(FLAGS.saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Only export predict mode\n",
    "estimator_train_model.export_saved_model(os.path.abspath(FLAGS.saved_dir), \n",
    "                                         serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(FLAGS.saved_dir+'*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update the model id in the path below with the correct one from above i.e'1549040172'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag='1549054852'\n",
    "os.environ['MODEL_FOR_SERVING']=FLAGS.saved_dir+model_tag+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the folder name below with the one from above i.e '1549040172'\n",
    "for file in glob.glob(FLAGS.saved_dir+model_tag+'/*'):\n",
    "    print(re.findall(r'[^\\\\/]+|[\\\\/]',file)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the saved model before serving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! saved_model_cli show --dir $MODEL_FOR_SERVING --tag serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cloud ML Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking gcloud installation (SDK)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "install SDK"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "in case of issue with \"Bad magic number in .pyc file\" -> mix python 2 and python 3\n",
    "which python -> path (should use python 3)\n",
    "export CLOUDSDK_PYTHON=path (should use python 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud components list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud components update"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud auth configure-docker"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud version"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud ml-engine versions create --help"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda3/bin/python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a input json file and string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input needed to get prediction using ml-engine an option --json-instances: 'dense_2_input' for each new entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction=x_test[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_prediction.tolist()\n",
    "json_file = \"../data/input_predict_gcloud.json\" \n",
    "\n",
    "with codecs.open(json_file, 'w', encoding='utf-8') as f:\n",
    "    for el in data:\n",
    "        instance = {'dense_2_input': el}\n",
    "        json.dump(instance, f , sort_keys=True)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input needed to get prediction using ml-engine and cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_prediction.tolist()\n",
    "json_file = \"../data/input_predict_cURL.json\" \n",
    "\n",
    "with codecs.open(json_file, 'w', encoding='utf-8') as f:\n",
    "    tmp={}\n",
    "    list_tmp=[]\n",
    "    for el in data:\n",
    "        tmp['dense_2_input']=el\n",
    "        list_tmp.append(tmp)\n",
    "    instance = {\"instances\": list_tmp}    \n",
    "    json.dump(instance, f , sort_keys=True)\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input needed to get prediction using ml-engine and requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_predict_request = json.dumps({\"signature_name\": \"serving_default\", \"instances\": input_prediction.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title):\n",
    "    plt.figure()\n",
    "    plt.imshow(img.reshape(28,28))\n",
    "    plt.axis('off')\n",
    "    plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    show(x_test[i],'Test dataset, true label: '+str(np.argmax(y_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model inference using gcloud locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda3/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine local predict --model-dir $MODEL_FOR_SERVING --json-instances ../data/input_predict_gcloud.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model using Cloud ML Engine\n",
    "- https://cloud.google.com/ml-engine/docs/v1/predict-request\n",
    "- https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#requesting_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PROJECT']=subprocess.run('gcloud config list project --format \"value(core.project)\"', shell=True, check=True, stdout=subprocess.PIPE).stdout.decode().replace('\\n', '')\n",
    "os.environ['MODEL']='mnist'\n",
    "os.environ['BUCKET']='gs://'+os.environ['PROJECT']\n",
    "os.environ['VERSION']='v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsutil need python 2.7\n",
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r $MODEL_FOR_SERVING $BUCKET/model_dir_tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine models list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when creating the model for the first time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud ml-engine models create ${MODEL} \\\n",
    "--regions us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a version and store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine versions create ${VERSION} \\\n",
    "--model ${MODEL} \\\n",
    "--origin=${BUCKET}/model_dir_tmp/1549054852 \\\n",
    "--runtime-version=1.12 \\\n",
    "--staging-bucket=${BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the list of model in ML-Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !gcloud ml-engine versions list --model mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our model using ML-Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine predict --model=${MODEL} --version=${VERSION} --json-instances ../data/input_predict_gcloud.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing using RESTful API \n",
    "- https://www.tensorflow.org/serving/api_rest  \n",
    "RESTful API is an application program interface (API) that uses HTTP requests to GET, PUT, POST and DELETE data (Json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://ml.googleapis.com/v1/projects/${PROJECT}/models/${MODEL}/versions/${VERSION} \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "https://ml.googleapis.com/v1/projects/${PROJECT}/models/${MODEL}/versions/${VERSION}:predict \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-d @../data/input_predict_cURL.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python and requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ml.googleapis.com/v1/projects/'+os.environ['PROJECT']+'/models/'+os.environ['MODEL']+'/versions/'+os.environ['VERSION']+':predict'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, stdout=subprocess.PIPE).stdout.decode().replace('\\n', ''))\n",
    "}\n",
    "\n",
    "json_response = requests.post(url=url, data=input_predict_request, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    show(x_test[i], 'The model thought this was a {} , and it was actually a {}'.format(np.argmax(predictions[i]['dense_3']),np.argmax(y_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing using gRPC API \n",
    "- https://cloud.google.com/endpoints/docs/grpc/about-grpc  \n",
    "gRPC is a high performance, open-source universal RPC framework, developed by Google. In gRPC, a client application can directly call methods on a server application on a different machine as if it was a local object, making it easier to create distributed applications and services (Protobuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload the model and make evaluation using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_model_opt_keras=tf.keras.models.load_model(FLAGS.model_dir_keras+'keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = reload_model_opt_keras.evaluate(x_train, \n",
    "                                        y_train, \n",
    "                                        verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the model using Keras and tf.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_opt_keras.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_opt_keras.evaluate(x_train, \n",
    "                       y_train, \n",
    "                       verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    show(x_test[i], 'The model thought this was a {} , and it was actually a {}'.format(np.argmax(predictions[i]['dense_3']),np.argmax(y_test[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_gcp_dl]",
   "language": "python",
   "name": "conda-env-env_gcp_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
