{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling ML using Cloud ML Engine\n",
    "\n",
    "- to run the notebook underlying this presentation, go to [github.com/tarrade/proj_DL_models_and_pipelines_with_GCP](https://github.com/tarrade/proj_DL_models_and_pipelines_with_GCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "2. Data Science Workflow\n",
    "3. Developing code\n",
    "4. Hands-ON Tutorial: Running MNIST on ML-Engine\n",
    "5. Setup Runtime for Notebook\n",
    "6. Load Data from BQ\n",
    "7. Package Model\n",
    "8. Train using ML-Engine\n",
    "9. Deployment\n",
    "10. Predictions\n",
    "11. Recap\n",
    "12. Appendix: Jupyter Slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shortcut: Run first cells and jump to any part in the notebook\n",
    "\n",
    "> Will only work after initial setup (see below) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Fragment to initalize working with this notebook on the CLOUD\n",
    "# check working directory\n",
    "from utils import chdir_\n",
    "pwd = chdir_()\n",
    "## Import Tensorflow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ModuleNotFoundError:\n",
    "    raise ModuleNotFoundError(\"Install Tensorflow\")\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## import config:\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "with open(\"config2.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## setup env-variables \n",
    "import os\n",
    "import platform\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "TEST_DATA_JSON = config['testdatafile']\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = PKG_NAME\n",
    "os.environ['TEST_DATA_JSON'] = TEST_DATA_JSON\n",
    "# os.environ['ENV_NAME'] = config['env-name']\n",
    "if platform.system() == 'Windows':\n",
    "    from script.config_client import filepath_ssl_cert\n",
    "    print('You run Windows -_-\\n\\n''This means you are most probably on a Company Laptop and therefore behind a proxy.\\n'\n",
    "         'Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables')\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = filepath_ssl_cert # 'win-filepath\\to\\axa'\n",
    "    assert os.path.isfile(os.environ['REQUESTS_CA_BUNDLE']), \"SSL-File not found\"\n",
    "    assert os.environ.get(key='HTTPS_PROXY') != None, \"Set a proxy\"\n",
    "    #os.environ['HTTPS_PROXY'] = 'https://C219746:Alles-Ist-Besser2019@sc-wvs-ch-win-pr-01-vip1.ch.doleni.net:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Set new OUTPUT and DATA directory on GS\n",
    "OUTDIR = '/'.join(['gs:/', BUCKET, PKG_NAME, 'trained'])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR $OUTDIR\n",
    "%env DATA $DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "gcloud config set project %PROJECT%\n",
    "gcloud config set compute/region %REGION%\n",
    "gcloud config set ml_engine/local_python \"%PYTHON_LOCAL%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Workflow (DSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Goal is to standardise the development of models\n",
    "     - Checklist of necessary technical steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Vision: Achieve an first end-to-end model in production within a *productincrement* of 10 weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Scale out: Scale without having to rewrite your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "// from https://github.com/jupyter/notebook/issues/3024#issuecomment-435630413\n",
       "var marked = require('components/marked/lib/marked');\n",
       "\n",
       "if (marked.Renderer.name !== 'NonExtensibleTableRenderer') {\n",
       "    function tablecell(content, flags) {\n",
       "        var type = flags.header ? 'th' : 'td';\n",
       "        var style = flags.align == null ? '' : ' style=\"text-align: ' + flags.align + '\"';\n",
       "        var start_tag = '<' + type + style + '>';\n",
       "        var end_tag = '</' + type + '>\\n';\n",
       "        return start_tag + content + end_tag;\n",
       "    }\n",
       "\n",
       "    var DefaultRenderer = marked.Renderer;\n",
       "    function NonExtensibleTableRenderer(options) {\n",
       "        DefaultRenderer.call(this, options);\n",
       "        Object.defineProperty(this, 'tablecell', {\n",
       "            get: function () { return tablecell; },\n",
       "            set: function () { } // No-op, sorry for this hack but we must prevent it from being redefined\n",
       "        });\n",
       "    }\n",
       "    NonExtensibleTableRenderer.prototype = Object.create(DefaultRenderer.prototype);\n",
       "    NonExtensibleTableRenderer.prototype.constructor = NonExtensibleTableRenderer;\n",
       "\n",
       "    marked.setOptions({\n",
       "        renderer: new NonExtensibleTableRenderer()\n",
       "    });\n",
       "    // Look away... it has to be done as newer versions of the notebook build a custom\n",
       "    // renderer rather than extending the default.\n",
       "    marked.Renderer = NonExtensibleTableRenderer;\n",
       "}\n",
       "\n",
       "var Jupyter = require('base/js/namespace');\n",
       "Jupyter.notebook.get_cells()\n",
       "   .filter(cell => cell.cell_type === 'markdown' && cell.rendered)\n",
       "   .forEach(mdcell => {\n",
       "       mdcell.unrender();\n",
       "       mdcell.render();\n",
       "   });\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript // some javascript to render markdown tables properly\n",
    "\n",
    "// from https://github.com/jupyter/notebook/issues/3024#issuecomment-435630413\n",
    "var marked = require('components/marked/lib/marked');\n",
    "\n",
    "if (marked.Renderer.name !== 'NonExtensibleTableRenderer') {\n",
    "    function tablecell(content, flags) {\n",
    "        var type = flags.header ? 'th' : 'td';\n",
    "        var style = flags.align == null ? '' : ' style=\"text-align: ' + flags.align + '\"';\n",
    "        var start_tag = '<' + type + style + '>';\n",
    "        var end_tag = '</' + type + '>\\n';\n",
    "        return start_tag + content + end_tag;\n",
    "    }\n",
    "\n",
    "    var DefaultRenderer = marked.Renderer;\n",
    "    function NonExtensibleTableRenderer(options) {\n",
    "        DefaultRenderer.call(this, options);\n",
    "        Object.defineProperty(this, 'tablecell', {\n",
    "            get: function () { return tablecell; },\n",
    "            set: function () { } // No-op, sorry for this hack but we must prevent it from being redefined\n",
    "        });\n",
    "    }\n",
    "    NonExtensibleTableRenderer.prototype = Object.create(DefaultRenderer.prototype);\n",
    "    NonExtensibleTableRenderer.prototype.constructor = NonExtensibleTableRenderer;\n",
    "\n",
    "    marked.setOptions({\n",
    "        renderer: new NonExtensibleTableRenderer()\n",
    "    });\n",
    "    // Look away... it has to be done as newer versions of the notebook build a custom\n",
    "    // renderer rather than extending the default.\n",
    "    marked.Renderer = NonExtensibleTableRenderer;\n",
    "}\n",
    "\n",
    "var Jupyter = require('base/js/namespace');\n",
    "Jupyter.notebook.get_cells()\n",
    "   .filter(cell => cell.cell_type === 'markdown' && cell.rendered)\n",
    "   .forEach(mdcell => {\n",
    "       mdcell.unrender();\n",
    "       mdcell.render();\n",
    "   });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Science Pipeline (DSP) - Checklist\n",
    "\n",
    "- further [documentation](https://confluence.axa.com/confluence/pages/viewpage.action?pageId=112334644)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Data Science Process](Images/data_science_circle_steps.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [Scaling Michelangelo](https://eng.uber.com/scaling-michelangelo/) - Data Science Process at Uber\n",
    "![Data Science Process at Uber](Images/uber_michelangelo_at_scale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![Data Science Process](Images/data_science_circle.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|   Step 1: Preparation                   |      Step 2: Data exploration and model building                   |    Step 3: Model deployment                    \n",
    "|   :------------------                   |      :-------------------------------------------                  |   :-----------------------------------------  \n",
    "| 1.1  Define business and project goal   | 2.1  Define and setup ML project infrastructure                    | 3.1  Model industralization                             \n",
    "| 1.2  Quick data exploration             | 2.2  Data exploration and visualizaiton                            | 3.2  Gather and analyze insightbalancing ...)     \n",
    "| 1.3  ML models strategy                 | 2.3  Build and evaluate a model                                    | -\n",
    "|         -                              | 2.4  Interpretability of ML model                                  | -\n",
    "|        -                                | 2.5  Productionize and deploy the ML models                        | -                                          \n",
    "> steps 1 and 2 can be done *only* locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Developing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using your own laptop:\n",
    "- Cloud SDK on your laptop (CLI)\n",
    "- your IDE (e.g. PyCharme)\n",
    "- Juypter Notebook\n",
    "- your conda env\n",
    "- `gcloud ml-engine local` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Simple Cloud setup using\n",
    "- [Google Console](https://console.cloud.google.com/) -Compute Engine with 5 GB storage\n",
    "- Cloud Editor\n",
    "- datalab, [Deep Learning VM](https://cloud.google.com/deep-learning-vm/)\n",
    "- env ([runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)) by google\n",
    "- `gcloud ml-engine` (`local`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "|Cloud SDK on Laptop | Google Console |\n",
    "|---------------------|----------------|\n",
    "| your machine | Tiny Compute Engine with 5 GB storage |\n",
    "| Your IDE | Code Editor|\n",
    "| Jupyter Notebook | Datalab, [Deep Learning VM](https://cloud.google.com/deep-learning-vm/) |\n",
    "| your conda env | env ([runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)) by google |\n",
    "| `gcloud ml-engine local` | `gcloud ml-engine`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![laptop-icon-24](Images/laptop-icon-24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Call your python script (module) in your conda env\n",
    "2. Use `gcloud ml-engine local train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AI Platform Notebooks: Deep Learning VM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Deep Learning VM](Images/deep-learning-overview_2x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Preconfigured (Deep Learning) VMs for ML prottyping\n",
    "    - only CPUs possible\n",
    "- you use a preconfigured runtime compatible to ML Engine runtimes for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A cluster of machines using ML-Engine service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![CloudMachineLearning.png](Images/CloudMachineLearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- runs a script \"autonomously\" on the cloud and stops afterwards\n",
    "- offers to run different type of clusters \n",
    "- invoked by `gcloud ml-engine train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> develop on your laptop if you are comfortable with setting up your environements\n",
    "\n",
    "> otherwise develop on a preconfigured Notebook instance without too many compute attached to it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">Migrate to ML-Engine Cluster on GCP to \n",
    ">   - distribute learning on several machines\n",
    ">   - serve model 24/7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-ON Tutorial: Running MNIST on ML-Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Images/gcp_training_options-Modelling.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- deep dive into step 2 and 3 of proposed Data Science process\n",
    "- data exploration is omitted since a curated dataset is used\n",
    "- Some title reference to previously described Data Science Process, e.g. DSP 2.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adapted from [Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/cloudmle/cloudmle.ipynb) of Google Coursera Course [Serverless Machine Learning with Tensorflow on Google Cloud Platform](https://www.coursera.org/learn/serverless-machine-learning-gcp/). The current code respository is [github/tarrade/tarrade/proj_DL_models_and_pipelines_with_GCP/](https://github.com/tarrade/proj_DL_models_and_pipelines_with_GCP/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://ml4a.github.io/images/figures/mnist-input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- black and white images are numeric vectors (Feat 1- 784)\n",
    "- ten labels (Figures 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- recognise hand-written digits (e.g. on a postal card) \n",
    "- standardise inputs to 0 - 1 range (e.g. using BEAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GCP services used in Tutorial\n",
    "We will look today at following GCP Services\n",
    "    - BigQuery (BQ)\n",
    "    - Cloudstorage (Buckets)\n",
    "    - ML Engine\n",
    "    - If time allows: Dataflow using Apache Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata \n",
    "plot_mnist_testdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "ToDo: export in readable yaml format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSP 2.1: Setup\n",
    "\n",
    "1. ML Engine Runtimes\n",
    "2. Repository Structure\n",
    "3. Configuration Variables\n",
    "    - Environment variables to set\n",
    "    - How to add them to your runtime\n",
    "4. Setup `gcloud` runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">Create conda environment\n",
    ">  ```\n",
    ">  conda env create -f environment.yml -n env_gcp_dl\n",
    ">  conda activate env_gcp_dl\n",
    ">  jupyter notebook \n",
    ">  ```\n",
    "> Starts notebook-server with all packages in your current path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Change working directory**\n",
    "\n",
    "- In order to import from `src` functionality later in this notebook, it is necessary to change to the root directory of the notebooks directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# check working directory\n",
    "import os\n",
    "WORKINGDIR = os.path.normpath(os.getcwd())\n",
    "print(\"Current Working direcotory:\\t{}\".format(WORKINGDIR))\n",
    "folders = WORKINGDIR.split(os.sep)\n",
    "if folders.pop() in ['notebook', 'src', 'talks']:\n",
    "  WORKINGDIR = os.sep.join(folders)\n",
    "  print(\"Changed to New working directory:\\t{dir}\".format(dir=WORKINGDIR))\n",
    "  os.chdir(WORKINGDIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML Engine Runtimes\n",
    "Default ML-Engine Runtimes depend on the Tensorflow Version\n",
    "- [list of runtimes](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)\n",
    "- Current Version: `1.13`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#!conda install tensorflow=1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "TF_VERSION=$(python3 -c 'import tensorflow as tf; print(tf.__version__)')\n",
    "if $TF_VERSION != \"1.13.0\"\n",
    "then\n",
    "    pip install tensorflow==1.13\n",
    "fi\n",
    "    echo \"Found Tensorflow: $TF_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- current version of gcp datalab\n",
    "- will be different on Windows machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Repository structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.04.2019  21:55    <DIR>          .\n",
      "15.04.2019  21:55    <DIR>          ..\n",
      "11.01.2019  11:46    <DIR>          .vscode\n",
      "15.04.2019  22:13               149 config.yaml\n",
      "15.04.2019  21:55               127 config_from_python.yaml\n",
      "12.04.2019  16:37               224 config2.yaml\n",
      "06.03.2019  17:23    <DIR>          data\n",
      "27.02.2019  10:15    <DIR>          doc\n",
      "16.04.2019  08:59    <DIR>          notebook\n",
      "11.01.2019  12:08    <DIR>          results\n",
      "15.04.2019  10:02    <DIR>          script\n",
      "12.04.2019  16:13    <DIR>          src\n",
      "15.04.2019  14:00    <DIR>          trained\n"
     ]
    }
   ],
   "source": [
    "ls | grep \"DIR\\|yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key Directories containing information\n",
    "```\n",
    ".\n",
    "+-- data\n",
    "+-- src\n",
    "|  +-- models\n",
    "|  +-- packages\n",
    "config.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the next step the contents of [`config.yaml`](config.yaml) will be important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GCP Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `PROJECT_ID`: unique ID that identifies your project, e.g. **ml-productive-pipeline-12345**\n",
    "- `BUCKET`: BLOB-store ID. Each project has per default an bucket named by the `PROJECT_ID`\n",
    "- `REGION`: Which data center to use\n",
    "\n",
    "> All Cloud-ML-Engine Services are only available in [`europe-west1`](https://cloud.google.com/ml-engine/docs/tensorflow/regions)\n",
    "\n",
    "- all products per Region in europe: [link](https://cloud.google.com/about/locations/?region=europe#region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# #Create config manually and save as yaml:\n",
    "config = {}\n",
    "config['project-id'] = 'presentation-38388'  # # REPLACE WITH YOUR PROJECT ID\n",
    "config['region'] = 'europe-west1' # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "config['bucket'] = 'presentation-38388'  # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "config['pkg-name'] = 'pkg_mnist_fnn'\n",
    "config['tf-version'] = '1.13'\n",
    "config['env-name'] = 'env_gcp_dl'\n",
    "with open(\"config.yaml\", 'w', encoding= 'utf8') as f:\n",
    "      yaml.dump(config, stream=f,  default_flow_style=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**ML-Engine Environment Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Additional Environment Variables needed for ML-Engine\n",
    "- `PKG_NAME`: Package Name which will contain your model\n",
    "- `TF_VERSION`: Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket': 'presentation-38388',\n",
      " 'env-name': 'env_gcp_dl',\n",
      " 'pkg-name': 'pkg_mnist_fnn',\n",
      " 'project-id': 'presentation-38388',\n",
      " 'region': 'europe-west1',\n",
      " 'tf-version': '1.13'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Environment variables for project and bucket\n",
    "\n",
    "Note that:\n",
    "1. Your project id is the *unique* string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads:  \n",
    "     \n",
    "     - Project ID: ml-productive-pipeline-12345\n",
    "     \n",
    "2. Cloud training often involves saving and restoring model files. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available). A common pattern is to prefix the bucket name by the project id, so that it is unique. Also, for cost reasons, you might want to use a single region bucket.\n",
    "\n",
    "\n",
    "Add all detail in to [config.yaml](../config.yaml) file in main directory. Missing in public repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adding Environment Variables to your runtime\n",
    "- add variables **persistently**  to the runtime of your kernel from jupyter (or datalab)\n",
    "- use `os.environ` dictionary\n",
    "- behind a proxy, configure globally\n",
    "  - `REQUESTS_CA_BUNDLE`: optional, filepath to your SLL-certificate (works for `request`-package)\n",
    "  - `HTTPS_PROXY`: optional, link to your proxy, possibly includign authentification or ports\n",
    "- possiblity to set `environment variables` for user permanently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You run Windows -_-\n",
      "\n",
      "This means you are most probably on a Company Laptop and therefore behind a proxy.\n",
      "Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables\n"
     ]
    }
   ],
   "source": [
    "## setup env-variables \n",
    "import os\n",
    "import platform\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "#TEST_DATA_JSON = config['testdatafile'] # added later\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = PKG_NAME\n",
    "#os.environ['TEST_DATA_JSON'] = TEST_DATA_JSON\n",
    "# os.environ['ENV_NAME'] = config['env-name']\n",
    "if platform.system() == 'Windows':\n",
    "    from script.config_client import filepath_ssl_cert\n",
    "    print('You run Windows -_-\\n\\n''This means you are most probably on a Company Laptop and therefore behind a proxy.\\n'\n",
    "         'Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables')\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = filepath_ssl_cert # 'win-filepath\\to\\axa'\n",
    "    assert os.path.isfile(os.environ['REQUESTS_CA_BUNDLE']), \"SSL-File not found\"\n",
    "    assert os.environ.get(key='HTTPS_PROXY') != None, \"Set a proxy\"\n",
    "    #os.environ['HTTPS_PROXY'] = 'https://C219746:Alles-Ist-Besser2019@sc-wvs-ch-win-pr-01-vip1.ch.doleni.net:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Access Environment Variables**\n",
    "- Now, you can access the environement variable in the terminal where your jupyter, datalab or ipython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Using Tensorflow Version: $TFVERSION\"\n",
      "\"Using Tensorflow Version: 1.13\"\n"
     ]
    }
   ],
   "source": [
    "!echo \"Using Tensorflow Version: $TFVERSION\"\n",
    "!echo \"Using Tensorflow Version: %TFVERSION%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setup gcloud runtime\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION\n",
    "## ensure we predict locally with our current Python environment\n",
    "gcloud config set ml_engine/local_python `which python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "local_python = sys.executable\n",
    "%env PYTHON_LOCAL $local_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "gcloud config set project %PROJECT%\n",
    "gcloud config set compute/region %REGION%\n",
    "gcloud config set ml_engine/local_python \"%PYTHON_LOCAL%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Access Control \n",
    "\n",
    "- sign in and let clients pick up credentials from GCloud SDK (this stores a json with your credentials on your machine)\n",
    "    ```\n",
    "    gcloud auth application-default login\n",
    "    ```\n",
    "\n",
    "- Service Accounts ([Creating and Managing Service Accounts](https://cloud.google.com/iam/docs/creating-managing-service-accounts))\n",
    "  - need be assigned read/write permission to `BUCKET`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Load Data: Bigquery Client (DSP 2.2 )\n",
    "\n",
    "There are several python clients available, see list. Here we use `bigquery` to load some data.\n",
    "\n",
    "Picks up  PROXY_HTTPS, REQUESTS_CA_BUNDLE, PROJECT_ID from environment\n",
    "\n",
    "- set all relevant variables as user environment variables\n",
    "    1. search \"env\" in windows search bar (press windows button)\n",
    "    2. select \"Edit environment variables for your account\"\n",
    "    3. select \"new\" and add the PROXY_HTTPS, REQUESTS_CA_BUNDLE, PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Download from public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Current project in use: ml-productive-pipeline-53122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\google\\auth\\_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state gender  year      name  number\n",
      "0    TX      F  1910      Mary     895\n",
      "1    TX      F  1910      Ruby     314\n",
      "2    TX      F  1910     Annie     277\n",
      "3    TX      F  1910    Willie     260\n",
      "4    TX      F  1910      Ruth     252\n",
      "5    TX      F  1910    Gladys     240\n",
      "6    TX      F  1910     Maria     223\n",
      "7    TX      F  1910   Frances     197\n",
      "8    TX      F  1910  Margaret     194\n",
      "9    TX      F  1910     Helen     189\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.environ['PROJECT']\n",
    "print(\"# Current project in use: {}\\n\".format(PROJECT_ID))\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "    WHERE state = 'TX'\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "df = client.query(sql).to_dataframe()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Download from project table\n",
    "- use `test` Dataset with table `DATA` of project (has to be created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_776</th>\n",
       "      <th>feat_777</th>\n",
       "      <th>feat_778</th>\n",
       "      <th>feat_779</th>\n",
       "      <th>feat_780</th>\n",
       "      <th>feat_781</th>\n",
       "      <th>feat_782</th>\n",
       "      <th>feat_783</th>\n",
       "      <th>feat_784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0   51       0       0       0       0       0       0       0       0   \n",
       "1   68       0       0       0       0       0       0       0       0   \n",
       "2   75       0       0       0       0       0       0       0       0   \n",
       "3  118       0       0       0       0       0       0       0       0   \n",
       "4  121       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_9  ...  feat_776  feat_777  feat_778  feat_779  feat_780  feat_781  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   feat_782  feat_783  feat_784  label  \n",
       "0         0         0         0      0  \n",
       "1         0         0         0      0  \n",
       "2         0         0         0      0  \n",
       "3         0         0         0      0  \n",
       "4         0         0         0      0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `{project}.test.DATA`\n",
    "    LIMIT 15\n",
    "\"\"\".format(project=PROJECT)\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6903</td>\n",
       "      <td>7877</td>\n",
       "      <td>6990</td>\n",
       "      <td>7141</td>\n",
       "      <td>6824</td>\n",
       "      <td>6313</td>\n",
       "      <td>6876</td>\n",
       "      <td>7293</td>\n",
       "      <td>6825</td>\n",
       "      <td>6958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9\n",
       "count  6903  7877  6990  7141  6824  6313  6876  7293  6825  6958"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT COUNT(label) as count\n",
    "    FROM `{project}.test.DATA`\n",
    "    GROUP BY label\n",
    "\"\"\".format(project=PROJECT)\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Downloading the entire table to pandas\n",
    "- BQ Query Default limit of128MB maximum reponse size, see [quotas](https://cloud.google.com/bigquery/quotas), does not allow to download entire Table\n",
    "- [`bigquery_storage`](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas#install_the_client_libraries) client has to be used to download large datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!pip install --upgrade google-cloud-bigquery[pandas]\n",
    "!pip install --upgrade google-cloud-bigquery-storage[fastavro,pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT: ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage_v1beta1\n",
    "\n",
    "\n",
    "# Explicitly create a credentials object. This allows you to use the same\n",
    "# credentials for both the BigQuery and BigQuery Storage clients, avoiding\n",
    "# unnecessary API calls to fetch duplicate authentication tokens.\n",
    "credentials, project_id = google.auth.default(\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "\n",
    "print(\"PROJECT: {}\".format(project_id))\n",
    "\n",
    "# Make clients.\n",
    "client = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=project_id\n",
    ")\n",
    "bqstorageclient = bigquery_storage_v1beta1.BigQueryStorageClient(\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Download a table.\n",
    "table = bigquery.TableReference.from_string(\n",
    "    \"{project}.test.DATA\".format(project=PROJECT)\n",
    ")\n",
    "rows = client.list_rows(\n",
    "    table,\n",
    "    #selected_fields=[\n",
    "    #    bigquery.SchemaField(\"label\", \"INTEGER\")\n",
    "    #],\n",
    ")\n",
    "df = rows.to_dataframe(bqstorage_client=bqstorageclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 786)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_776</th>\n",
       "      <th>feat_777</th>\n",
       "      <th>feat_778</th>\n",
       "      <th>feat_779</th>\n",
       "      <th>feat_780</th>\n",
       "      <th>feat_781</th>\n",
       "      <th>feat_782</th>\n",
       "      <th>feat_783</th>\n",
       "      <th>feat_784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0   51       0       0       0       0       0       0       0       0   \n",
       "1   68       0       0       0       0       0       0       0       0   \n",
       "2   75       0       0       0       0       0       0       0       0   \n",
       "3  118       0       0       0       0       0       0       0       0   \n",
       "4  121       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_9  ...  feat_776  feat_777  feat_778  feat_779  feat_780  feat_781  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   feat_782  feat_783  feat_784  label  \n",
       "0         0         0         0      0  \n",
       "1         0         0         0      0  \n",
       "2         0         0         0      0  \n",
       "3         0         0         0      0  \n",
       "4         0         0         0      0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(file='data/mnist/raw/mnist_all', allow_pickle=True, arr=df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model: Packaging model (DSP 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Take your code and put into a standard Python package structure, see  [Recommended package structure](https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer#project-structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key-Idea: \n",
    " - define entry point which can be called\n",
    " - write all tasks as a function (callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    "Why a package?\n",
    " - can be called from other scripts `import model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `model.py`\n",
    "\n",
    "load most recent version, if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load src/pkg_mnist_fnn/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "# First try to start Cloud ML uing MNIST example.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from .utils import load_data\n",
    "##########################################################################\n",
    "#Factor into config:\n",
    "IMAGE_SHAPE = (28,28)\n",
    "N_PIXEL = 28 * 28\n",
    "NUM_LABELS = 10\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "##########################################################################\n",
    "def parse_images(x):\n",
    "    return x.reshape(len(x), -1).astype('float32')\n",
    "\n",
    "\n",
    "def parse_labels(y):\n",
    "    return y.astype('int32')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "\n",
    "\n",
    "def numpy_input_fn(images: np.ndarray,\n",
    "                   labels: np.ndarray,\n",
    "                   mode=tf.estimator.ModeKeys.EVAL):\n",
    "    \"\"\"\n",
    "    Return depending on the `mode`-key an Interator which can be use to feed into\n",
    "    the Estimator-Model. \n",
    "\n",
    "    Alternative if a `tf.data.Dataset` named `dataset` would be created:\n",
    "    `dataset.make_one_shot_iterator().get_next()`\n",
    "    \"\"\"\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        _epochs = EPOCHS\n",
    "        _shuffle = True\n",
    "        _num_threads = 2  # This leads to doubling the number of epochs\n",
    "    else:\n",
    "        _epochs = 1\n",
    "        _shuffle = False\n",
    "        _num_threads = 1\n",
    "\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        {'x': images},\n",
    "        y=labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_epochs=_epochs, # Boolean, if True shuffles the queue. \n",
    "                            # Avoid shuffle at prediction time.\n",
    "        # Boolean, if True shuffles the queue. Avoid shuffle at prediction\n",
    "        shuffle=_shuffle,\n",
    "        queue_capacity=1000, # Integer, number of threads used for reading\n",
    "        # and enqueueing. To have predicted order of reading and enqueueing, \n",
    "        # such as in prediction and evaluation mode, num_threads should be 1.\n",
    "        num_threads=_num_threads\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "```python\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\n",
    "    }\n",
    "    features = feature_placeholders\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "         features=features, \n",
    "         receiver_tensors=feature_placeholders,\n",
    "         receiver_tensors_alternatives=None\n",
    "         )\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "def train_and_evaluate(args):\n",
    "    \"\"\"\n",
    "    Utility function for distributed training on ML-Engine\n",
    "    www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \n",
    "    \"\"\"\n",
    "    # Load Data in Memoery\n",
    "    (x_train, y_train), (x_test, y_test) = load_data(\n",
    "        rel_path=args['data_path'])\n",
    "  \n",
    "    x_train = parse_images(x_train)\n",
    "    x_test = parse_images(x_test)\n",
    "\n",
    "    y_train = parse_labels(y_train)\n",
    "    y_test = parse_labels(y_test)\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "        hidden_units=[256, 128, 64],\n",
    "        feature_columns=[tf.feature_column.numeric_column(\n",
    "            'x', shape=[N_PIXEL, ])],\n",
    "        model_dir=args['output_dir'],\n",
    "        n_classes=10,\n",
    "        optimizer=tf.train.AdamOptimizer,\n",
    "        # activation_fn=,\n",
    "        dropout=0.2,\n",
    "        batch_norm=False,\n",
    "        loss_reduction='weighted_sum',\n",
    "        warm_start_from=None,\n",
    "        config = None\n",
    "    )   \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "    # see next slide\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "def train_and_evaluate(args):\n",
    "    \"\"\"\n",
    "    Utility function for distributed training on ML-Engine\n",
    "    www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \n",
    "    \"\"\"\n",
    "    # see previous slide\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "    # see previous slide\n",
    "    )   \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN),\n",
    "        max_steps=args['train_steps'],\n",
    "        hooks = None\n",
    "    )\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\n",
    "        steps=None,\n",
    "        start_delay_secs=args['eval_delay_secs'],\n",
    "        throttle_secs=args['min_eval_frequency'],\n",
    "        exporters=exporter\n",
    "    )\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `task.py`\n",
    "\n",
    "load most recent file using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load src/pkg_mnist_fnn/task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "\"\"\"\n",
    "Parse arguments and call main function\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "from .model import train_and_evaluate\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--data_path',\n",
    "        help='GCS or local path to training data',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help='GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_batch_size',\n",
    "        help='Batch size for training steps',\n",
    "        type=int,\n",
    "        default='128'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_steps',\n",
    "        help='Steps to run the training job for',\n",
    "        type=int,\n",
    "        default='200'\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    parser.add_argument(\n",
    "        '--hidden_units',\n",
    "        help='List of hidden layer sizes to use for DNN feature columns',\n",
    "        nargs='+',\n",
    "        type=int,\n",
    "        default=[128, 64, 32]\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job_dir',\n",
    "        help='this model ignores this field, but it is required by gcloud',\n",
    "        default='junk'\n",
    "    )\n",
    "    # Eval arguments\n",
    "    parser.add_argument(\n",
    "        '--eval_delay_secs',\n",
    "        help='How long to wait before running first evaluation',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min_eval_frequency',\n",
    "        help='Seconds between evaluations',\n",
    "        default=10,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    OUTDIR = args['output_dir']\n",
    "    # #######################################\n",
    "    # # Train and Evaluate (use TensorBoard to visualize)\n",
    "    train_and_evaluate(args)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train using ML-Engine on (DSP 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modeling and ML-Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gcp_training_options-overview.png](Images/gcp_training_options-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Environment Variables with absolut paths to relevant folders: \n",
    "    - `PWD`: where your project folder lies\n",
    "    - `PKG_NAME`: Self-Contained Package to be exported into `site-packages` in `venv`\n",
    "    - `trained`: Where to store checkpoints (logs, weights, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_local = os.path.join(os.getcwd(),'data', 'mnist', 'raw', 'mnist.npz')\n",
    "OUTDIR_local = os.path.join(os.getcwd(),'trained', PKG_NAME)\n",
    "os.environ['OUTDIR_LOCAL'] = OUTDIR_local\n",
    "os.environ['DATA_LOCAL'] = data_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Data Directory:\t C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\n",
      "Local Output Dir:\t C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\n"
     ]
    }
   ],
   "source": [
    "print(\"Local Data Directory:\\t {}\".format(os.environ['DATA_LOCAL']))\n",
    "print(\"Local Output Dir:\\t {}\".format(os.environ['OUTDIR_LOCAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Running the Python `module` without gcp ml-engine\n",
    "\n",
    "- Entry point is defined in `task.py`\n",
    "  - parses command line arguments \n",
    "- conda env has to be active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)\n",
    "os.listdir(OUTDIR_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m src.${PKG_NAME}.task \\\n",
    "   --data_path=$DATA_LOCAL \\\n",
    "   --output_dir=$OUTDIR_LOCAL \\\n",
    "   --train_steps=1000 \\\n",
    "   --job_dir=tmp\n",
    "echo \"Saved Model, ckpts, exported model to: $OUTDIR_LOCAL\"\n",
    "ls $OUTDIR_LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>activate %ENV_NAME%\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>conda.bat activate mnist \r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>python -m src.%PKG_NAME%.task ^\n",
      "More?    --data_path=%DATA_LOCAL% ^\n",
      "More?    --output_dir=%OUTDIR_LOCAL% ^\n",
      "More?    --train_steps=1500 ^\n",
      "More?    --job_dir=tmp\n",
      "Current Working direcotory:\tC:\\Users\\C219746\\gcp\\project\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': '128 32 4', \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': [128, 32, 4], \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "Save output to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "## load data, specified path to try: C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "Loaded data from C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "## start training and evaluation\r\n",
      "### save model, ckpts, etc. to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
      "\"Saved Model, ckpts, exported model to: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\"\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>dir %OUTDIR_LOCAL%\n",
      " Volume in drive C is Windows\r\n",
      " Volume Serial Number is 1CB1-4182\r\n",
      "\r\n",
      " Directory of C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\r\n",
      "\r\n",
      "15.04.2019  13:59    <DIR>          .\r\n",
      "15.04.2019  13:59    <DIR>          ..\r\n",
      "15.04.2019  13:59               266 checkpoint\r\n",
      "15.04.2019  13:59    <DIR>          eval\r\n",
      "15.04.2019  13:59           771'612 events.out.tfevents.1555329570.C054018\r\n",
      "15.04.2019  13:59    <DIR>          export\r\n",
      "15.04.2019  13:59           476'925 graph.pbtxt\r\n",
      "15.04.2019  13:59                16 model.ckpt-0.data-00000-of-00002\r\n",
      "15.04.2019  13:59         1'257'480 model.ckpt-0.data-00001-of-00002\r\n",
      "15.04.2019  13:59             1'018 model.ckpt-0.index\r\n",
      "15.04.2019  13:59           217'827 model.ckpt-0.meta\r\n",
      "15.04.2019  13:59                16 model.ckpt-1200.data-00000-of-00002\r\n",
      "15.04.2019  13:59         1'257'480 model.ckpt-1200.data-00001-of-00002\r\n",
      "15.04.2019  13:59             1'018 model.ckpt-1200.index\r\n",
      "15.04.2019  13:59           217'827 model.ckpt-1200.meta\r\n",
      "15.04.2019  13:59                16 model.ckpt-1500.data-00000-of-00002\r\n",
      "15.04.2019  13:59         1'257'480 model.ckpt-1500.data-00001-of-00002\r\n",
      "15.04.2019  13:59             1'018 model.ckpt-1500.index\r\n",
      "15.04.2019  13:59           217'827 model.ckpt-1500.meta\r\n",
      "15.04.2019  13:59                16 model.ckpt-400.data-00000-of-00002\r\n",
      "15.04.2019  13:59         1'257'480 model.ckpt-400.data-00001-of-00002\r\n",
      "15.04.2019  13:59             1'018 model.ckpt-400.index\r\n",
      "15.04.2019  13:59           217'827 model.ckpt-400.meta\r\n",
      "15.04.2019  13:59                16 model.ckpt-800.data-00000-of-00002\r\n",
      "15.04.2019  13:59         1'257'480 model.ckpt-800.data-00001-of-00002\r\n",
      "15.04.2019  13:59             1'018 model.ckpt-800.index\r\n",
      "15.04.2019  13:59           217'827 model.ckpt-800.meta\r\n",
      "              23 File(s)      8'630'508 bytes\r\n",
      "               4 Dir(s)  143'287'283'712 bytes free\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Colocations handled automatically by placer.\r\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\r\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n",
      "2019-04-15 13:59:31.421033: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use standard file APIs to check for files with this prefix.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python -m src.%PKG_NAME%.task ^\n",
    "   --data_path=%DATA_LOCAL% ^\n",
    "   --output_dir=%OUTDIR_LOCAL% ^\n",
    "   --train_steps=1500 ^\n",
    "   --job_dir=tmp\n",
    "echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
    "dir %OUTDIR_LOCAL%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Call hidden units parameter\n",
    "- change model architecture\n",
    "- here previous model is deleted -> later several model will be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\t/home/enryh/proj_DL_models_and_pipelines_with_GCP\n",
      "Arguments:\n",
      "{'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_151816', 'train_batch_size': 128, 'train_steps': 1000, 'hidden_units': '128 64 32', 'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\n",
      "Arguments:\n",
      "{'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_151816', 'train_batch_size': 128, 'train_steps': 1000, 'hidden_units': [128, 64, 32], 'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\n",
      "Save output to: gs://ml-productive-pipeline-53122/mnist_190322_151816/\n",
      "## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "1\n",
      "2\n",
      "Loaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "## start training and evaluation\n",
      "### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190322_151816/\n",
      "Saved Model, ckpts, exported model to: gs://ml-productive-pipeline-53122/mnist_190322_151816\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m src.${PKG_NAME}.task \\\n",
    "   --data_path    $DATA_LOCAL \\\n",
    "   --output_dir   $OUTDIR_LOCAL \\\n",
    "   --train_steps  1000 \\\n",
    "   --job_dir      tmp  \\\n",
    "   --train_batch_size   128 \\\n",
    "   --hidden_units \"128 64 32\"\n",
    "echo \"Saved Model, ckpts, exported model to: $OUTDIR_LOCAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>activate %ENV_NAME%\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>conda.bat activate mnist \r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>python -m src.%PKG_NAME%.task ^\n",
      "More?    --data_path=%DATA_LOCAL% ^\n",
      "More?    --output_dir=%OUTDIR_LOCAL% ^\n",
      "More?    --train_steps=1500 ^\n",
      "More?    --train_batch_size 128  ^\n",
      "More?    --hidden_units \"128 64 32\" ^\n",
      "More?    --job_dir=tmp\n",
      "Current Working direcotory:\tC:\\Users\\C219746\\gcp\\project\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': '128 64 32', \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': [128, 64, 32], \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "Save output to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "## load data, specified path to try: C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "Loaded data from C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "## start training and evaluation\r\n",
      "### save model, ckpts, etc. to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
      "\"Saved Model, ckpts, exported model to: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\"\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>dir %OUTDIR_LOCAL%\n",
      " Volume in drive C is Windows\r\n",
      " Volume Serial Number is 1CB1-4182\r\n",
      "\r\n",
      " Directory of C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\r\n",
      "\r\n",
      "15.04.2019  13:39    <DIR>          .\r\n",
      "15.04.2019  13:39    <DIR>          ..\r\n",
      "15.04.2019  13:39               266 checkpoint\r\n",
      "15.04.2019  13:39    <DIR>          eval\r\n",
      "15.04.2019  13:39           831'505 events.out.tfevents.1555328346.C054018\r\n",
      "15.04.2019  13:39    <DIR>          export\r\n",
      "15.04.2019  13:39           479'494 graph.pbtxt\r\n",
      "15.04.2019  13:39                16 model.ckpt-0.data-00000-of-00002\r\n",
      "15.04.2019  13:39         1'333'752 model.ckpt-0.data-00001-of-00002\r\n",
      "15.04.2019  13:39             1'021 model.ckpt-0.index\r\n",
      "15.04.2019  13:39           218'915 model.ckpt-0.meta\r\n",
      "15.04.2019  13:39                16 model.ckpt-1200.data-00000-of-00002\r\n",
      "15.04.2019  13:39         1'333'752 model.ckpt-1200.data-00001-of-00002\r\n",
      "15.04.2019  13:39             1'021 model.ckpt-1200.index\r\n",
      "15.04.2019  13:39           218'915 model.ckpt-1200.meta\r\n",
      "15.04.2019  13:39                16 model.ckpt-1500.data-00000-of-00002\r\n",
      "15.04.2019  13:39         1'333'752 model.ckpt-1500.data-00001-of-00002\r\n",
      "15.04.2019  13:39             1'021 model.ckpt-1500.index\r\n",
      "15.04.2019  13:39           218'915 model.ckpt-1500.meta\r\n",
      "15.04.2019  13:39                16 model.ckpt-400.data-00000-of-00002\r\n",
      "15.04.2019  13:39         1'333'752 model.ckpt-400.data-00001-of-00002\r\n",
      "15.04.2019  13:39             1'021 model.ckpt-400.index\r\n",
      "15.04.2019  13:39           218'915 model.ckpt-400.meta\r\n",
      "15.04.2019  13:39                16 model.ckpt-800.data-00000-of-00002\r\n",
      "15.04.2019  13:39         1'333'752 model.ckpt-800.data-00001-of-00002\r\n",
      "15.04.2019  13:39             1'021 model.ckpt-800.index\r\n",
      "15.04.2019  13:39           218'915 model.ckpt-800.meta\r\n",
      "              23 File(s)      9'079'785 bytes\r\n",
      "               4 Dir(s)  143'287'013'376 bytes free\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Colocations handled automatically by placer.\r\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\r\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n",
      "2019-04-15 13:39:07.231912: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use standard file APIs to check for files with this prefix.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python -m src.%PKG_NAME%.task ^\n",
    "   --data_path=%DATA_LOCAL% ^\n",
    "   --output_dir=%OUTDIR_LOCAL% ^\n",
    "   --train_steps=1500 ^\n",
    "   --train_batch_size 128  ^\n",
    "   --hidden_units \"128 64 32\" ^\n",
    "   --job_dir=tmp\n",
    "echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
    "dir %OUTDIR_LOCAL%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1555329587'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.normpath(\"{}/export/exporter\".format(OUTDIR_local)))[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**And we would be ready to deploy**\n",
    "\n",
    "... but of course not without looking at performance metrics or predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training using `gcloud ml-engine local train`\n",
    "\n",
    "- continue training using `ml-engine local`\n",
    "- needs full-paths for out-dir: Add `$PWD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=${PKG_NAME}.task \\\n",
    "   --package-path=src/${PKG_NAME} \\\n",
    "   -- \\\n",
    "   --data_path=$DATA \\d\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5500 \\\n",
    "   --job_dir=./tmp # not needed, but necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>activate  %ENV_NAME%\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>conda.bat activate mnist \r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine local train ^\n",
      "More?    --module-name=%PKG_NAME%.task ^\n",
      "More?    --package-path=src\\%PKG_NAME% ^\n",
      "More?    -- ^\n",
      "More?    --data_path=%DATA_LOCAL% ^\n",
      "More?    --output_dir=%OUTDIR_LOCAL% ^\n",
      "More?    --train_steps=1500 ^\n",
      "More?    --job_dir=.\\tmp \n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': '128 32 4', \"\r\n",
      " \"'job_dir': '.\\\\\\\\tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': [128, 32, 4], \"\r\n",
      " \"'job_dir': '.\\\\\\\\tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "Save output to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "## load data, specified path to try: C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "Loaded data from C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "## start training and evaluation\r\n",
      "### save model, ckpts, etc. to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>dir %OUTDIR_LOCAL%\n",
      " Volume in drive C is Windows\r\n",
      " Volume Serial Number is 1CB1-4182\r\n",
      "\r\n",
      " Directory of C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\r\n",
      "\r\n",
      "15.04.2019  14:00    <DIR>          .\r\n",
      "15.04.2019  14:00    <DIR>          ..\r\n",
      "15.04.2019  14:00               266 checkpoint\r\n",
      "15.04.2019  14:00    <DIR>          eval\r\n",
      "15.04.2019  14:00           770'308 events.out.tfevents.1555329629.C054018\r\n",
      "15.04.2019  14:00    <DIR>          export\r\n",
      "15.04.2019  14:00           476'925 graph.pbtxt\r\n",
      "15.04.2019  14:00                16 model.ckpt-0.data-00000-of-00002\r\n",
      "15.04.2019  14:00         1'257'480 model.ckpt-0.data-00001-of-00002\r\n",
      "15.04.2019  14:00             1'018 model.ckpt-0.index\r\n",
      "15.04.2019  14:00           217'827 model.ckpt-0.meta\r\n",
      "15.04.2019  14:00                16 model.ckpt-1200.data-00000-of-00002\r\n",
      "15.04.2019  14:00         1'257'480 model.ckpt-1200.data-00001-of-00002\r\n",
      "15.04.2019  14:00             1'018 model.ckpt-1200.index\r\n",
      "15.04.2019  14:00           217'827 model.ckpt-1200.meta\r\n",
      "15.04.2019  14:00                16 model.ckpt-1500.data-00000-of-00002\r\n",
      "15.04.2019  14:00         1'257'480 model.ckpt-1500.data-00001-of-00002\r\n",
      "15.04.2019  14:00             1'018 model.ckpt-1500.index\r\n",
      "15.04.2019  14:00           217'827 model.ckpt-1500.meta\r\n",
      "15.04.2019  14:00                16 model.ckpt-400.data-00000-of-00002\r\n",
      "15.04.2019  14:00         1'257'480 model.ckpt-400.data-00001-of-00002\r\n",
      "15.04.2019  14:00             1'018 model.ckpt-400.index\r\n",
      "15.04.2019  14:00           217'827 model.ckpt-400.meta\r\n",
      "15.04.2019  14:00                16 model.ckpt-800.data-00000-of-00002\r\n",
      "15.04.2019  14:00         1'257'480 model.ckpt-800.data-00001-of-00002\r\n",
      "15.04.2019  14:00             1'018 model.ckpt-800.index\r\n",
      "15.04.2019  14:00           217'827 model.ckpt-800.meta\r\n",
      "              23 File(s)      8'629'204 bytes\r\n",
      "               4 Dir(s)  143'287'263'232 bytes free\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Colocations handled automatically by placer.\r\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\r\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n",
      "2019-04-15 14:00:30.410230: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use standard file APIs to check for files with this prefix.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud ml-engine local train ^\n",
    "   --module-name=%PKG_NAME%.task ^\n",
    "   --package-path=src\\%PKG_NAME% ^\n",
    "   -- ^\n",
    "   --data_path=%DATA_LOCAL% ^\n",
    "   --output_dir=%OUTDIR_LOCAL% ^\n",
    "   --train_steps=1500 ^\n",
    "   --job_dir=.\\tmp \n",
    "dir %OUTDIR_LOCAL%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine local train  --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training Cloud using `gcloud ml-engine train`\n",
    "\n",
    "- a copy of the data is in Google Storage (buckets)\n",
    "- `gcloud ml-engine` output is saved to `OUTDIR`in Google Storage \n",
    "  - checkpoints (logs)\n",
    "  - model graph and weights\n",
    "- data is copied to Google Storage (see [console](https://console.cloud.google.com/))\n",
    "  \n",
    "> NOTE: No with-spaces behind line break symbol **\\**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs using 10000 steps: 21.3\n",
      "For ten epochs specify 4688 steps\n"
     ]
    }
   ],
   "source": [
    "# 10 epochs in global steps:\n",
    "steps = 10000\n",
    "batch_size = 128\n",
    "n_train = 60000\n",
    "print(\"Number of epochs using {} steps: {:.1f}\".format(steps, steps * batch_size / n_train))\n",
    "steps = int(60000 / 128 * 10) + 1\n",
    "print(\"For ten epochs specify {} steps\".format(steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Check: Does this account for parallel processes in input fct?\n",
    "- If global steps is done on two processes, the number doubles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME=mnist_190415_221908\n",
      "env: OUTDIR=gs://presentation-38388/mnist_190415_221908\n",
      "env: DATA=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "# Set JOBNAME environment variable\n",
    "import datetime\n",
    "JOBNAME = 'mnist_' + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "%env JOBNAME {JOBNAME}\n",
    "# Set new OUTPUT and DATA directory in GS\n",
    "OUTDIR = '/'.join(['gs:/', BUCKET, JOBNAME])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR $OUTDIR\n",
    "%env DATA $DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBNAME is  mnist_190411_191955\n",
      "env: OUTDIR=gs://ml-productive-pipeline-53122/mnist_190411_191955\n",
      "OUTDIR on GS: gs://ml-productive-pipeline-53122/mnist_190411_191955\n",
      "DATA on GS: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "os.environ['JOBNAME'] = JOBNAME\n",
    "print(\"JOBNAME is \", JOBNAME)\n",
    "\n",
    "#os.environ['OUTDIR'] = OUTDIR \n",
    "#os.environ['DATA'] = DATA\n",
    "print(\"OUTDIR on GS: {}\".format(OUTDIR))\n",
    "print(\"DATA on GS: {}\".format(DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp ${PWD}/data/mnist/raw/mnist.npz ${DATA}\n",
    "gsutil ls ${DATA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>gsutil -m cp %cd%\\data\\mnist\\raw\\mnist.npz %DATA%\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>gsutil -m cp %cd%\\data\\mnist\\raw\\mnist.npz %DATA%\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Proxy configuration is present in both the https_proxy\r\n",
      "environment variable and boto configuration, but configuration\r\n",
      "differs. boto configuration proxy values will be used. Differences\r\n",
      "detected:\r\n",
      "Boto proxy user: \"CHDOLENINET\\C219746\" differs from https_proxy proxy user: \"C219746\"\r\n",
      "Copying file://C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz [Content-Type=application/octet-stream]...\r\n",
      "/ [0/1 files][    0.0 B/ 11.0 MiB]   0% Done                                    \r",
      "-\r",
      "- [0/1 files][  2.1 MiB/ 11.0 MiB]  18% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/1 files][  5.4 MiB/ 11.0 MiB]  49% Done                                    \r",
      "/\r",
      "/ [0/1 files][  8.5 MiB/ 11.0 MiB]  77% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [1/1 files][ 11.0 MiB/ 11.0 MiB] 100% Done                                    \r",
      "\r\n",
      "Operation completed over 1 objects/11.0 MiB.                                     \r\n",
      "WARNING: Proxy configuration is present in both the https_proxy\r\n",
      "environment variable and boto configuration, but configuration\r\n",
      "differs. boto configuration proxy values will be used. Differences\r\n",
      "detected:\r\n",
      "Boto proxy user: \"CHDOLENINET\\C219746\" differs from https_proxy proxy user: \"C219746\"\r\n",
      "Copying file://C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz [Content-Type=application/octet-stream]...\r\n",
      "/ [0/1 files][    0.0 B/ 11.0 MiB]   0% Done                                    \r",
      "-\r",
      "- [0/1 files][  2.6 MiB/ 11.0 MiB]  23% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/1 files][  5.9 MiB/ 11.0 MiB]  54% Done                                    \r",
      "/\r",
      "/ [0/1 files][  9.0 MiB/ 11.0 MiB]  82% Done                                    \r",
      "-\r",
      "- [1/1 files][ 11.0 MiB/ 11.0 MiB] 100% Done                                    \r",
      "\\\r",
      "\r\n",
      "Operation completed over 1 objects/11.0 MiB.                                     \r\n"
     ]
    }
   ],
   "source": [
    "%%cmd \n",
    "gsutil -m cp %cd%\\data\\mnist\\raw\\mnist.npz %DATA%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Proxy configuration is present in both the https_proxy\n",
      "environment variable and boto configuration, but configuration\n",
      "differs. boto configuration proxy values will be used. Differences\n",
      "detected:\n",
      "Boto proxy user: \"CHDOLENINET\\C219746\" differs from https_proxy proxy user: \"C219746\"\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls \"gs://%BUCKET%/%PKG_NAME%/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!gsutil ls $DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ml-engine on cluster\n",
    "- decide which [tier](https://cloud.google.com/ml-engine/docs/tensorflow/machine-types#scale_tiers) to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TIER=STANDARD_1\n"
     ]
    }
   ],
   "source": [
    "%env TIER STANDARD_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/mnist_190411_192024 gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz europe-west1 mnist_190411_193009\n",
      "jobId: mnist_190411_193009\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [mnist_190411_193009] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_190411_193009\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190411_193009\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $OUTDIR $DATA $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=$PKG_NAME.task \\\n",
    "   --package-path=${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=$TIER \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --data_path=$DATA \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000 \\\n",
    "   --job_dir=$OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>echo \"OUT: %OUTDIR%, Region: %REGION%, JOBNAME: %JOBNAME%\"\n",
      "\"OUT: gs://ml-productive-pipeline-53122/mnist_190412_153749, Region: europe-west1, JOBNAME: mnist_190412_153749\"\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>gsutil -m rm -rf %OUTDIR%\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine jobs submit training %JOBNAME% ^\n",
      "More?    --region=%REGION% ^\n",
      "More?    --module-name=%PKG_NAME%.task ^\n",
      "More?    --package-path=src\\%PKG_NAME% ^\n",
      "More?    --staging-bucket=gs://%BUCKET% ^\n",
      "More?    --scale-tier=%TIER% ^\n",
      "More?    --python-version 3.5 ^\n",
      "More?    --runtime-version=%TFVERSION% ^\n",
      "More?    -- ^\n",
      "More?    --data_path=%DATA% ^\n",
      "More?    --output_dir=%OUTDIR% ^\n",
      "More?    --train_steps=1000 ^\n",
      "More?    --job_dir=%OUTDIR%/jobs \n",
      "jobId: mnist_190412_153749\r\n",
      "state: QUEUED\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Proxy configuration is present in both the https_proxy\r\n",
      "environment variable and boto configuration, but configuration\r\n",
      "differs. boto configuration proxy values will be used. Differences\r\n",
      "detected:\r\n",
      "Boto proxy user: \"CHDOLENINET\\C219746\" differs from https_proxy proxy user: \"C219746\"\r\n",
      "CommandException: 1 files/objects could not be removed.\r\n",
      "Job [mnist_190412_153749] submitted successfully.\r\n",
      "Your job is still active. You may view the status of your job with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs describe mnist_190412_153749\r\n",
      "\r\n",
      "or continue streaming the logs with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190412_153749\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "echo \"OUT: %OUTDIR%, Region: %REGION%, JOBNAME: %JOBNAME%\"\n",
    "gsutil -m rm -rf %OUTDIR%\n",
    "\n",
    "gcloud ml-engine jobs submit training %JOBNAME% ^\n",
    "   --region=%REGION% ^\n",
    "   --module-name=%PKG_NAME%.task ^\n",
    "   --package-path=src\\%PKG_NAME% ^\n",
    "   --staging-bucket=gs://%BUCKET% ^\n",
    "   --scale-tier=%TIER% ^\n",
    "   --python-version 3.5 ^\n",
    "   --runtime-version=%TFVERSION% ^\n",
    "   -- ^\n",
    "   --data_path=%DATA% ^\n",
    "   --output_dir=%OUTDIR% ^\n",
    "   --train_steps=1000 ^\n",
    "   --job_dir=%OUTDIR%/jobs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fetch logs from ml-engine job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-04-12T14:13:38Z'\n",
      "etag: RwSAC3JegPY=\n",
      "jobId: mnist_190412_153749\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "  - --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749\n",
      "  - --train_steps=1000\n",
      "  - --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "  packageUris:\n",
      "  - gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "  pythonModule: pkg_mnist_fnn.task\n",
      "  pythonVersion: '3.5'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.13'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/mnist_190412_153749?project=ml-productive-pipeline-53122\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fmnist_190412_153749&project=ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs describe %JOBNAME%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $JOBNAME\n",
    "gcloud ml-engine jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs stream-logs $JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-04-12 16:13:38 +0200\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-04-12 16:13:38 +0200\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-04-12 16:13:39 +0200\tservice\t\tJob mnist_190412_153749 is queued.\n",
      "INFO\t2019-04-12 16:13:40 +0200\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-04-12 16:16:46 +0200\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"worker\", \"index\": 1} --job={\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t}\n",
      "WARNING\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"worker\", \"index\": 0} --job={\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t}\n",
      "WARNING\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-1\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-1\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-1\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"ps\", \"index\": 1} --job={\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t}\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tmaster-replica-0\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tps-replica-1\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:29 +0200\tps-replica-1\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tps-replica-1\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tmaster-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:29 +0200\tmaster-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:31 +0200\tps-replica-1\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tps-replica-1\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tmaster-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tps-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tTF_CONFIG environment variable: {'environment': 'cloud', 'job': {'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'region': 'europe-west1', 'scale_tier': 'STANDARD_1', 'runtime_version': '1.13', 'python_version': '3.5', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'python_module': 'pkg_mnist_fnn.task'}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'type': 'worker', 'index': 1}, 'cluster': {'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tUsing config: {'_train_distribute': None, '_eval_distribute': None, '_num_worker_replicas': 5, '_save_summary_steps': 100, '_protocol': None, '_device_fn': None, '_experimental_distribute': None, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_save_checkpoints_secs': None, '_num_ps_replicas': 3, '_task_type': 'worker', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tdevice_filters: \"/job:worker/task:1\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t  }\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t, '_keep_checkpoint_every_n_hours': 1, '_is_chief': False, '_save_checkpoints_steps': 400, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f07abb07b70>, '_evaluation_master': '', '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_task_id': 1, '_master': 'grpc://cmle-training-worker-6fd0bbea02-1:2222', '_global_id_in_cluster': 2}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tXLA service 0x4a912e0 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> localhost:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tWaiting 10 secs before starting training.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tTF_CONFIG environment variable: {'job': {'scale_tier': 'STANDARD_1', 'region': 'europe-west1', 'python_module': 'pkg_mnist_fnn.task', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'python_version': '3.5', 'runtime_version': '1.13', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz']}, 'environment': 'cloud', 'cluster': {'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'task': {'index': 0, 'cloud': 'qe913eccfb8ab063b-ml', 'type': 'worker'}}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tUsing config: {'_is_chief': False, '_save_checkpoints_steps': 400, '_keep_checkpoint_every_n_hours': 1, '_keep_checkpoint_max': 5, '_service': None, '_save_summary_steps': 100, '_protocol': None, '_train_distribute': None, '_evaluation_master': '', '_save_checkpoints_secs': None, '_experimental_distribute': None, '_tf_random_seed': None, '_task_type': 'worker', '_num_ps_replicas': 3, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_task_id': 0, '_log_step_count_steps': 100, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tdevice_filters: \"/job:worker/task:0\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t  }\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t, '_eval_distribute': None, '_device_fn': None, '_num_worker_replicas': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fac5fe2fd30>, '_master': 'grpc://cmle-training-worker-6fd0bbea02-0:2222', '_global_id_in_cluster': 1}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tXLA service 0x3f47950 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tInitialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tWaiting 5 secs before starting training.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"ps\", \"index\": 2} --job={\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t}\n",
      "WARNING\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tTF_CONFIG environment variable: {'task': {'index': 1, 'cloud': 'qe913eccfb8ab063b-ml', 'type': 'ps'}, 'cluster': {'master': ['cmle-training-master-6fd0bbea02-0:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222']}, 'environment': 'cloud', 'job': {'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'region': 'europe-west1', 'python_module': 'pkg_mnist_fnn.task', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'runtime_version': '1.13', 'scale_tier': 'STANDARD_1', 'python_version': '3.5'}}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tUsing config: {'_save_summary_steps': 100, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_eval_distribute': None, '_log_step_count_steps': 100, '_task_id': 1, '_task_type': 'ps', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tdevice_filters: \"/job:worker\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tdevice_filters: \"/job:chief\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t  }\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t, '_keep_checkpoint_every_n_hours': 1, '_protocol': None, '_tf_random_seed': None, '_train_distribute': None, '_save_checkpoints_steps': 400, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc23ad2fe48>, '_num_ps_replicas': 3, '_experimental_distribute': None, '_evaluation_master': '', '_num_worker_replicas': 5, '_keep_checkpoint_max': 5, '_is_chief': False, '_device_fn': None, '_master': 'grpc://cmle-training-ps-6fd0bbea02-1:2222', '_global_id_in_cluster': 6, '_save_checkpoints_secs': None, '_service': None}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tXLA service 0x465af00 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> localhost:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:38 +0200\tps-replica-2\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:38 +0200\tps-replica-2\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:38 +0200\tps-replica-2\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tTF_CONFIG environment variable: {'cluster': {'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'job': {'scale_tier': 'STANDARD_1', 'runtime_version': '1.13', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'python_module': 'pkg_mnist_fnn.task', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'region': 'europe-west1', 'python_version': '3.5'}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'master'}, 'environment': 'cloud'}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tUsing config: {'_protocol': None, '_num_ps_replicas': 3, '_keep_checkpoint_every_n_hours': 1, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faa29ec3a20>, '_num_worker_replicas': 5, '_task_id': 0, '_evaluation_master': '', '_task_type': 'master', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t  }\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t, '_experimental_distribute': None, '_log_step_count_steps': 100, '_save_checkpoints_steps': 400, '_global_id_in_cluster': 0, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': None, '_device_fn': None, '_service': None, '_train_distribute': None, '_is_chief': True, '_keep_checkpoint_max': 5, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_master': 'grpc://cmle-training-master-6fd0bbea02-0:2222'}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tXLA service 0x57d7a50 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tInitialize GrpcChannelCache for job master -> {0 -> localhost:2222}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tStarted server with target: grpc://localhost:2222\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tCalling model_fn.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-2\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-2\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tCalling model_fn.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tworker-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tworker-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-2\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"ps\", \"index\": 0} --job={\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t}\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"worker\", \"index\": 3} --job={\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t}\n",
      "WARNING\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:43 +0200\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tworker-replica-3\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:43 +0200\tworker-replica-3\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tworker-replica-3\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tCalling model_fn.\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-1\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-1\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-3\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-3\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-1\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:48 +0200\tps-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tTF_CONFIG environment variable: {'task': {'index': 2, 'type': 'ps', 'cloud': 'qe913eccfb8ab063b-ml'}, 'environment': 'cloud', 'cluster': {'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'job': {'python_version': '3.5', 'python_module': 'pkg_mnist_fnn.task', 'scale_tier': 'STANDARD_1', 'runtime_version': '1.13', 'region': 'europe-west1', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz']}}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tUsing config: {'_num_ps_replicas': 3, '_num_worker_replicas': 5, '_is_chief': False, '_save_checkpoints_secs': None, '_save_checkpoints_steps': 400, '_master': 'grpc://cmle-training-ps-6fd0bbea02-2:2222', '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_device_fn': None, '_protocol': None, '_evaluation_master': '', '_experimental_distribute': None, '_eval_distribute': None, '_keep_checkpoint_every_n_hours': 1, '_global_id_in_cluster': 7, '_task_id': 2, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8a490a47f0>, '_save_summary_steps': 100, '_service': None, '_train_distribute': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_type': 'ps', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tdevice_filters: \"/job:worker\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tdevice_filters: \"/job:chief\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t  }\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tXLA service 0x3d43390 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> localhost:2222}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tTF_CONFIG environment variable: {'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'ps'}, 'cluster': {'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'job': {'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'region': 'europe-west1', 'runtime_version': '1.13', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'python_module': 'pkg_mnist_fnn.task', 'scale_tier': 'STANDARD_1', 'python_version': '3.5'}, 'environment': 'cloud'}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tUsing config: {'_master': 'grpc://cmle-training-ps-6fd0bbea02-0:2222', '_num_worker_replicas': 5, '_task_id': 0, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tdevice_filters: \"/job:worker\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tdevice_filters: \"/job:chief\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t  }\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t, '_task_type': 'ps', '_service': None, '_keep_checkpoint_every_n_hours': 1, '_save_summary_steps': 100, '_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feef75ffbe0>, '_evaluation_master': '', '_save_checkpoints_secs': None, '_train_distribute': None, '_log_step_count_steps': 100, '_is_chief': False, '_save_checkpoints_steps': 400, '_device_fn': None, '_experimental_distribute': None, '_global_id_in_cluster': 5, '_tf_random_seed': None, '_num_ps_replicas': 3, '_keep_checkpoint_max': 5, '_protocol': None, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/'}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tXLA service 0x55536d0 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tInitialize GrpcChannelCache for job ps -> {0 -> localhost:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tTF_CONFIG environment variable: {'job': {'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'region': 'europe-west1', 'python_module': 'pkg_mnist_fnn.task', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'python_version': '3.5', 'runtime_version': '1.13', 'scale_tier': 'STANDARD_1'}, 'environment': 'cloud', 'cluster': {'master': ['cmle-training-master-6fd0bbea02-0:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222']}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'type': 'worker', 'index': 3}}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tUsing config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4898bfab38>, '_eval_distribute': None, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_tf_random_seed': None, '_num_ps_replicas': 3, '_protocol': None, '_num_worker_replicas': 5, '_train_distribute': None, '_task_type': 'worker', '_service': None, '_global_id_in_cluster': 4, '_keep_checkpoint_every_n_hours': 1, '_task_id': 3, '_evaluation_master': '', '_log_step_count_steps': 100, '_experimental_distribute': None, '_is_chief': False, '_save_checkpoints_secs': None, '_master': 'grpc://cmle-training-worker-6fd0bbea02-3:2222', '_keep_checkpoint_max': 5, '_device_fn': None, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tdevice_filters: \"/job:worker/task:3\"\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t  }\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t, '_save_summary_steps': 100, '_save_checkpoints_steps': 400}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tXLA service 0x3fd8090 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> localhost:2222}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tWaiting 20 secs before starting training.\n",
      "INFO\t2019-04-12 16:18:55 +0200\tworker-replica-1\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "INFO\t2019-04-12 16:18:55 +0200\tworker-replica-1\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:18:56 +0200\tworker-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "INFO\t2019-04-12 16:18:56 +0200\tworker-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:04 +0200\tmaster-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "INFO\t2019-04-12 16:19:04 +0200\tmaster-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:05 +0200\tworker-replica-1\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:06 +0200\tworker-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tCalling model_fn.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tStart master session 2a25f093cd1877cd with config: device_filters: \"/job:ps\" device_filters: \"/job:master\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-1\t\tStart master session 8c0509f64cefc812 with config: device_filters: \"/job:ps\" device_filters: \"/job:worker/task:1\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-1\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-3\t\tStart master session 11710010415a2106 with config: device_filters: \"/job:ps\" device_filters: \"/job:worker/task:3\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-1\t\tDone running local_init_op.\n",
      "WARNING\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tStart master session 2e2cf98c9665ece2 with config: device_filters: \"/job:ps\" device_filters: \"/job:worker/task:0\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tDone running local_init_op.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tRunning local_init_op.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tDone running local_init_op.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tloss = 6070.0254, step = 0\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tloss = 4008.1248, step = 1\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tloss = 1838.0073, step = 7\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tglobal_step/sec: 262.216\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-1\t\tloss = 306.47083, step = 221 (0.975 sec)\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tglobal_step/sec: 311.923\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-3\t\tloss = 306.78598, step = 297 (1.109 sec)\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tglobal_step/sec: 307.463\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tloss = 293.81055, step = 439 (1.526 sec)\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tglobal_step/sec: 288.177\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-1\t\tloss = 310.63556, step = 468 (0.826 sec)\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tglobal_step/sec: 314.457\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-3\t\tloss = 294.56342, step = 587 (0.962 sec)\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tglobal_step/sec: 315.897\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-1\t\tloss = 282.3244, step = 731 (0.840 sec)\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tglobal_step/sec: 317.1\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tloss = 277.44867, step = 789 (1.106 sec)\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-0\t\tglobal_step/sec: 292.684\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tloss = 274.37057, step = 887 (0.975 sec)\n",
      "INFO\t2019-04-12 16:19:18 +0200\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt.\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-0\t\tglobal_step/sec: 323.354\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tloss = 257.42102, step = 991 (0.832 sec)\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tLoss for final step: 295.44537.\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t{'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_steps': 1000, 'eval_delay_secs': 1, 'train_batch_size': 128, 'hidden_units': '128 32 4', 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz'}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t{'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_steps': 1000, 'eval_delay_secs': 1, 'train_batch_size': 128, 'hidden_units': [128, 32, 4], 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz'}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tLoss for final step: 261.01215.\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t{'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'train_steps': 1000, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'hidden_units': '128 32 4', 'eval_delay_secs': 1}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t{'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'train_steps': 1000, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'hidden_units': [128, 32, 4], 'eval_delay_secs': 1}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-3\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-3\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-3\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-1\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-1\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-1\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tLoss for final step: 292.49524.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t{'train_steps': 1000, 'hidden_units': '128 32 4', 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_batch_size': 128, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t{'train_steps': 1000, 'hidden_units': [128, 32, 4], 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_batch_size': 128, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:20 +0200\tworker-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:19:20 +0200\tworker-replica-0\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:19:20 +0200\tworker-replica-0\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:19:40 +0200\tmaster-replica-0\t\tSaving checkpoints for 1005 into gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tStarting evaluation at 2019-04-12T14:20:02Z\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tGraph was finalized.\n",
      "WARNING\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tUse standard file APIs to check for files with this prefix.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt-1005\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [10/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [20/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [30/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [40/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [50/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [60/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [70/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tFinished evaluation at 2019-04-12-14:20:06\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tSaving dict for global step 1005: accuracy = 0.2071, average_loss = 1.9944633, global_step = 1005, loss = 252.4637\n",
      "INFO\t2019-04-12 16:20:10 +0200\tmaster-replica-0\t\tSaving 'checkpoint_path' summary for global step 1005: gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt-1005\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tDone calling model_fn.\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tExport includes no default signature!\n",
      "INFO\t2019-04-12 16:20:16 +0200\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt-1005\n",
      "INFO\t2019-04-12 16:20:17 +0200\tmaster-replica-0\t\tAssets added to graph.\n",
      "INFO\t2019-04-12 16:20:17 +0200\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2019-04-12 16:20:31 +0200\tmaster-replica-0\t\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190412_153749/export/exporter/temp-b'1555078811'/saved_model.pb\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tloss = 268.05585, step = 1004\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tLoss for final step: 268.05585.\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t{'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'eval_delay_secs': 1, 'min_eval_frequency': 5, 'train_steps': 1000, 'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'hidden_units': '128 32 4', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t{'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'eval_delay_secs': 1, 'min_eval_frequency': 5, 'train_steps': 1000, 'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'hidden_units': [128, 32, 4], 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:20:53 +0200\tservice\t\tTearing down training program.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-0\t\tTerminated by service. If the job is supposed to continue running, it will be restarted on other VM shortly.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-0\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-1\t\tTerminated by service. If the job is supposed to continue running, it will be restarted on other VM shortly.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-1\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-1\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-2\t\tTerminated by service. If the job is supposed to continue running, it will be restarted on other VM shortly.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-2\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-2\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:21:47 +0200\tservice\t\tFinished tearing down training program.\n",
      "INFO\t2019-04-12 16:21:48 +0200\tservice\t\tJob completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs stream-logs %JOBNAME%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Don't be concerned if the notebook appears stalled (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud. \n",
    "\n",
    "**Use the Cloud Console link to monitor the job and do NOT proceed until the job is done.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Check out results in the logs, see [example](https://cloud.google.com/solutions/machine-learning/recommendation-system-tensorflow-train-cloud-ml-engine#results_of_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML-Engine with Hyperparameter search\n",
    "- Bayesian approach to find optimal hyperparameters, see \n",
    "    > Golovin et.al (2017): Google Vizier: A Service for Black-Box Optimization\n",
    "- consecutive search, here\n",
    "    - 2 trials in parallel\n",
    "    - a total of 30 trials\n",
    "- see `hyperp_config.yaml`:\n",
    "    - `train_batch_size`\n",
    "    - `hidden_units`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Configure Search in  `hyperp_config.yaml`:\n",
    "```python\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    hyperparameterMetricTag: accuracy\n",
    "    maxTrials: 16\n",
    "    maxParallelTrials: 2\n",
    "    params:\n",
    "      - parameterName: train_batch_size\n",
    "        type: INTEGER\n",
    "        minValue: 64\n",
    "        maxValue: 512\n",
    "        scaleType: UNIT_LOG_SCALE\n",
    "      - parameterName: hidden_units\n",
    "        type: CATEGORICAL\n",
    "        categoricalValues: [\"128 64 32\", \"256 128 64\", \"512 256 128 64\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load hyperp_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Create unique `JOBNAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBNAME  mnist_190322_155703\n",
      "OUTDIR on GS: gs://ml-productive-pipeline-53122/mnist_190322_155703\n",
      "DATA on GS: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "# Set JOBNAME environment variable\n",
    "import datetime\n",
    "%env JOBNAME {'mnist_' + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")}\n",
    "# Set new OUTPUT and DATA directory in GS\n",
    "OUTDIR = '/'.join(['gs:/', BUCKET, JOBNAME])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR $OUTDIR\n",
    "%env DATA $DATA\n",
    "%env TIER STANDARD_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Start Bayesian Hyperparameter Search:\n",
    "\n",
    "- add `config` parameter with `hyperp_config.yaml` as argument:\n",
    "- one can add other parameter to `hyperp_config.yaml`, see [docs on submitting](https://cloud.google.com/ml-engine/docs/tensorflow/training-jobs#formatting_your_configuration_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "echo %OUTDIR %DATA% %REGION% %JOBNAME%\n",
    "#gsutil -m rm -rf %OUTDIR%\n",
    "gcloud ml-engine jobs submit training %JOBNAME% ^\n",
    "   --region %REGION% ^\n",
    "   --module-name %PKG_NAME%.task ^\n",
    "   --package-path %cd%/src/%PKG_NAME% ^\n",
    "   --staging-bucket gs://%BUCKET% ^\n",
    "   --scale-tier %TIER% ^\n",
    "   --python-version 3.5 ^\n",
    "   --runtime-version %TFVERSION% ^\n",
    "   --config hyperp_config.yaml ^\n",
    "   -- ^\n",
    "   --data_path %DATA% ^\n",
    "   --output_dir %OUTDIR% ^\n",
    "   --train_steps 5000 ^\n",
    "   --job_dir %OUTDIR%/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/mnist_190322_155703 gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz europe-west1 mnist_190322_155703\n",
      "jobId: mnist_190322_155703\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [mnist_190322_155703] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_190322_155703\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190322_155703\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $OUTDIR $DATA $REGION $JOBNAME\n",
    "#gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region $REGION \\\n",
    "   --module-name $PKG_NAME.task \\\n",
    "   --package-path ${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket gs://$BUCKET \\\n",
    "   --scale-tier $TIER \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version $TFVERSION \\\n",
    "   --config hyperp_config.yaml \\\n",
    "   -- \\\n",
    "   --data_path $DATA \\\n",
    "   --output_dir $OUTDIR \\\n",
    "   --train_steps 5000 \\\n",
    "   --job_dir $OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 15:57:15 +0100\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-03-22 15:57:15 +0100\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-03-22 15:57:15 +0100\tservice\t\tJob mnist_190322_155703 is queued.\n",
      "INFO\t2019-03-22 15:57:24 +0100\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-03-22 15:57:24 +0100\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-03-22 15:57:31 +0100\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-03-22 15:57:31 +0100\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-03-22 15:58:53 +0100\tmaster-replica-0\t1\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0, \"trial\": \"1\"} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\"],  \"python_module\": \"pkg_mnist_fnn.task\",  \"args\": [\"--data_path\", \"gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703\", \"--train_steps\", \"5000\", \"--job_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs\"],  \"hyperparameters\": {    \"goal\": \"MAXIMIZE\",    \"params\": [{      \"parameter_name\": \"train_batch_size\",      \"min_value\": 64.0,      \"max_value\": 512.0,      \"type\": \"INTEGER\",      \"scale_type\": \"UNIT_LOG_SCALE\"    }, {      \"parameter_name\": \"hidden_units\",      \"type\": \"CATEGORICAL\",      \"categorical_values\": [\"128 64 32\", \"256 128 64\", \"512 256 128 64\"]    }],    \"max_trials\": 4,    \"max_parallel_trials\": 2,    \"hyperparameter_metric_tag\": \"accuracy\"  },  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"} --hyperparams={\"hidden_units\":\"128 64 32\",\"train_batch_size\":\"314\"}\n",
      "INFO\t2019-03-22 15:58:53 +0100\tmaster-replica-0\t2\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0, \"trial\": \"2\"} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\"],  \"python_module\": \"pkg_mnist_fnn.task\",  \"args\": [\"--data_path\", \"gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703\", \"--train_steps\", \"5000\", \"--job_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs\"],  \"hyperparameters\": {    \"goal\": \"MAXIMIZE\",    \"params\": [{      \"parameter_name\": \"train_batch_size\",      \"min_value\": 64.0,      \"max_value\": 512.0,      \"type\": \"INTEGER\",      \"scale_type\": \"UNIT_LOG_SCALE\"    }, {      \"parameter_name\": \"hidden_units\",      \"type\": \"CATEGORICAL\",      \"categorical_values\": [\"128 64 32\", \"256 128 64\", \"512 256 128 64\"]    }],    \"max_trials\": 4,    \"max_parallel_trials\": 2,    \"hyperparameter_metric_tag\": \"accuracy\"  },  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"} --hyperparams={\"hidden_units\":\"256 128 64\",\"train_batch_size\":\"165\"}\n",
      "INFO\t2019-03-22 15:59:02 +0100\tmaster-replica-0\t2\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-03-22 15:59:02 +0100\tmaster-replica-0\t2\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:02 +0100\tmaster-replica-0\t2\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:02 +0100\tmaster-replica-0\t1\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-03-22 15:59:02 +0100\tmaster-replica-0\t1\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:02 +0100\tmaster-replica-0\t1\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:04 +0100\tmaster-replica-0\t2\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:04 +0100\tmaster-replica-0\t2\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:04 +0100\tmaster-replica-0\t1\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:04 +0100\tmaster-replica-0\t1\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:06 +0100\tmaster-replica-0\t2\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:06 +0100\tmaster-replica-0\t1\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:07 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 15:59:07 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:07 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 15:59:07 +0100\tmaster-replica-0\t2\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:07 +0100\tmaster-replica-0\t2\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 15:59:07 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t1\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 15:59:08 +0100\tmaster-replica-0\t2\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t1\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t2\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t1\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t2\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t2\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 15:59:09 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t1\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t1\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t2\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t2\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t2\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t1\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t1\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 15:59:10 +0100\tmaster-replica-0\t1\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t2\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t2\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t1\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t1\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t2\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t2\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t1\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t1\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t2\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 15:59:12 +0100\tmaster-replica-0\t1\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 15:59:13 +0100\tmaster-replica-0\t2\tRunning command: python3 -m pkg_mnist_fnn.task --data_path gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir gs://ml-productive-pipeline-53122/mnist_190322_155703 --train_steps 5000 --job_dir gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs --hidden_units 256 128 64 --train_batch_size 165\n",
      "INFO\t2019-03-22 15:59:13 +0100\tmaster-replica-0\t1\tRunning command: python3 -m pkg_mnist_fnn.task --data_path gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir gs://ml-productive-pipeline-53122/mnist_190322_155703 --train_steps 5000 --job_dir gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs --hidden_units 128 64 32 --train_batch_size 314\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tTF_CONFIG environment variable: {'job': {'args': ['--data_path', 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703', '--train_steps', '5000', '--job_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', '--hidden_units', '256 128 64', '--train_batch_size', '165'], 'python_version': '3.5', 'region': 'europe-west1', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz'], 'runtime_version': '1.12', 'python_module': 'pkg_mnist_fnn.task', 'hyperparameters': {'hyperparameter_metric_tag': 'accuracy', 'max_trials': 4, 'params': [{'scale_type': 'UNIT_LOG_SCALE', 'min_value': 64.0, 'type': 'INTEGER', 'parameter_name': 'train_batch_size', 'max_value': 512.0}, {'parameter_name': 'hidden_units', 'type': 'CATEGORICAL', 'categorical_values': ['128 64 32', '256 128 64', '512 256 128 64']}], 'goal': 'MAXIMIZE', 'max_parallel_trials': 2}, 'run_on_raw_vm': True}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'master', 'trial': '2'}, 'environment': 'cloud', 'cluster': {'master': ['127.0.0.1:2222']}}\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tUsing config: {'_device_fn': None, '_save_checkpoints_secs': None, '_experimental_distribute': None, '_protocol': None, '_evaluation_master': '', '_num_worker_replicas': 1, '_train_distribute': None, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/2', '_num_ps_replicas': 0, '_save_checkpoints_steps': 400, '_is_chief': True, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 1, '_master': '', '_keep_checkpoint_max': 5, '_service': None, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tallow_soft_placement: true\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tgraph_options {\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\t  rewrite_options {\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\t  }\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\t}\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\t, '_eval_distribute': None, '_task_id': 0, '_task_type': 'master', '_tf_random_seed': None, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5b27207f28>, '_global_id_in_cluster': 0}\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tNot using Distribute Coordinator.\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\tTF_CONFIG environment variable: {'job': {'python_module': 'pkg_mnist_fnn.task', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz'], 'python_version': '3.5', 'run_on_raw_vm': True, 'hyperparameters': {'goal': 'MAXIMIZE', 'max_parallel_trials': 2, 'params': [{'min_value': 64.0, 'max_value': 512.0, 'scale_type': 'UNIT_LOG_SCALE', 'parameter_name': 'train_batch_size', 'type': 'INTEGER'}, {'categorical_values': ['128 64 32', '256 128 64', '512 256 128 64'], 'parameter_name': 'hidden_units', 'type': 'CATEGORICAL'}], 'hyperparameter_metric_tag': 'accuracy', 'max_trials': 4}, 'region': 'europe-west1', 'runtime_version': '1.12', 'args': ['--data_path', 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703', '--train_steps', '5000', '--job_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', '--hidden_units', '128 64 32', '--train_batch_size', '314']}, 'cluster': {'master': ['127.0.0.1:2222']}, 'task': {'index': 0, 'type': 'master', 'trial': '1', 'cloud': 'qe913eccfb8ab063b-ml'}, 'environment': 'cloud'}\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\tUsing config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcd90d5d7b8>, '_experimental_distribute': None, '_keep_checkpoint_max': 5, '_device_fn': None, '_evaluation_master': '', '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/1', '_task_type': 'master', '_tf_random_seed': None, '_task_id': 0, '_eval_distribute': None, '_save_summary_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_num_worker_replicas': 1, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\tallow_soft_placement: true\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\tgraph_options {\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\t  rewrite_options {\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\t  }\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\t}\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\t, '_is_chief': True, '_save_checkpoints_secs': None, '_protocol': None, '_keep_checkpoint_every_n_hours': 1, '_save_checkpoints_steps': 400, '_master': '', '_log_step_count_steps': 100, '_train_distribute': None, '_num_ps_replicas': 0}\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\tNot using Distribute Coordinator.\n",
      "INFO\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t1\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "WARNING\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-03-22 15:59:16 +0100\tmaster-replica-0\t2\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 15:59:17 +0100\tmaster-replica-0\t2\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-03-22 15:59:18 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 15:59:18 +0100\tmaster-replica-0\t1\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-03-22 15:59:21 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 15:59:21 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 15:59:21 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "WARNING\t2019-03-22 15:59:21 +0100\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 15:59:21 +0100\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-03-22 15:59:21 +0100\tmaster-replica-0\t2\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 15:59:21 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 15:59:22 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 15:59:22 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "WARNING\t2019-03-22 15:59:22 +0100\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 15:59:22 +0100\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-03-22 15:59:22 +0100\tmaster-replica-0\t1\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 15:59:24 +0100\tmaster-replica-0\t2\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 15:59:24 +0100\tmaster-replica-0\t1\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 15:59:38 +0100\tmaster-replica-0\t2\tloss = 14088.875, step = 1\n",
      "INFO\t2019-03-22 15:59:39 +0100\tmaster-replica-0\t1\tloss = 16889.828, step = 1\n",
      "INFO\t2019-03-22 15:59:39 +0100\tmaster-replica-0\t2\tglobal_step/sec: 102.938\n",
      "INFO\t2019-03-22 15:59:39 +0100\tmaster-replica-0\t2\tloss = 222.19196, step = 101 (0.972 sec)\n",
      "INFO\t2019-03-22 15:59:40 +0100\tmaster-replica-0\t1\tglobal_step/sec: 128.57\n",
      "INFO\t2019-03-22 15:59:40 +0100\tmaster-replica-0\t1\tloss = 383.96838, step = 101 (0.779 sec)\n",
      "INFO\t2019-03-22 15:59:40 +0100\tmaster-replica-0\t2\tglobal_step/sec: 116.747\n",
      "INFO\t2019-03-22 15:59:40 +0100\tmaster-replica-0\t2\tloss = 190.41492, step = 201 (0.856 sec)\n",
      "INFO\t2019-03-22 15:59:40 +0100\tmaster-replica-0\t1\tglobal_step/sec: 145.006\n",
      "INFO\t2019-03-22 15:59:40 +0100\tmaster-replica-0\t1\tloss = 204.21902, step = 201 (0.690 sec)\n",
      "INFO\t2019-03-22 15:59:41 +0100\tmaster-replica-0\t2\tglobal_step/sec: 100.476\n",
      "INFO\t2019-03-22 15:59:41 +0100\tmaster-replica-0\t2\tloss = 112.849174, step = 301 (0.995 sec)\n",
      "INFO\t2019-03-22 15:59:41 +0100\tmaster-replica-0\t1\tglobal_step/sec: 134.477\n",
      "INFO\t2019-03-22 15:59:41 +0100\tmaster-replica-0\t1\tloss = 169.19995, step = 301 (0.744 sec)\n",
      "INFO\t2019-03-22 15:59:42 +0100\tmaster-replica-0\t1\tSaving checkpoints for 400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 15:59:42 +0100\tmaster-replica-0\t2\tSaving checkpoints for 400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-14:59:57\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-14:59:57\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 15:59:57 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 15:59:58 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-400\n",
      "INFO\t2019-03-22 15:59:58 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-400\n",
      "INFO\t2019-03-22 15:59:59 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:00:00\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t1\tSaving dict for global step 400: accuracy = 0.8161, average_loss = 0.70312846, global_step = 400, loss = 89.0036\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:00:00\n",
      "INFO\t2019-03-22 16:00:00 +0100\tmaster-replica-0\t2\tSaving dict for global step 400: accuracy = 0.8904, average_loss = 0.401438, global_step = 400, loss = 50.814934\n",
      "INFO\t2019-03-22 16:00:04 +0100\tmaster-replica-0\t2\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-03-22 16:00:04 +0100\tmaster-replica-0\t1\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-03-22 16:00:05 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 400: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-400\n",
      "INFO\t2019-03-22 16:00:05 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 400: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-400\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:00:09 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-400\n",
      "INFO\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-400\n",
      "WARNING\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t2\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "WARNING\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t1\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:00:10 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:00:23 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553266806'/saved_model.pb\n",
      "INFO\t2019-03-22 16:00:23 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553266806'/saved_model.pb\n",
      "INFO\t2019-03-22 16:00:28 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.11142\n",
      "INFO\t2019-03-22 16:00:28 +0100\tmaster-replica-0\t2\tloss = 108.887215, step = 401 (47.362 sec)\n",
      "INFO\t2019-03-22 16:00:29 +0100\tmaster-replica-0\t2\tglobal_step/sec: 96.4074\n",
      "INFO\t2019-03-22 16:00:29 +0100\tmaster-replica-0\t2\tloss = 96.10785, step = 501 (1.037 sec)\n",
      "INFO\t2019-03-22 16:00:30 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.06609\n",
      "INFO\t2019-03-22 16:00:30 +0100\tmaster-replica-0\t1\tloss = 146.3831, step = 401 (48.401 sec)\n",
      "INFO\t2019-03-22 16:00:30 +0100\tmaster-replica-0\t2\tglobal_step/sec: 96.77\n",
      "INFO\t2019-03-22 16:00:30 +0100\tmaster-replica-0\t2\tloss = 90.901245, step = 601 (1.033 sec)\n",
      "INFO\t2019-03-22 16:00:30 +0100\tmaster-replica-0\t1\tglobal_step/sec: 132.223\n",
      "INFO\t2019-03-22 16:00:30 +0100\tmaster-replica-0\t1\tloss = 139.68951, step = 501 (0.756 sec)\n",
      "INFO\t2019-03-22 16:00:31 +0100\tmaster-replica-0\t1\tglobal_step/sec: 137.015\n",
      "INFO\t2019-03-22 16:00:31 +0100\tmaster-replica-0\t1\tloss = 89.83683, step = 601 (0.729 sec)\n",
      "INFO\t2019-03-22 16:00:31 +0100\tmaster-replica-0\t2\tglobal_step/sec: 94.991\n",
      "INFO\t2019-03-22 16:00:31 +0100\tmaster-replica-0\t2\tloss = 71.76198, step = 701 (1.054 sec)\n",
      "INFO\t2019-03-22 16:00:32 +0100\tmaster-replica-0\t1\tglobal_step/sec: 147.275\n",
      "INFO\t2019-03-22 16:00:32 +0100\tmaster-replica-0\t1\tloss = 85.778404, step = 701 (0.679 sec)\n",
      "INFO\t2019-03-22 16:00:32 +0100\tmaster-replica-0\t2\tSaving checkpoints for 800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:00:32 +0100\tmaster-replica-0\t1\tSaving checkpoints for 800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:00:47 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:00:47 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:00:48\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:00:48\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-800\n",
      "INFO\t2019-03-22 16:00:48 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-800\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:00:50\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t1\tSaving dict for global step 800: accuracy = 0.8827, average_loss = 0.45601714, global_step = 800, loss = 57.72369\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:00:50\n",
      "INFO\t2019-03-22 16:00:50 +0100\tmaster-replica-0\t2\tSaving dict for global step 800: accuracy = 0.9177, average_loss = 0.29891577, global_step = 800, loss = 37.83744\n",
      "INFO\t2019-03-22 16:00:51 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 800: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-800\n",
      "INFO\t2019-03-22 16:00:51 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 800: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-800\n",
      "INFO\t2019-03-22 16:00:53 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-800\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-800\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:00:54 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:01:08 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553266852'/saved_model.pb\n",
      "INFO\t2019-03-22 16:01:08 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553266852'/saved_model.pb\n",
      "INFO\t2019-03-22 16:01:13 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.40103\n",
      "INFO\t2019-03-22 16:01:13 +0100\tmaster-replica-0\t2\tloss = 75.48168, step = 801 (41.648 sec)\n",
      "INFO\t2019-03-22 16:01:14 +0100\tmaster-replica-0\t2\tglobal_step/sec: 123.549\n",
      "INFO\t2019-03-22 16:01:14 +0100\tmaster-replica-0\t2\tloss = 90.53703, step = 901 (0.809 sec)\n",
      "INFO\t2019-03-22 16:01:14 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.36729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:01:14 +0100\tmaster-replica-0\t1\tloss = 92.09708, step = 801 (42.244 sec)\n",
      "INFO\t2019-03-22 16:01:15 +0100\tmaster-replica-0\t1\tglobal_step/sec: 138.434\n",
      "INFO\t2019-03-22 16:01:15 +0100\tmaster-replica-0\t1\tloss = 60.91696, step = 901 (0.722 sec)\n",
      "INFO\t2019-03-22 16:01:15 +0100\tmaster-replica-0\t2\tglobal_step/sec: 109.811\n",
      "INFO\t2019-03-22 16:01:15 +0100\tmaster-replica-0\t2\tloss = 54.609985, step = 1001 (0.911 sec)\n",
      "INFO\t2019-03-22 16:01:15 +0100\tmaster-replica-0\t1\tglobal_step/sec: 145.319\n",
      "INFO\t2019-03-22 16:01:15 +0100\tmaster-replica-0\t1\tloss = 83.6654, step = 1001 (0.687 sec)\n",
      "INFO\t2019-03-22 16:01:16 +0100\tmaster-replica-0\t2\tglobal_step/sec: 106.318\n",
      "INFO\t2019-03-22 16:01:16 +0100\tmaster-replica-0\t2\tloss = 77.066185, step = 1101 (0.941 sec)\n",
      "INFO\t2019-03-22 16:01:16 +0100\tmaster-replica-0\t1\tglobal_step/sec: 158.11\n",
      "INFO\t2019-03-22 16:01:16 +0100\tmaster-replica-0\t1\tloss = 132.58244, step = 1101 (0.633 sec)\n",
      "INFO\t2019-03-22 16:01:17 +0100\tmaster-replica-0\t2\tSaving checkpoints for 1200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:01:17 +0100\tmaster-replica-0\t1\tSaving checkpoints for 1200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:01:32 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:01:32 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:01:32 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:01:32\n",
      "INFO\t2019-03-22 16:01:32 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:01:33 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:01:33 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:01:33 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:01:33 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:01:33\n",
      "INFO\t2019-03-22 16:01:33 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:01:33 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:01:35\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t1\tSaving dict for global step 1200: accuracy = 0.9065, average_loss = 0.38688126, global_step = 1200, loss = 48.97231\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:01:35 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:01:36 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:01:36\n",
      "INFO\t2019-03-22 16:01:36 +0100\tmaster-replica-0\t2\tSaving dict for global step 1200: accuracy = 0.9346, average_loss = 0.24788225, global_step = 1200, loss = 31.3775\n",
      "INFO\t2019-03-22 16:01:36 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 1200: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:01:36 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 1200: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:01:38 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:01:39 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:01:40 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:01:40 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:01:40 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:01:52 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553266896'/saved_model.pb\n",
      "INFO\t2019-03-22 16:01:53 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553266897'/saved_model.pb\n",
      "INFO\t2019-03-22 16:01:57 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.41874\n",
      "INFO\t2019-03-22 16:01:57 +0100\tmaster-replica-0\t1\tloss = 81.82509, step = 1201 (41.344 sec)\n",
      "INFO\t2019-03-22 16:01:58 +0100\tmaster-replica-0\t1\tglobal_step/sec: 123.329\n",
      "INFO\t2019-03-22 16:01:58 +0100\tmaster-replica-0\t1\tloss = 58.53128, step = 1301 (0.812 sec)\n",
      "INFO\t2019-03-22 16:01:58 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.34366\n",
      "INFO\t2019-03-22 16:01:58 +0100\tmaster-replica-0\t2\tloss = 52.9007, step = 1201 (42.669 sec)\n",
      "INFO\t2019-03-22 16:01:59 +0100\tmaster-replica-0\t1\tglobal_step/sec: 120.528\n",
      "INFO\t2019-03-22 16:01:59 +0100\tmaster-replica-0\t1\tloss = 99.2262, step = 1401 (0.829 sec)\n",
      "INFO\t2019-03-22 16:01:59 +0100\tmaster-replica-0\t2\tglobal_step/sec: 106.01\n",
      "INFO\t2019-03-22 16:01:59 +0100\tmaster-replica-0\t2\tloss = 43.626335, step = 1301 (0.943 sec)\n",
      "INFO\t2019-03-22 16:02:00 +0100\tmaster-replica-0\t1\tglobal_step/sec: 181.029\n",
      "INFO\t2019-03-22 16:02:00 +0100\tmaster-replica-0\t1\tloss = 49.468147, step = 1501 (0.552 sec)\n",
      "INFO\t2019-03-22 16:02:00 +0100\tmaster-replica-0\t1\tSaving checkpoints for 1600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:02:00 +0100\tmaster-replica-0\t2\tglobal_step/sec: 100.125\n",
      "INFO\t2019-03-22 16:02:00 +0100\tmaster-replica-0\t2\tloss = 47.795635, step = 1401 (1.000 sec)\n",
      "INFO\t2019-03-22 16:02:01 +0100\tmaster-replica-0\t2\tglobal_step/sec: 98.3776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:02:01 +0100\tmaster-replica-0\t2\tloss = 73.93053, step = 1501 (1.015 sec)\n",
      "INFO\t2019-03-22 16:02:02 +0100\tmaster-replica-0\t2\tSaving checkpoints for 1600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:02:15 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:02:15 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:02:15 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:02:15\n",
      "INFO\t2019-03-22 16:02:15 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:02:16 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:02:17 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:02:18\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:02:18\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t1\tSaving dict for global step 1600: accuracy = 0.912, average_loss = 0.33660278, global_step = 1600, loss = 42.60795\n",
      "INFO\t2019-03-22 16:02:18 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:02:19 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 1600: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:02:20\n",
      "INFO\t2019-03-22 16:02:20 +0100\tmaster-replica-0\t2\tSaving dict for global step 1600: accuracy = 0.9443, average_loss = 0.20653072, global_step = 1600, loss = 26.143127\n",
      "INFO\t2019-03-22 16:02:21 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 1600: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:02:21 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:02:22 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:02:24 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:02:35 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553266940'/saved_model.pb\n",
      "INFO\t2019-03-22 16:02:37 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553266942'/saved_model.pb\n",
      "INFO\t2019-03-22 16:02:40 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.48685\n",
      "INFO\t2019-03-22 16:02:40 +0100\tmaster-replica-0\t1\tloss = 88.15579, step = 1601 (40.213 sec)\n",
      "INFO\t2019-03-22 16:02:40 +0100\tmaster-replica-0\t1\tglobal_step/sec: 141.102\n",
      "INFO\t2019-03-22 16:02:40 +0100\tmaster-replica-0\t1\tloss = 74.64209, step = 1701 (0.708 sec)\n",
      "INFO\t2019-03-22 16:02:41 +0100\tmaster-replica-0\t1\tglobal_step/sec: 136.046\n",
      "INFO\t2019-03-22 16:02:41 +0100\tmaster-replica-0\t1\tloss = 59.590202, step = 1801 (0.734 sec)\n",
      "INFO\t2019-03-22 16:02:42 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.46069\n",
      "INFO\t2019-03-22 16:02:42 +0100\tmaster-replica-0\t2\tloss = 39.17587, step = 1601 (40.640 sec)\n",
      "INFO\t2019-03-22 16:02:42 +0100\tmaster-replica-0\t1\tglobal_step/sec: 127.998\n",
      "INFO\t2019-03-22 16:02:42 +0100\tmaster-replica-0\t1\tloss = 54.57722, step = 1901 (0.781 sec)\n",
      "INFO\t2019-03-22 16:02:43 +0100\tmaster-replica-0\t1\tSaving checkpoints for 2000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:02:43 +0100\tmaster-replica-0\t2\tglobal_step/sec: 90.8801\n",
      "INFO\t2019-03-22 16:02:43 +0100\tmaster-replica-0\t2\tloss = 27.23893, step = 1701 (1.099 sec)\n",
      "INFO\t2019-03-22 16:02:44 +0100\tmaster-replica-0\t2\tglobal_step/sec: 114.645\n",
      "INFO\t2019-03-22 16:02:44 +0100\tmaster-replica-0\t2\tloss = 49.14409, step = 1801 (0.872 sec)\n",
      "INFO\t2019-03-22 16:02:45 +0100\tmaster-replica-0\t2\tglobal_step/sec: 119.427\n",
      "INFO\t2019-03-22 16:02:45 +0100\tmaster-replica-0\t2\tloss = 48.081566, step = 1901 (0.838 sec)\n",
      "INFO\t2019-03-22 16:02:46 +0100\tmaster-replica-0\t2\tSaving checkpoints for 2000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:03:02 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:03 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:03 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:03:03\n",
      "INFO\t2019-03-22 16:03:03 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:03:03 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:03:05\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t2\tSaving dict for global step 2000: accuracy = 0.9503, average_loss = 0.18319955, global_step = 2000, loss = 23.189817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:05 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:03:05\n",
      "INFO\t2019-03-22 16:03:06 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:03:06 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:03:06 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 2000: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:03:08\n",
      "INFO\t2019-03-22 16:03:08 +0100\tmaster-replica-0\t1\tSaving dict for global step 2000: accuracy = 0.9196, average_loss = 0.31308043, global_step = 2000, loss = 39.630436\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 2000: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:03:09 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:03:12 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:03:22 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553266987'/saved_model.pb\n",
      "INFO\t2019-03-22 16:03:25 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553266990'/saved_model.pb\n",
      "INFO\t2019-03-22 16:03:27 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.39288\n",
      "INFO\t2019-03-22 16:03:27 +0100\tmaster-replica-0\t2\tloss = 31.519602, step = 2001 (41.792 sec)\n",
      "INFO\t2019-03-22 16:03:28 +0100\tmaster-replica-0\t2\tglobal_step/sec: 88.5717\n",
      "INFO\t2019-03-22 16:03:28 +0100\tmaster-replica-0\t2\tloss = 25.27155, step = 2101 (1.128 sec)\n",
      "INFO\t2019-03-22 16:03:29 +0100\tmaster-replica-0\t2\tglobal_step/sec: 102.992\n",
      "INFO\t2019-03-22 16:03:29 +0100\tmaster-replica-0\t2\tloss = 33.260933, step = 2201 (0.971 sec)\n",
      "INFO\t2019-03-22 16:03:29 +0100\tmaster-replica-0\t2\tglobal_step/sec: 116.661\n",
      "INFO\t2019-03-22 16:03:29 +0100\tmaster-replica-0\t2\tloss = 15.86054, step = 2301 (0.857 sec)\n",
      "INFO\t2019-03-22 16:03:30 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.08438\n",
      "INFO\t2019-03-22 16:03:30 +0100\tmaster-replica-0\t1\tloss = 41.666183, step = 2001 (47.976 sec)\n",
      "INFO\t2019-03-22 16:03:30 +0100\tmaster-replica-0\t2\tSaving checkpoints for 2400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:03:31 +0100\tmaster-replica-0\t1\tglobal_step/sec: 133.751\n",
      "INFO\t2019-03-22 16:03:32 +0100\tmaster-replica-0\t1\tloss = 83.168945, step = 2101 (1.588 sec)\n",
      "INFO\t2019-03-22 16:03:32 +0100\tmaster-replica-0\t1\tglobal_step/sec: 65.8487\n",
      "INFO\t2019-03-22 16:03:32 +0100\tmaster-replica-0\t1\tloss = 57.50324, step = 2201 (0.677 sec)\n",
      "INFO\t2019-03-22 16:03:33 +0100\tmaster-replica-0\t1\tglobal_step/sec: 179.689\n",
      "INFO\t2019-03-22 16:03:33 +0100\tmaster-replica-0\t1\tloss = 53.921776, step = 2301 (0.557 sec)\n",
      "INFO\t2019-03-22 16:03:33 +0100\tmaster-replica-0\t1\tSaving checkpoints for 2400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:03:48 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:48 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:48 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:03:48\n",
      "INFO\t2019-03-22 16:03:48 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:03:48 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:03:50\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:03:50\n",
      "INFO\t2019-03-22 16:03:50 +0100\tmaster-replica-0\t2\tSaving dict for global step 2400: accuracy = 0.9524, average_loss = 0.17589802, global_step = 2400, loss = 22.265572\n",
      "INFO\t2019-03-22 16:03:51 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 2400: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:03:52 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:03:53 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:03:53 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:03:53\n",
      "INFO\t2019-03-22 16:03:53 +0100\tmaster-replica-0\t1\tSaving dict for global step 2400: accuracy = 0.9269, average_loss = 0.27936587, global_step = 2400, loss = 35.36277\n",
      "INFO\t2019-03-22 16:03:53 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 2400: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:03:54 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:03:55 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:03:55 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:03:56 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:03:57 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:03:57 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:04:07 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553267032'/saved_model.pb\n",
      "INFO\t2019-03-22 16:04:09 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553267034'/saved_model.pb\n",
      "INFO\t2019-03-22 16:04:15 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.21523\n",
      "INFO\t2019-03-22 16:04:15 +0100\tmaster-replica-0\t2\tloss = 43.058056, step = 2401 (45.144 sec)\n",
      "INFO\t2019-03-22 16:04:16 +0100\tmaster-replica-0\t2\tglobal_step/sec: 92.236\n",
      "INFO\t2019-03-22 16:04:16 +0100\tmaster-replica-0\t2\tloss = 24.849266, step = 2501 (1.084 sec)\n",
      "INFO\t2019-03-22 16:04:17 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.27392\n",
      "INFO\t2019-03-22 16:04:17 +0100\tmaster-replica-0\t1\tloss = 37.361515, step = 2401 (43.977 sec)\n",
      "INFO\t2019-03-22 16:04:17 +0100\tmaster-replica-0\t2\tglobal_step/sec: 87.7432\n",
      "INFO\t2019-03-22 16:04:17 +0100\tmaster-replica-0\t2\tloss = 19.094383, step = 2601 (1.137 sec)\n",
      "INFO\t2019-03-22 16:04:17 +0100\tmaster-replica-0\t1\tglobal_step/sec: 137.486\n",
      "INFO\t2019-03-22 16:04:17 +0100\tmaster-replica-0\t1\tloss = 44.15644, step = 2501 (0.727 sec)\n",
      "INFO\t2019-03-22 16:04:18 +0100\tmaster-replica-0\t2\tglobal_step/sec: 123.604\n",
      "INFO\t2019-03-22 16:04:18 +0100\tmaster-replica-0\t2\tloss = 42.69452, step = 2701 (0.809 sec)\n",
      "INFO\t2019-03-22 16:04:18 +0100\tmaster-replica-0\t1\tglobal_step/sec: 134.556\n",
      "INFO\t2019-03-22 16:04:18 +0100\tmaster-replica-0\t1\tloss = 64.88831, step = 2601 (0.743 sec)\n",
      "INFO\t2019-03-22 16:04:18 +0100\tmaster-replica-0\t2\tSaving checkpoints for 2800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:04:19 +0100\tmaster-replica-0\t1\tglobal_step/sec: 131.535\n",
      "INFO\t2019-03-22 16:04:19 +0100\tmaster-replica-0\t1\tloss = 64.24518, step = 2701 (0.760 sec)\n",
      "INFO\t2019-03-22 16:04:20 +0100\tmaster-replica-0\t1\tSaving checkpoints for 2800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:04:36 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:04:37\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:04:37\n",
      "INFO\t2019-03-22 16:04:37 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:04:38 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:04:39\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t2\tSaving dict for global step 2800: accuracy = 0.9593, average_loss = 0.15990382, global_step = 2800, loss = 20.24099\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:04:39 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:04:40\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t1\tSaving dict for global step 2800: accuracy = 0.938, average_loss = 0.25137287, global_step = 2800, loss = 31.819351\n",
      "INFO\t2019-03-22 16:04:40 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 2800: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:04:41 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 2800: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:04:43 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:04:44 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:04:44 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:04:44 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:04:56 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553267081'/saved_model.pb\n",
      "INFO\t2019-03-22 16:04:57 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553267081'/saved_model.pb\n",
      "INFO\t2019-03-22 16:05:03 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.26406\n",
      "INFO\t2019-03-22 16:05:03 +0100\tmaster-replica-0\t1\tloss = 28.779533, step = 2801 (44.174 sec)\n",
      "INFO\t2019-03-22 16:05:04 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.17542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:05:04 +0100\tmaster-replica-0\t2\tloss = 34.242496, step = 2801 (45.969 sec)\n",
      "INFO\t2019-03-22 16:05:04 +0100\tmaster-replica-0\t1\tglobal_step/sec: 124.113\n",
      "INFO\t2019-03-22 16:05:04 +0100\tmaster-replica-0\t1\tloss = 46.135605, step = 2901 (0.801 sec)\n",
      "INFO\t2019-03-22 16:05:04 +0100\tmaster-replica-0\t2\tglobal_step/sec: 111.353\n",
      "INFO\t2019-03-22 16:05:05 +0100\tmaster-replica-0\t2\tloss = 37.010498, step = 2901 (0.898 sec)\n",
      "INFO\t2019-03-22 16:05:05 +0100\tmaster-replica-0\t1\tglobal_step/sec: 124.515\n",
      "INFO\t2019-03-22 16:05:05 +0100\tmaster-replica-0\t1\tloss = 51.724136, step = 3001 (0.803 sec)\n",
      "INFO\t2019-03-22 16:05:05 +0100\tmaster-replica-0\t1\tglobal_step/sec: 145.901\n",
      "INFO\t2019-03-22 16:05:05 +0100\tmaster-replica-0\t1\tloss = 42.51751, step = 3101 (0.685 sec)\n",
      "INFO\t2019-03-22 16:05:06 +0100\tmaster-replica-0\t2\tglobal_step/sec: 96.2106\n",
      "INFO\t2019-03-22 16:05:06 +0100\tmaster-replica-0\t2\tloss = 25.378647, step = 3001 (1.039 sec)\n",
      "INFO\t2019-03-22 16:05:06 +0100\tmaster-replica-0\t1\tSaving checkpoints for 3200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:05:06 +0100\tmaster-replica-0\t2\tglobal_step/sec: 107.772\n",
      "INFO\t2019-03-22 16:05:06 +0100\tmaster-replica-0\t2\tloss = 28.248423, step = 3101 (0.929 sec)\n",
      "INFO\t2019-03-22 16:05:07 +0100\tmaster-replica-0\t2\tSaving checkpoints for 3200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:05:22 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:05:23 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:05:23 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:05:23\n",
      "INFO\t2019-03-22 16:05:23 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:05:23 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:05:23 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:05:24 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:05:24 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:05:24\n",
      "INFO\t2019-03-22 16:05:24 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:05:24 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:05:25\n",
      "INFO\t2019-03-22 16:05:25 +0100\tmaster-replica-0\t1\tSaving dict for global step 3200: accuracy = 0.9394, average_loss = 0.2454642, global_step = 3200, loss = 31.071419\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:05:26\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t2\tSaving dict for global step 3200: accuracy = 0.9622, average_loss = 0.14479482, global_step = 3200, loss = 18.328459\n",
      "INFO\t2019-03-22 16:05:26 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 3200: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:05:27 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 3200: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:05:28 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:05:29 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:05:30 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:05:41 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553267127'/saved_model.pb\n",
      "INFO\t2019-03-22 16:05:42 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553267128'/saved_model.pb\n",
      "INFO\t2019-03-22 16:05:48 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.36375\n",
      "INFO\t2019-03-22 16:05:49 +0100\tmaster-replica-0\t1\tloss = 37.21372, step = 3201 (43.150 sec)\n",
      "INFO\t2019-03-22 16:05:49 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.3401\n",
      "INFO\t2019-03-22 16:05:49 +0100\tmaster-replica-0\t1\tglobal_step/sec: 64.7096\n",
      "INFO\t2019-03-22 16:05:49 +0100\tmaster-replica-0\t1\tloss = 37.410477, step = 3301 (0.702 sec)\n",
      "INFO\t2019-03-22 16:05:50 +0100\tmaster-replica-0\t2\tloss = 21.76727, step = 3201 (43.560 sec)\n",
      "INFO\t2019-03-22 16:05:50 +0100\tmaster-replica-0\t1\tglobal_step/sec: 135.645\n",
      "INFO\t2019-03-22 16:05:50 +0100\tmaster-replica-0\t1\tloss = 48.51895, step = 3401 (0.737 sec)\n",
      "INFO\t2019-03-22 16:05:51 +0100\tmaster-replica-0\t1\tglobal_step/sec: 140.431\n",
      "INFO\t2019-03-22 16:05:51 +0100\tmaster-replica-0\t1\tloss = 34.651867, step = 3501 (0.712 sec)\n",
      "INFO\t2019-03-22 16:05:51 +0100\tmaster-replica-0\t2\tglobal_step/sec: 54.206\n",
      "INFO\t2019-03-22 16:05:51 +0100\tmaster-replica-0\t2\tloss = 25.228277, step = 3301 (1.017 sec)\n",
      "INFO\t2019-03-22 16:05:51 +0100\tmaster-replica-0\t1\tSaving checkpoints for 3600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:05:52 +0100\tmaster-replica-0\t2\tglobal_step/sec: 108.552\n",
      "INFO\t2019-03-22 16:05:52 +0100\tmaster-replica-0\t2\tloss = 32.004585, step = 3401 (0.921 sec)\n",
      "INFO\t2019-03-22 16:05:53 +0100\tmaster-replica-0\t2\tglobal_step/sec: 103.281\n",
      "INFO\t2019-03-22 16:05:53 +0100\tmaster-replica-0\t2\tloss = 26.25671, step = 3501 (0.968 sec)\n",
      "INFO\t2019-03-22 16:05:54 +0100\tmaster-replica-0\t2\tSaving checkpoints for 3600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:06:07 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:06:08 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:06:08 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:06:08\n",
      "INFO\t2019-03-22 16:06:08 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:06:08 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:06:09 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:06:10\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:06:10\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t1\tSaving dict for global step 3600: accuracy = 0.9396, average_loss = 0.23192236, global_step = 3600, loss = 29.357262\n",
      "INFO\t2019-03-22 16:06:10 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:06:11 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 3600: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:06:12\n",
      "INFO\t2019-03-22 16:06:12 +0100\tmaster-replica-0\t2\tSaving dict for global step 3600: accuracy = 0.9645, average_loss = 0.12732507, global_step = 3600, loss = 16.117098\n",
      "INFO\t2019-03-22 16:06:13 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 3600: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:06:13 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:06:14 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:06:16 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:06:26 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553267172'/saved_model.pb\n",
      "INFO\t2019-03-22 16:06:29 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553267174'/saved_model.pb\n",
      "INFO\t2019-03-22 16:06:34 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.33602\n",
      "INFO\t2019-03-22 16:06:34 +0100\tmaster-replica-0\t1\tloss = 42.418247, step = 3601 (42.808 sec)\n",
      "INFO\t2019-03-22 16:06:34 +0100\tmaster-replica-0\t1\tglobal_step/sec: 137.323\n",
      "INFO\t2019-03-22 16:06:34 +0100\tmaster-replica-0\t1\tloss = 51.88821, step = 3701 (0.728 sec)\n",
      "INFO\t2019-03-22 16:06:35 +0100\tmaster-replica-0\t1\tglobal_step/sec: 138.347\n",
      "INFO\t2019-03-22 16:06:35 +0100\tmaster-replica-0\t1\tloss = 50.966167, step = 3801 (0.723 sec)\n",
      "INFO\t2019-03-22 16:06:36 +0100\tmaster-replica-0\t1\tglobal_step/sec: 148.06\n",
      "INFO\t2019-03-22 16:06:36 +0100\tmaster-replica-0\t1\tloss = 41.946476, step = 3901 (0.675 sec)\n",
      "INFO\t2019-03-22 16:06:36 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.33832\n",
      "INFO\t2019-03-22 16:06:36 +0100\tmaster-replica-0\t2\tloss = 25.720676, step = 3601 (42.766 sec)\n",
      "INFO\t2019-03-22 16:06:36 +0100\tmaster-replica-0\t1\tSaving checkpoints for 4000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:06:37 +0100\tmaster-replica-0\t2\tglobal_step/sec: 103.29\n",
      "INFO\t2019-03-22 16:06:37 +0100\tmaster-replica-0\t2\tloss = 23.474154, step = 3701 (0.968 sec)\n",
      "INFO\t2019-03-22 16:06:38 +0100\tmaster-replica-0\t2\tglobal_step/sec: 107.608\n",
      "INFO\t2019-03-22 16:06:38 +0100\tmaster-replica-0\t2\tloss = 16.276232, step = 3801 (0.929 sec)\n",
      "INFO\t2019-03-22 16:06:38 +0100\tmaster-replica-0\t2\tglobal_step/sec: 120.48\n",
      "INFO\t2019-03-22 16:06:38 +0100\tmaster-replica-0\t2\tloss = 29.917126, step = 3901 (0.830 sec)\n",
      "INFO\t2019-03-22 16:06:39 +0100\tmaster-replica-0\t2\tSaving checkpoints for 4000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:06:52 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:06:52 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:06:52 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:06:52\n",
      "INFO\t2019-03-22 16:06:52 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:06:53 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:06:54 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:06:54 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:06:54 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:06:54 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:06:54 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:06:54 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:06:55 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:06:55 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:06:55 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:06:55 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:06:55\n",
      "INFO\t2019-03-22 16:06:55 +0100\tmaster-replica-0\t1\tSaving dict for global step 4000: accuracy = 0.9447, average_loss = 0.21573552, global_step = 4000, loss = 27.308294\n",
      "INFO\t2019-03-22 16:06:55 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:06:56 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 4000: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:06:56 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:06:56 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:06:56\n",
      "INFO\t2019-03-22 16:06:56 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:06:56 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:06:58\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t2\tSaving dict for global step 4000: accuracy = 0.9644, average_loss = 0.1400194, global_step = 4000, loss = 17.723976\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:06:58 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:06:59 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:06:59 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 4000: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:06:59 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:06:59 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:07:01 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:07:02 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:07:11 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553267216'/saved_model.pb\n",
      "INFO\t2019-03-22 16:07:15 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553267220'/saved_model.pb\n",
      "INFO\t2019-03-22 16:07:19 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.32861\n",
      "INFO\t2019-03-22 16:07:19 +0100\tmaster-replica-0\t1\tloss = 24.019842, step = 4001 (42.971 sec)\n",
      "INFO\t2019-03-22 16:07:19 +0100\tmaster-replica-0\t1\tglobal_step/sec: 129.516\n",
      "INFO\t2019-03-22 16:07:19 +0100\tmaster-replica-0\t1\tloss = 44.336006, step = 4101 (0.746 sec)\n",
      "INFO\t2019-03-22 16:07:20 +0100\tmaster-replica-0\t1\tglobal_step/sec: 136.667\n",
      "INFO\t2019-03-22 16:07:20 +0100\tmaster-replica-0\t1\tloss = 48.011436, step = 4201 (0.731 sec)\n",
      "INFO\t2019-03-22 16:07:21 +0100\tmaster-replica-0\t1\tglobal_step/sec: 136.3\n",
      "INFO\t2019-03-22 16:07:21 +0100\tmaster-replica-0\t1\tloss = 29.76207, step = 4301 (0.734 sec)\n",
      "INFO\t2019-03-22 16:07:21 +0100\tmaster-replica-0\t1\tSaving checkpoints for 4400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:07:22 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.29506\n",
      "INFO\t2019-03-22 16:07:22 +0100\tmaster-replica-0\t2\tloss = 16.124352, step = 4001 (43.572 sec)\n",
      "INFO\t2019-03-22 16:07:23 +0100\tmaster-replica-0\t2\tglobal_step/sec: 106.23\n",
      "INFO\t2019-03-22 16:07:23 +0100\tmaster-replica-0\t2\tloss = 14.186893, step = 4101 (0.942 sec)\n",
      "INFO\t2019-03-22 16:07:24 +0100\tmaster-replica-0\t2\tglobal_step/sec: 101.822\n",
      "INFO\t2019-03-22 16:07:24 +0100\tmaster-replica-0\t2\tloss = 15.740831, step = 4201 (0.982 sec)\n",
      "INFO\t2019-03-22 16:07:25 +0100\tmaster-replica-0\t2\tglobal_step/sec: 120.826\n",
      "INFO\t2019-03-22 16:07:25 +0100\tmaster-replica-0\t2\tloss = 26.682814, step = 4301 (0.827 sec)\n",
      "INFO\t2019-03-22 16:07:26 +0100\tmaster-replica-0\t2\tSaving checkpoints for 4400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:07:38 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:07:38 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:07:38 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:07:38\n",
      "INFO\t2019-03-22 16:07:38 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:07:39 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:07:40 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:07:40 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:07:40 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:07:40 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:07:41 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:07:41 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:07:41 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:07:41 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:07:41 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:07:41 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:07:41\n",
      "INFO\t2019-03-22 16:07:41 +0100\tmaster-replica-0\t1\tSaving dict for global step 4400: accuracy = 0.9455, average_loss = 0.22133054, global_step = 4400, loss = 28.016523\n",
      "INFO\t2019-03-22 16:07:42 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:07:42 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 4400: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:07:42 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:07:42 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:07:42\n",
      "INFO\t2019-03-22 16:07:42 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:07:42 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:07:44\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t2\tSaving dict for global step 4400: accuracy = 0.9675, average_loss = 0.1252038, global_step = 4400, loss = 15.848583\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:07:44 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:07:45 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:07:45 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:07:45 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:07:45 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 4400: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:07:48 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:07:57 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553267262'/saved_model.pb\n",
      "INFO\t2019-03-22 16:08:00 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553267266'/saved_model.pb\n",
      "INFO\t2019-03-22 16:08:05 +0100\tmaster-replica-0\t1\tglobal_step/sec: 2.28874\n",
      "INFO\t2019-03-22 16:08:06 +0100\tmaster-replica-0\t1\tloss = 46.81066, step = 4401 (44.645 sec)\n",
      "INFO\t2019-03-22 16:08:06 +0100\tmaster-replica-0\t1\tglobal_step/sec: 58.6082\n",
      "INFO\t2019-03-22 16:08:06 +0100\tmaster-replica-0\t1\tloss = 38.66124, step = 4501 (0.753 sec)\n",
      "INFO\t2019-03-22 16:08:07 +0100\tmaster-replica-0\t1\tglobal_step/sec: 132.924\n",
      "INFO\t2019-03-22 16:08:07 +0100\tmaster-replica-0\t1\tloss = 24.690096, step = 4601 (0.752 sec)\n",
      "INFO\t2019-03-22 16:08:08 +0100\tmaster-replica-0\t1\tSaving checkpoints for 4688 into gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt.\n",
      "INFO\t2019-03-22 16:08:08 +0100\tmaster-replica-0\t2\tglobal_step/sec: 2.31749\n",
      "INFO\t2019-03-22 16:08:09 +0100\tmaster-replica-0\t2\tloss = 7.7446804, step = 4401 (43.929 sec)\n",
      "INFO\t2019-03-22 16:08:10 +0100\tmaster-replica-0\t2\tglobal_step/sec: 56.2119\n",
      "INFO\t2019-03-22 16:08:10 +0100\tmaster-replica-0\t2\tloss = 28.348011, step = 4501 (1.000 sec)\n",
      "INFO\t2019-03-22 16:08:11 +0100\tmaster-replica-0\t2\tglobal_step/sec: 101.682\n",
      "INFO\t2019-03-22 16:08:11 +0100\tmaster-replica-0\t2\tloss = 26.812534, step = 4601 (0.983 sec)\n",
      "INFO\t2019-03-22 16:08:11 +0100\tmaster-replica-0\t2\tSaving checkpoints for 4688 into gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt.\n",
      "INFO\t2019-03-22 16:08:24 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:08:24 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:08:24 +0100\tmaster-replica-0\t1\tStarting evaluation at 2019-03-22-15:08:24\n",
      "INFO\t2019-03-22 16:08:24 +0100\tmaster-replica-0\t1\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:08:24 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tFinished evaluation at 2019-03-22-15:08:26\n",
      "INFO\t2019-03-22 16:08:26 +0100\tmaster-replica-0\t1\tSaving dict for global step 4688: accuracy = 0.9401, average_loss = 0.23305047, global_step = 4688, loss = 29.50006\n",
      "INFO\t2019-03-22 16:08:27 +0100\tmaster-replica-0\t1\tSaving 'checkpoint_path' summary for global step 4688: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:08:28 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:08:28 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:08:28 +0100\tmaster-replica-0\t2\tStarting evaluation at 2019-03-22-15:08:28\n",
      "INFO\t2019-03-22 16:08:28 +0100\tmaster-replica-0\t2\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:08:28 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:08:30 +0100\tmaster-replica-0\t1\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/1/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tFinished evaluation at 2019-03-22-15:08:31\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t2\tSaving dict for global step 4688: accuracy = 0.9684, average_loss = 0.11979702, global_step = 4688, loss = 15.16418\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t1\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:08:31 +0100\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-03-22 16:08:32 +0100\tmaster-replica-0\t2\tSaving 'checkpoint_path' summary for global step 4688: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:08:34 +0100\tmaster-replica-0\t2\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:08:35 +0100\tmaster-replica-0\t2\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/2/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:08:36 +0100\tmaster-replica-0\t2\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:08:36 +0100\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-03-22 16:08:45 +0100\tmaster-replica-0\t1\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1/export/exporter/temp-b'1553267308'/saved_model.pb\n",
      "INFO\t2019-03-22 16:08:48 +0100\tmaster-replica-0\t2\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2/export/exporter/temp-b'1553267313'/saved_model.pb\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tLoss for final step: 11.268467.\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tArguments:\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\t{'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703', 'hidden_units': '128 64 32', 'eval_delay_secs': 1, 'train_batch_size': 314, 'train_steps': 5000, 'min_eval_frequency': 5, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz'}\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tArguments:\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\t{'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703', 'hidden_units': [128, 64, 32], 'eval_delay_secs': 1, 'train_batch_size': 314, 'train_steps': 5000, 'min_eval_frequency': 5, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tSave output to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\t## start training and evaluation\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190322_155703/1\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tModule completed; cleaning up.\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tClean up finished.\n",
      "INFO\t2019-03-22 16:08:54 +0100\tmaster-replica-0\t1\tTask completed successfully.\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\tLoss for final step: 16.675682.\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\tArguments:\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\t{'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', 'train_batch_size': 165, 'hidden_units': '256 128 64', 'min_eval_frequency': 5, 'train_steps': 5000, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703'}\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\tArguments:\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\t{'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', 'train_batch_size': 165, 'hidden_units': [256, 128, 64], 'min_eval_frequency': 5, 'train_steps': 5000, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703'}\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\tSave output to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\t## start training and evaluation\n",
      "INFO\t2019-03-22 16:08:56 +0100\tmaster-replica-0\t2\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190322_155703/2\n",
      "INFO\t2019-03-22 16:08:57 +0100\tmaster-replica-0\t2\tModule completed; cleaning up.\n",
      "INFO\t2019-03-22 16:08:57 +0100\tmaster-replica-0\t2\tClean up finished.\n",
      "INFO\t2019-03-22 16:08:57 +0100\tmaster-replica-0\t2\tTask completed successfully.\n",
      "INFO\t2019-03-22 16:12:11 +0100\tservice\t\tJob completed successfully.\n",
      "INFO\t2019-03-22 16:12:14 +0100\tservice\t\tJob completed successfully.\n",
      "INFO\t2019-03-22 16:13:50 +0100\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-03-22 16:13:50 +0100\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-03-22 16:13:55 +0100\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-03-22 16:13:56 +0100\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-03-22 16:15:05 +0100\tmaster-replica-0\t3\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0, \"trial\": \"3\"} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\"],  \"python_module\": \"pkg_mnist_fnn.task\",  \"args\": [\"--data_path\", \"gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703\", \"--train_steps\", \"5000\", \"--job_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs\"],  \"hyperparameters\": {    \"goal\": \"MAXIMIZE\",    \"params\": [{      \"parameter_name\": \"train_batch_size\",      \"min_value\": 64.0,      \"max_value\": 512.0,      \"type\": \"INTEGER\",      \"scale_type\": \"UNIT_LOG_SCALE\"    }, {      \"parameter_name\": \"hidden_units\",      \"type\": \"CATEGORICAL\",      \"categorical_values\": [\"128 64 32\", \"256 128 64\", \"512 256 128 64\"]    }],    \"max_trials\": 4,    \"max_parallel_trials\": 2,    \"hyperparameter_metric_tag\": \"accuracy\"  },  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"} --hyperparams={\"hidden_units\":\"512 256 128 64\",\"train_batch_size\":\"195\"}\n",
      "INFO\t2019-03-22 16:15:13 +0100\tmaster-replica-0\t3\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-03-22 16:15:13 +0100\tmaster-replica-0\t3\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:13 +0100\tmaster-replica-0\t3\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:13 +0100\tmaster-replica-0\t4\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0, \"trial\": \"4\"} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\"],  \"python_module\": \"pkg_mnist_fnn.task\",  \"args\": [\"--data_path\", \"gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703\", \"--train_steps\", \"5000\", \"--job_dir\", \"gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs\"],  \"hyperparameters\": {    \"goal\": \"MAXIMIZE\",    \"params\": [{      \"parameter_name\": \"train_batch_size\",      \"min_value\": 64.0,      \"max_value\": 512.0,      \"type\": \"INTEGER\",      \"scale_type\": \"UNIT_LOG_SCALE\"    }, {      \"parameter_name\": \"hidden_units\",      \"type\": \"CATEGORICAL\",      \"categorical_values\": [\"128 64 32\", \"256 128 64\", \"512 256 128 64\"]    }],    \"max_trials\": 4,    \"max_parallel_trials\": 2,    \"hyperparameter_metric_tag\": \"accuracy\"  },  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"} --hyperparams={\"hidden_units\":\"256 128 64\",\"train_batch_size\":\"165\"}\n",
      "INFO\t2019-03-22 16:15:15 +0100\tmaster-replica-0\t3\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:15 +0100\tmaster-replica-0\t3\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:17 +0100\tmaster-replica-0\t3\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:18 +0100\tmaster-replica-0\t3\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 16:15:19 +0100\tmaster-replica-0\t3\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:19 +0100\tmaster-replica-0\t3\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:20 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:20 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:20 +0100\tmaster-replica-0\t3\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:20 +0100\tmaster-replica-0\t3\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 16:15:21 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:21 +0100\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:21 +0100\tmaster-replica-0\t3\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 16:15:21 +0100\tmaster-replica-0\t3\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 16:15:21 +0100\tmaster-replica-0\t3\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:22 +0100\tmaster-replica-0\t3\tInstalling collected packages: pkg-mnist-fnn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:15:22 +0100\tmaster-replica-0\t3\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-03-22 16:15:22 +0100\tmaster-replica-0\t3\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-03-22 16:15:22 +0100\tmaster-replica-0\t3\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 16:15:22 +0100\tmaster-replica-0\t3\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 16:15:22 +0100\tmaster-replica-0\t3\tRunning command: python3 -m pkg_mnist_fnn.task --data_path gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir gs://ml-productive-pipeline-53122/mnist_190322_155703 --train_steps 5000 --job_dir gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs --train_batch_size 195 --hidden_units 512 256 128 64\n",
      "INFO\t2019-03-22 16:15:23 +0100\tmaster-replica-0\t4\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-03-22 16:15:23 +0100\tmaster-replica-0\t4\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:23 +0100\tmaster-replica-0\t4\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:25 +0100\tmaster-replica-0\t4\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:25 +0100\tmaster-replica-0\t4\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\tTF_CONFIG environment variable: {'environment': 'cloud', 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'trial': '3', 'type': 'master'}, 'cluster': {'master': ['127.0.0.1:2222']}, 'job': {'args': ['--data_path', 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703', '--train_steps', '5000', '--job_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', '--train_batch_size', '195', '--hidden_units', '512 256 128 64'], 'python_version': '3.5', 'runtime_version': '1.12', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz'], 'run_on_raw_vm': True, 'hyperparameters': {'max_trials': 4, 'params': [{'parameter_name': 'train_batch_size', 'type': 'INTEGER', 'max_value': 512.0, 'scale_type': 'UNIT_LOG_SCALE', 'min_value': 64.0}, {'categorical_values': ['128 64 32', '256 128 64', '512 256 128 64'], 'type': 'CATEGORICAL', 'parameter_name': 'hidden_units'}], 'hyperparameter_metric_tag': 'accuracy', 'max_parallel_trials': 2, 'goal': 'MAXIMIZE'}, 'python_module': 'pkg_mnist_fnn.task', 'region': 'europe-west1'}}\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\tUsing config: {'_num_ps_replicas': 0, '_evaluation_master': '', '_device_fn': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_master': '', '_task_id': 0, '_train_distribute': None, '_service': None, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': 400, '_experimental_distribute': None, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78b7f10cf8>, '_eval_distribute': None, '_global_id_in_cluster': 0, '_task_type': 'master', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\tallow_soft_placement: true\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\tgraph_options {\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\t  rewrite_options {\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\t  }\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\t}\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\t, '_save_checkpoints_secs': None, '_keep_checkpoint_every_n_hours': 1, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/3'}\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\tNot using Distribute Coordinator.\n",
      "INFO\t2019-03-22 16:15:26 +0100\tmaster-replica-0\t3\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "INFO\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t4\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 16:15:27 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:15:28 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:15:28 +0100\tmaster-replica-0\t3\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-03-22 16:15:28 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:28 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:29 +0100\tmaster-replica-0\t4\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:29 +0100\tmaster-replica-0\t4\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 16:15:30 +0100\tmaster-replica-0\t4\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t4\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t4\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t4\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t3\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-22 16:15:31 +0100\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t4\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t4\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t4\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "WARNING\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:15:32 +0100\tmaster-replica-0\t3\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 16:15:33 +0100\tmaster-replica-0\t4\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-03-22 16:15:33 +0100\tmaster-replica-0\t4\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-03-22 16:15:33 +0100\tmaster-replica-0\t4\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-03-22 16:15:33 +0100\tmaster-replica-0\t4\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 16:15:33 +0100\tmaster-replica-0\t4\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-03-22 16:15:33 +0100\tmaster-replica-0\t4\tRunning command: python3 -m pkg_mnist_fnn.task --data_path gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir gs://ml-productive-pipeline-53122/mnist_190322_155703 --train_steps 5000 --job_dir gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs --hidden_units 256 128 64 --train_batch_size 165\n",
      "INFO\t2019-03-22 16:15:35 +0100\tmaster-replica-0\t3\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tTF_CONFIG environment variable: {'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'master', 'trial': '4'}, 'cluster': {'master': ['127.0.0.1:2222']}, 'job': {'hyperparameters': {'max_parallel_trials': 2, 'max_trials': 4, 'hyperparameter_metric_tag': 'accuracy', 'goal': 'MAXIMIZE', 'params': [{'parameter_name': 'train_batch_size', 'scale_type': 'UNIT_LOG_SCALE', 'min_value': 64.0, 'type': 'INTEGER', 'max_value': 512.0}, {'parameter_name': 'hidden_units', 'type': 'CATEGORICAL', 'categorical_values': ['128 64 32', '256 128 64', '512 256 128 64']}]}, 'args': ['--data_path', 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703', '--train_steps', '5000', '--job_dir', 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', '--hidden_units', '256 128 64', '--train_batch_size', '165'], 'python_module': 'pkg_mnist_fnn.task', 'runtime_version': '1.12', 'python_version': '3.5', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz'], 'run_on_raw_vm': True, 'region': 'europe-west1'}, 'environment': 'cloud'}\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tUsing config: {'_keep_checkpoint_max': 5, '_task_id': 0, '_is_chief': True, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tallow_soft_placement: true\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tgraph_options {\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\t  rewrite_options {\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\t  }\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\t}\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\t, '_save_checkpoints_steps': 400, '_num_ps_replicas': 0, '_master': '', '_device_fn': None, '_experimental_distribute': None, '_service': None, '_train_distribute': None, '_keep_checkpoint_every_n_hours': 1, '_num_worker_replicas': 1, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/4', '_tf_random_seed': None, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_evaluation_master': '', '_task_type': 'master', '_protocol': None, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f427d9b07b8>, '_global_id_in_cluster': 0, '_eval_distribute': None}\n",
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tNot using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "WARNING\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-03-22 16:15:38 +0100\tmaster-replica-0\t4\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-03-22 16:15:40 +0100\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:15:40 +0100\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:15:40 +0100\tmaster-replica-0\t4\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-03-22 16:15:40 +0100\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:15:40 +0100\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:15:40 +0100\tmaster-replica-0\t4\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 16:15:40 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:15:41 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:15:41 +0100\tmaster-replica-0\t4\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-03-22 16:15:44 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:15:45 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:15:45 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "WARNING\t2019-03-22 16:15:45 +0100\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:15:45 +0100\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:15:45 +0100\tmaster-replica-0\t4\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-03-22 16:15:47 +0100\tmaster-replica-0\t4\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:15:48 +0100\tmaster-replica-0\t3\tloss = 15243.988, step = 1\n",
      "INFO\t2019-03-22 16:15:50 +0100\tmaster-replica-0\t3\tglobal_step/sec: 53.508\n",
      "INFO\t2019-03-22 16:15:50 +0100\tmaster-replica-0\t3\tloss = 246.87842, step = 101 (1.870 sec)\n",
      "INFO\t2019-03-22 16:15:52 +0100\tmaster-replica-0\t3\tglobal_step/sec: 70.1226\n",
      "INFO\t2019-03-22 16:15:52 +0100\tmaster-replica-0\t3\tloss = 156.73206, step = 201 (1.425 sec)\n",
      "INFO\t2019-03-22 16:15:53 +0100\tmaster-replica-0\t3\tglobal_step/sec: 64.6371\n",
      "INFO\t2019-03-22 16:15:53 +0100\tmaster-replica-0\t3\tloss = 104.16511, step = 301 (1.548 sec)\n",
      "INFO\t2019-03-22 16:15:55 +0100\tmaster-replica-0\t3\tSaving checkpoints for 400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:16:01 +0100\tmaster-replica-0\t4\tloss = 19083.867, step = 1\n",
      "INFO\t2019-03-22 16:16:02 +0100\tmaster-replica-0\t4\tglobal_step/sec: 92.0891\n",
      "INFO\t2019-03-22 16:16:02 +0100\tmaster-replica-0\t4\tloss = 415.2511, step = 101 (1.087 sec)\n",
      "INFO\t2019-03-22 16:16:03 +0100\tmaster-replica-0\t4\tglobal_step/sec: 105.939\n",
      "INFO\t2019-03-22 16:16:03 +0100\tmaster-replica-0\t4\tloss = 147.36267, step = 201 (0.944 sec)\n",
      "INFO\t2019-03-22 16:16:04 +0100\tmaster-replica-0\t4\tglobal_step/sec: 98.517\n",
      "INFO\t2019-03-22 16:16:04 +0100\tmaster-replica-0\t4\tloss = 156.48221, step = 301 (1.015 sec)\n",
      "INFO\t2019-03-22 16:16:05 +0100\tmaster-replica-0\t4\tSaving checkpoints for 400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:16:09 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:16:10 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:16:10 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:16:10\n",
      "INFO\t2019-03-22 16:16:10 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:16:10 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-400\n",
      "INFO\t2019-03-22 16:16:12 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:16:12 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:16:12 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:16:12 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:16:12 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:16:12 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:16:13 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:16:13 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:16:13 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:16:13 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:16:13\n",
      "INFO\t2019-03-22 16:16:13 +0100\tmaster-replica-0\t3\tSaving dict for global step 400: accuracy = 0.9104, average_loss = 0.33777335, global_step = 400, loss = 42.756123\n",
      "INFO\t2019-03-22 16:16:16 +0100\tmaster-replica-0\t3\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-03-22 16:16:17 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 400: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-400\n",
      "INFO\t2019-03-22 16:16:20 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:16:20 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:16:20 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:16:20\n",
      "INFO\t2019-03-22 16:16:20 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:16:21 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-400\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-400\n",
      "INFO\t2019-03-22 16:16:22 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "WARNING\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t3\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:16:23\n",
      "INFO\t2019-03-22 16:16:23 +0100\tmaster-replica-0\t4\tSaving dict for global step 400: accuracy = 0.8777, average_loss = 0.42962027, global_step = 400, loss = 54.382313\n",
      "INFO\t2019-03-22 16:16:26 +0100\tmaster-replica-0\t4\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-03-22 16:16:27 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 400: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-400\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:16:32 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-400\n",
      "WARNING\t2019-03-22 16:16:33 +0100\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-22 16:16:33 +0100\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-03-22 16:16:33 +0100\tmaster-replica-0\t4\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-03-22 16:16:33 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:16:33 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:16:35 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553267778'/saved_model.pb\n",
      "INFO\t2019-03-22 16:16:41 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.10524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:16:41 +0100\tmaster-replica-0\t3\tloss = 94.529816, step = 401 (47.500 sec)\n",
      "INFO\t2019-03-22 16:16:42 +0100\tmaster-replica-0\t3\tglobal_step/sec: 60.2118\n",
      "INFO\t2019-03-22 16:16:42 +0100\tmaster-replica-0\t3\tloss = 84.04193, step = 501 (1.661 sec)\n",
      "INFO\t2019-03-22 16:16:44 +0100\tmaster-replica-0\t3\tglobal_step/sec: 76.3628\n",
      "INFO\t2019-03-22 16:16:44 +0100\tmaster-replica-0\t3\tloss = 71.01366, step = 601 (1.309 sec)\n",
      "INFO\t2019-03-22 16:16:45 +0100\tmaster-replica-0\t3\tglobal_step/sec: 67.2474\n",
      "INFO\t2019-03-22 16:16:45 +0100\tmaster-replica-0\t3\tloss = 39.489944, step = 701 (1.488 sec)\n",
      "INFO\t2019-03-22 16:16:45 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553267788'/saved_model.pb\n",
      "INFO\t2019-03-22 16:16:47 +0100\tmaster-replica-0\t3\tSaving checkpoints for 800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:16:51 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.14643\n",
      "INFO\t2019-03-22 16:16:51 +0100\tmaster-replica-0\t4\tloss = 99.2393, step = 401 (46.591 sec)\n",
      "INFO\t2019-03-22 16:16:52 +0100\tmaster-replica-0\t4\tglobal_step/sec: 99.4221\n",
      "INFO\t2019-03-22 16:16:52 +0100\tmaster-replica-0\t4\tloss = 101.1579, step = 501 (1.005 sec)\n",
      "INFO\t2019-03-22 16:16:53 +0100\tmaster-replica-0\t4\tglobal_step/sec: 97.3425\n",
      "INFO\t2019-03-22 16:16:53 +0100\tmaster-replica-0\t4\tloss = 70.70778, step = 601 (1.027 sec)\n",
      "INFO\t2019-03-22 16:16:54 +0100\tmaster-replica-0\t4\tglobal_step/sec: 126.478\n",
      "INFO\t2019-03-22 16:16:54 +0100\tmaster-replica-0\t4\tloss = 82.63219, step = 701 (0.790 sec)\n",
      "INFO\t2019-03-22 16:16:54 +0100\tmaster-replica-0\t4\tSaving checkpoints for 800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:17:02 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:17:02 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:17:02 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:17:02\n",
      "INFO\t2019-03-22 16:17:02 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:17:03 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-800\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:17:05 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:17:06 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:17:06\n",
      "INFO\t2019-03-22 16:17:06 +0100\tmaster-replica-0\t3\tSaving dict for global step 800: accuracy = 0.9385, average_loss = 0.23311755, global_step = 800, loss = 29.50855\n",
      "INFO\t2019-03-22 16:17:06 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 800: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-800\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-800\n",
      "INFO\t2019-03-22 16:17:09 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:17:10 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:17:10 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:17:10\n",
      "INFO\t2019-03-22 16:17:10 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:17:10 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-800\n",
      "INFO\t2019-03-22 16:17:10 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:17:10 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:17:12\n",
      "INFO\t2019-03-22 16:17:12 +0100\tmaster-replica-0\t4\tSaving dict for global step 800: accuracy = 0.9221, average_loss = 0.29591674, global_step = 800, loss = 37.457813\n",
      "INFO\t2019-03-22 16:17:13 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 800: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-800\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-800\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:17:16 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:17:22 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553267827'/saved_model.pb\n",
      "INFO\t2019-03-22 16:17:28 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.36178\n",
      "INFO\t2019-03-22 16:17:28 +0100\tmaster-replica-0\t3\tloss = 51.1835, step = 801 (42.341 sec)\n",
      "INFO\t2019-03-22 16:17:29 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553267834'/saved_model.pb\n",
      "INFO\t2019-03-22 16:17:29 +0100\tmaster-replica-0\t3\tglobal_step/sec: 69.1379\n",
      "INFO\t2019-03-22 16:17:29 +0100\tmaster-replica-0\t3\tloss = 60.671574, step = 901 (1.447 sec)\n",
      "INFO\t2019-03-22 16:17:31 +0100\tmaster-replica-0\t3\tglobal_step/sec: 66.3334\n",
      "INFO\t2019-03-22 16:17:31 +0100\tmaster-replica-0\t3\tloss = 59.72364, step = 1001 (2.255 sec)\n",
      "INFO\t2019-03-22 16:17:33 +0100\tmaster-replica-0\t3\tglobal_step/sec: 46.7854\n",
      "INFO\t2019-03-22 16:17:33 +0100\tmaster-replica-0\t3\tloss = 89.47713, step = 1101 (1.389 sec)\n",
      "INFO\t2019-03-22 16:17:34 +0100\tmaster-replica-0\t3\tSaving checkpoints for 1200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:17:34 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.45254\n",
      "INFO\t2019-03-22 16:17:34 +0100\tmaster-replica-0\t4\tloss = 75.58117, step = 801 (40.775 sec)\n",
      "INFO\t2019-03-22 16:17:35 +0100\tmaster-replica-0\t4\tglobal_step/sec: 104.291\n",
      "INFO\t2019-03-22 16:17:35 +0100\tmaster-replica-0\t4\tloss = 57.183556, step = 901 (0.958 sec)\n",
      "INFO\t2019-03-22 16:17:36 +0100\tmaster-replica-0\t4\tglobal_step/sec: 101.454\n",
      "INFO\t2019-03-22 16:17:36 +0100\tmaster-replica-0\t4\tloss = 67.02675, step = 1001 (0.986 sec)\n",
      "INFO\t2019-03-22 16:17:37 +0100\tmaster-replica-0\t4\tglobal_step/sec: 101.397\n",
      "INFO\t2019-03-22 16:17:37 +0100\tmaster-replica-0\t4\tloss = 24.094227, step = 1101 (0.986 sec)\n",
      "INFO\t2019-03-22 16:17:38 +0100\tmaster-replica-0\t4\tSaving checkpoints for 1200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:17:54 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:17:54 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:17:54 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:17:54\n",
      "INFO\t2019-03-22 16:17:54 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:17:54 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:17:56\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:17:56 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:17:57 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:17:57 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:17:57 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:17:57 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:17:57\n",
      "INFO\t2019-03-22 16:17:57 +0100\tmaster-replica-0\t4\tSaving dict for global step 1200: accuracy = 0.9349, average_loss = 0.23593035, global_step = 1200, loss = 29.864601\n",
      "INFO\t2019-03-22 16:17:57 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 1200: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:17:59\n",
      "INFO\t2019-03-22 16:17:59 +0100\tmaster-replica-0\t3\tSaving dict for global step 1200: accuracy = 0.9466, average_loss = 0.19556397, global_step = 1200, loss = 24.754932\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 1200: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:18:00 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:18:01 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:18:01 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:18:01 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:18:03 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-1200\n",
      "INFO\t2019-03-22 16:18:04 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:18:04 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:18:14 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553267878'/saved_model.pb\n",
      "INFO\t2019-03-22 16:18:17 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553267881'/saved_model.pb\n",
      "INFO\t2019-03-22 16:18:19 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.38831\n",
      "INFO\t2019-03-22 16:18:19 +0100\tmaster-replica-0\t4\tloss = 15.888314, step = 1201 (41.871 sec)\n",
      "INFO\t2019-03-22 16:18:20 +0100\tmaster-replica-0\t4\tglobal_step/sec: 106.594\n",
      "INFO\t2019-03-22 16:18:20 +0100\tmaster-replica-0\t4\tloss = 36.78186, step = 1301 (0.938 sec)\n",
      "INFO\t2019-03-22 16:18:21 +0100\tmaster-replica-0\t4\tglobal_step/sec: 97.8736\n",
      "INFO\t2019-03-22 16:18:21 +0100\tmaster-replica-0\t4\tloss = 36.457314, step = 1401 (1.022 sec)\n",
      "INFO\t2019-03-22 16:18:22 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.03616\n",
      "INFO\t2019-03-22 16:18:22 +0100\tmaster-replica-0\t3\tloss = 38.040943, step = 1201 (49.117 sec)\n",
      "INFO\t2019-03-22 16:18:22 +0100\tmaster-replica-0\t4\tglobal_step/sec: 104.189\n",
      "INFO\t2019-03-22 16:18:22 +0100\tmaster-replica-0\t4\tloss = 55.021095, step = 1501 (0.959 sec)\n",
      "INFO\t2019-03-22 16:18:23 +0100\tmaster-replica-0\t4\tSaving checkpoints for 1600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:18:23 +0100\tmaster-replica-0\t3\tglobal_step/sec: 67.2943\n",
      "INFO\t2019-03-22 16:18:23 +0100\tmaster-replica-0\t3\tloss = 47.02013, step = 1301 (1.482 sec)\n",
      "INFO\t2019-03-22 16:18:25 +0100\tmaster-replica-0\t3\tglobal_step/sec: 69.9722\n",
      "INFO\t2019-03-22 16:18:25 +0100\tmaster-replica-0\t3\tloss = 45.49173, step = 1401 (1.428 sec)\n",
      "INFO\t2019-03-22 16:18:26 +0100\tmaster-replica-0\t3\tglobal_step/sec: 63.6661\n",
      "INFO\t2019-03-22 16:18:26 +0100\tmaster-replica-0\t3\tloss = 26.909231, step = 1501 (1.572 sec)\n",
      "INFO\t2019-03-22 16:18:28 +0100\tmaster-replica-0\t3\tSaving checkpoints for 1600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:18:38 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:18:38 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:18:38 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:18:38\n",
      "INFO\t2019-03-22 16:18:38 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:18:38 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:18:40 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:18:40 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:18:41\n",
      "INFO\t2019-03-22 16:18:41 +0100\tmaster-replica-0\t4\tSaving dict for global step 1600: accuracy = 0.9419, average_loss = 0.21221656, global_step = 1600, loss = 26.862854\n",
      "INFO\t2019-03-22 16:18:42 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 1600: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:18:42 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:18:42 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:18:42 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:18:42\n",
      "INFO\t2019-03-22 16:18:42 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:18:43 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:18:45 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:18:46 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:18:45\n",
      "INFO\t2019-03-22 16:18:46 +0100\tmaster-replica-0\t3\tSaving dict for global step 1600: accuracy = 0.9569, average_loss = 0.16551413, global_step = 1600, loss = 20.951155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:18:46 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 1600: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:18:49 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-1600\n",
      "INFO\t2019-03-22 16:18:50 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:18:50 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:18:58 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553267923'/saved_model.pb\n",
      "INFO\t2019-03-22 16:19:03 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553267927'/saved_model.pb\n",
      "INFO\t2019-03-22 16:19:03 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.4474\n",
      "INFO\t2019-03-22 16:19:03 +0100\tmaster-replica-0\t4\tloss = 33.200634, step = 1601 (40.860 sec)\n",
      "INFO\t2019-03-22 16:19:04 +0100\tmaster-replica-0\t4\tglobal_step/sec: 100.597\n",
      "INFO\t2019-03-22 16:19:04 +0100\tmaster-replica-0\t4\tloss = 39.892273, step = 1701 (0.994 sec)\n",
      "INFO\t2019-03-22 16:19:05 +0100\tmaster-replica-0\t4\tglobal_step/sec: 98.744\n",
      "INFO\t2019-03-22 16:19:05 +0100\tmaster-replica-0\t4\tloss = 41.425232, step = 1801 (1.013 sec)\n",
      "INFO\t2019-03-22 16:19:06 +0100\tmaster-replica-0\t4\tglobal_step/sec: 104.823\n",
      "INFO\t2019-03-22 16:19:06 +0100\tmaster-replica-0\t4\tloss = 23.760378, step = 1901 (0.954 sec)\n",
      "INFO\t2019-03-22 16:19:07 +0100\tmaster-replica-0\t4\tSaving checkpoints for 2000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:19:08 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.42071\n",
      "INFO\t2019-03-22 16:19:08 +0100\tmaster-replica-0\t3\tloss = 31.788195, step = 1601 (41.309 sec)\n",
      "INFO\t2019-03-22 16:19:09 +0100\tmaster-replica-0\t3\tglobal_step/sec: 64.2586\n",
      "INFO\t2019-03-22 16:19:09 +0100\tmaster-replica-0\t3\tloss = 31.876236, step = 1701 (1.557 sec)\n",
      "INFO\t2019-03-22 16:19:11 +0100\tmaster-replica-0\t3\tglobal_step/sec: 63.4807\n",
      "INFO\t2019-03-22 16:19:11 +0100\tmaster-replica-0\t3\tloss = 16.692432, step = 1801 (1.574 sec)\n",
      "INFO\t2019-03-22 16:19:12 +0100\tmaster-replica-0\t3\tglobal_step/sec: 74.6567\n",
      "INFO\t2019-03-22 16:19:12 +0100\tmaster-replica-0\t3\tloss = 38.258553, step = 1901 (1.339 sec)\n",
      "INFO\t2019-03-22 16:19:13 +0100\tmaster-replica-0\t3\tSaving checkpoints for 2000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:19:23 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:19:23 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:19:23 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:19:23\n",
      "INFO\t2019-03-22 16:19:24 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:19:24 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:19:26\n",
      "INFO\t2019-03-22 16:19:26 +0100\tmaster-replica-0\t4\tSaving dict for global step 2000: accuracy = 0.9512, average_loss = 0.18039267, global_step = 2000, loss = 22.834515\n",
      "INFO\t2019-03-22 16:19:27 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 2000: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:19:29 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:19:30 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:19:31 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:19:31 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:19:31\n",
      "INFO\t2019-03-22 16:19:31 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:19:31 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:19:33 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:19:33 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:19:34\n",
      "INFO\t2019-03-22 16:19:34 +0100\tmaster-replica-0\t3\tSaving dict for global step 2000: accuracy = 0.9616, average_loss = 0.14815637, global_step = 2000, loss = 18.753971\n",
      "INFO\t2019-03-22 16:19:35 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 2000: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:19:37 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2000\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:19:38 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:19:42 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553267968'/saved_model.pb\n",
      "INFO\t2019-03-22 16:19:48 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.40035\n",
      "INFO\t2019-03-22 16:19:48 +0100\tmaster-replica-0\t4\tloss = 39.84931, step = 2001 (41.661 sec)\n",
      "INFO\t2019-03-22 16:19:49 +0100\tmaster-replica-0\t4\tglobal_step/sec: 101.665\n",
      "INFO\t2019-03-22 16:19:49 +0100\tmaster-replica-0\t4\tloss = 43.233955, step = 2101 (0.983 sec)\n",
      "INFO\t2019-03-22 16:19:49 +0100\tmaster-replica-0\t4\tglobal_step/sec: 109.276\n",
      "INFO\t2019-03-22 16:19:49 +0100\tmaster-replica-0\t4\tloss = 11.788353, step = 2201 (0.915 sec)\n",
      "INFO\t2019-03-22 16:19:50 +0100\tmaster-replica-0\t4\tglobal_step/sec: 102.409\n",
      "INFO\t2019-03-22 16:19:50 +0100\tmaster-replica-0\t4\tloss = 45.510124, step = 2301 (0.977 sec)\n",
      "INFO\t2019-03-22 16:19:51 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553267976'/saved_model.pb\n",
      "INFO\t2019-03-22 16:19:51 +0100\tmaster-replica-0\t4\tSaving checkpoints for 2400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:19:56 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.29833\n",
      "INFO\t2019-03-22 16:19:56 +0100\tmaster-replica-0\t3\tloss = 22.367535, step = 2001 (44.258 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:19:58 +0100\tmaster-replica-0\t3\tglobal_step/sec: 44.956\n",
      "INFO\t2019-03-22 16:19:58 +0100\tmaster-replica-0\t3\tloss = 21.221863, step = 2101 (1.477 sec)\n",
      "INFO\t2019-03-22 16:19:59 +0100\tmaster-replica-0\t3\tglobal_step/sec: 62.6646\n",
      "INFO\t2019-03-22 16:19:59 +0100\tmaster-replica-0\t3\tloss = 23.630194, step = 2201 (1.595 sec)\n",
      "INFO\t2019-03-22 16:20:01 +0100\tmaster-replica-0\t3\tglobal_step/sec: 77.4973\n",
      "INFO\t2019-03-22 16:20:01 +0100\tmaster-replica-0\t3\tloss = 32.08347, step = 2301 (1.290 sec)\n",
      "INFO\t2019-03-22 16:20:02 +0100\tmaster-replica-0\t3\tSaving checkpoints for 2400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:20:09 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:20:09 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:20:09 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:20:09\n",
      "INFO\t2019-03-22 16:20:09 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:20:09 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:20:11 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:20:12 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:20:12\n",
      "INFO\t2019-03-22 16:20:12 +0100\tmaster-replica-0\t4\tSaving dict for global step 2400: accuracy = 0.9554, average_loss = 0.16451815, global_step = 2400, loss = 20.825083\n",
      "INFO\t2019-03-22 16:20:12 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 2400: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:20:15 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:20:18 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:20:19 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:20:19 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:20:19\n",
      "INFO\t2019-03-22 16:20:19 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:20:19 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:20:21 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:20:21 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:20:21 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:20:22\n",
      "INFO\t2019-03-22 16:20:22 +0100\tmaster-replica-0\t3\tSaving dict for global step 2400: accuracy = 0.9609, average_loss = 0.14123131, global_step = 2400, loss = 17.87738\n",
      "INFO\t2019-03-22 16:20:23 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 2400: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:20:25 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2400\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:20:26 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:20:28 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553268013'/saved_model.pb\n",
      "INFO\t2019-03-22 16:20:35 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.2408\n",
      "INFO\t2019-03-22 16:20:35 +0100\tmaster-replica-0\t4\tloss = 47.285603, step = 2401 (44.627 sec)\n",
      "INFO\t2019-03-22 16:20:36 +0100\tmaster-replica-0\t4\tglobal_step/sec: 104.162\n",
      "INFO\t2019-03-22 16:20:36 +0100\tmaster-replica-0\t4\tloss = 24.594685, step = 2501 (0.960 sec)\n",
      "INFO\t2019-03-22 16:20:37 +0100\tmaster-replica-0\t4\tglobal_step/sec: 106.134\n",
      "INFO\t2019-03-22 16:20:37 +0100\tmaster-replica-0\t4\tloss = 39.126396, step = 2601 (0.943 sec)\n",
      "INFO\t2019-03-22 16:20:38 +0100\tmaster-replica-0\t4\tglobal_step/sec: 106.145\n",
      "INFO\t2019-03-22 16:20:38 +0100\tmaster-replica-0\t4\tloss = 26.602789, step = 2701 (0.941 sec)\n",
      "INFO\t2019-03-22 16:20:38 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553268024'/saved_model.pb\n",
      "INFO\t2019-03-22 16:20:39 +0100\tmaster-replica-0\t4\tSaving checkpoints for 2800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:20:45 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.23174\n",
      "INFO\t2019-03-22 16:20:45 +0100\tmaster-replica-0\t3\tloss = 34.543713, step = 2401 (44.809 sec)\n",
      "INFO\t2019-03-22 16:20:47 +0100\tmaster-replica-0\t3\tglobal_step/sec: 74.3144\n",
      "INFO\t2019-03-22 16:20:47 +0100\tmaster-replica-0\t3\tloss = 22.371485, step = 2501 (1.345 sec)\n",
      "INFO\t2019-03-22 16:20:48 +0100\tmaster-replica-0\t3\tglobal_step/sec: 75.3374\n",
      "INFO\t2019-03-22 16:20:48 +0100\tmaster-replica-0\t3\tloss = 10.957578, step = 2601 (1.327 sec)\n",
      "INFO\t2019-03-22 16:20:49 +0100\tmaster-replica-0\t3\tglobal_step/sec: 76.753\n",
      "INFO\t2019-03-22 16:20:49 +0100\tmaster-replica-0\t3\tloss = 10.55335, step = 2701 (1.303 sec)\n",
      "INFO\t2019-03-22 16:20:51 +0100\tmaster-replica-0\t3\tSaving checkpoints for 2800 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:20:55 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:20:55 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:20:55 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:20:55\n",
      "INFO\t2019-03-22 16:20:56 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:20:56 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:20:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:20:58 +0100\tmaster-replica-0\t4\tSaving dict for global step 2800: accuracy = 0.9571, average_loss = 0.15940186, global_step = 2800, loss = 20.177452\n",
      "INFO\t2019-03-22 16:20:59 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 2800: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:21:01 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:21:02 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:21:07 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:21:07 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:21:07 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:21:07\n",
      "INFO\t2019-03-22 16:21:08 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:21:08 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:21:10\n",
      "INFO\t2019-03-22 16:21:10 +0100\tmaster-replica-0\t3\tSaving dict for global step 2800: accuracy = 0.9646, average_loss = 0.13454215, global_step = 2800, loss = 17.030651\n",
      "INFO\t2019-03-22 16:21:11 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 2800: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:21:14 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:21:15 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-2800\n",
      "INFO\t2019-03-22 16:21:15 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553268060'/saved_model.pb\n",
      "INFO\t2019-03-22 16:21:15 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:21:15 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:21:22 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.27521\n",
      "INFO\t2019-03-22 16:21:22 +0100\tmaster-replica-0\t4\tloss = 10.736734, step = 2801 (43.953 sec)\n",
      "INFO\t2019-03-22 16:21:23 +0100\tmaster-replica-0\t4\tglobal_step/sec: 106.521\n",
      "INFO\t2019-03-22 16:21:23 +0100\tmaster-replica-0\t4\tloss = 29.333405, step = 2901 (0.939 sec)\n",
      "INFO\t2019-03-22 16:21:24 +0100\tmaster-replica-0\t4\tglobal_step/sec: 101.542\n",
      "INFO\t2019-03-22 16:21:24 +0100\tmaster-replica-0\t4\tloss = 28.315922, step = 3001 (0.985 sec)\n",
      "INFO\t2019-03-22 16:21:25 +0100\tmaster-replica-0\t4\tglobal_step/sec: 112.694\n",
      "INFO\t2019-03-22 16:21:25 +0100\tmaster-replica-0\t4\tloss = 29.073946, step = 3101 (0.887 sec)\n",
      "INFO\t2019-03-22 16:21:25 +0100\tmaster-replica-0\t4\tSaving checkpoints for 3200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:21:27 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553268072'/saved_model.pb\n",
      "INFO\t2019-03-22 16:21:35 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.21614\n",
      "INFO\t2019-03-22 16:21:35 +0100\tmaster-replica-0\t3\tloss = 16.73066, step = 2801 (45.124 sec)\n",
      "INFO\t2019-03-22 16:21:36 +0100\tmaster-replica-0\t3\tglobal_step/sec: 75.2545\n",
      "INFO\t2019-03-22 16:21:36 +0100\tmaster-replica-0\t3\tloss = 28.130444, step = 2901 (1.329 sec)\n",
      "INFO\t2019-03-22 16:21:37 +0100\tmaster-replica-0\t3\tglobal_step/sec: 76.5183\n",
      "INFO\t2019-03-22 16:21:37 +0100\tmaster-replica-0\t3\tloss = 18.909544, step = 3001 (1.307 sec)\n",
      "INFO\t2019-03-22 16:21:38 +0100\tmaster-replica-0\t3\tglobal_step/sec: 78.8956\n",
      "INFO\t2019-03-22 16:21:38 +0100\tmaster-replica-0\t3\tloss = 14.198404, step = 3101 (1.267 sec)\n",
      "INFO\t2019-03-22 16:21:40 +0100\tmaster-replica-0\t3\tSaving checkpoints for 3200 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:21:42 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:21:42 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:21:42 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:21:42\n",
      "INFO\t2019-03-22 16:21:42 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:21:42 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:21:44\n",
      "INFO\t2019-03-22 16:21:44 +0100\tmaster-replica-0\t4\tSaving dict for global step 3200: accuracy = 0.9591, average_loss = 0.15597773, global_step = 3200, loss = 19.744015\n",
      "INFO\t2019-03-22 16:21:45 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 3200: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:21:48 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:21:56 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:21:57 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:21:57 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:21:57\n",
      "INFO\t2019-03-22 16:21:57 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:21:57 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:21:59 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:21:59 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:21:59 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:21:59 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:21:59 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:21:59 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:22:00 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:22:00 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:22:00 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:22:00 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:22:00\n",
      "INFO\t2019-03-22 16:22:00 +0100\tmaster-replica-0\t3\tSaving dict for global step 3200: accuracy = 0.9639, average_loss = 0.14325838, global_step = 3200, loss = 18.133972\n",
      "INFO\t2019-03-22 16:22:00 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 3200: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:22:01 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553268106'/saved_model.pb\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:22:03 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:22:04 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-3200\n",
      "INFO\t2019-03-22 16:22:04 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:22:04 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:22:09 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.27328\n",
      "INFO\t2019-03-22 16:22:09 +0100\tmaster-replica-0\t4\tloss = 14.223584, step = 3201 (44.764 sec)\n",
      "INFO\t2019-03-22 16:22:10 +0100\tmaster-replica-0\t4\tglobal_step/sec: 56.7228\n",
      "INFO\t2019-03-22 16:22:10 +0100\tmaster-replica-0\t4\tloss = 37.424156, step = 3301 (0.989 sec)\n",
      "INFO\t2019-03-22 16:22:11 +0100\tmaster-replica-0\t4\tglobal_step/sec: 103.353\n",
      "INFO\t2019-03-22 16:22:11 +0100\tmaster-replica-0\t4\tloss = 12.859766, step = 3401 (0.967 sec)\n",
      "INFO\t2019-03-22 16:22:12 +0100\tmaster-replica-0\t4\tglobal_step/sec: 124.171\n",
      "INFO\t2019-03-22 16:22:12 +0100\tmaster-replica-0\t4\tloss = 43.828953, step = 3501 (0.805 sec)\n",
      "INFO\t2019-03-22 16:22:13 +0100\tmaster-replica-0\t4\tSaving checkpoints for 3600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:22:16 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553268121'/saved_model.pb\n",
      "INFO\t2019-03-22 16:22:23 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.22727\n",
      "INFO\t2019-03-22 16:22:24 +0100\tmaster-replica-0\t3\tloss = 25.089573, step = 3201 (45.702 sec)\n",
      "INFO\t2019-03-22 16:22:26 +0100\tmaster-replica-0\t3\tglobal_step/sec: 44.8912\n",
      "INFO\t2019-03-22 16:22:26 +0100\tmaster-replica-0\t3\tloss = 29.187962, step = 3301 (1.424 sec)\n",
      "INFO\t2019-03-22 16:22:27 +0100\tmaster-replica-0\t3\tglobal_step/sec: 76.0158\n",
      "INFO\t2019-03-22 16:22:27 +0100\tmaster-replica-0\t3\tloss = 15.573823, step = 3401 (1.315 sec)\n",
      "INFO\t2019-03-22 16:22:28 +0100\tmaster-replica-0\t3\tglobal_step/sec: 75.0237\n",
      "INFO\t2019-03-22 16:22:28 +0100\tmaster-replica-0\t3\tloss = 12.808496, step = 3501 (1.334 sec)\n",
      "INFO\t2019-03-22 16:22:30 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:22:30 +0100\tmaster-replica-0\t3\tSaving checkpoints for 3600 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:22:30 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:22:30 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:22:30\n",
      "INFO\t2019-03-22 16:22:30 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:22:30 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:22:32\n",
      "INFO\t2019-03-22 16:22:32 +0100\tmaster-replica-0\t4\tSaving dict for global step 3600: accuracy = 0.9634, average_loss = 0.13949758, global_step = 3600, loss = 17.657923\n",
      "INFO\t2019-03-22 16:22:33 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 3600: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:22:36 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:22:37 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:22:37 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:22:46 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:22:46 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:22:46 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:22:46\n",
      "INFO\t2019-03-22 16:22:46 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:22:47 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:22:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:22:49 +0100\tmaster-replica-0\t3\tSaving dict for global step 3600: accuracy = 0.9681, average_loss = 0.123379335, global_step = 3600, loss = 15.617637\n",
      "INFO\t2019-03-22 16:22:50 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553268154'/saved_model.pb\n",
      "INFO\t2019-03-22 16:22:50 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 3600: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:22:53 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-3600\n",
      "INFO\t2019-03-22 16:22:54 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:22:54 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:22:57 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.22402\n",
      "INFO\t2019-03-22 16:22:57 +0100\tmaster-replica-0\t4\tloss = 26.453148, step = 3601 (44.965 sec)\n",
      "INFO\t2019-03-22 16:22:58 +0100\tmaster-replica-0\t4\tglobal_step/sec: 100.16\n",
      "INFO\t2019-03-22 16:22:58 +0100\tmaster-replica-0\t4\tloss = 34.28965, step = 3701 (0.998 sec)\n",
      "INFO\t2019-03-22 16:22:59 +0100\tmaster-replica-0\t4\tglobal_step/sec: 102.491\n",
      "INFO\t2019-03-22 16:22:59 +0100\tmaster-replica-0\t4\tloss = 23.476944, step = 3801 (0.976 sec)\n",
      "INFO\t2019-03-22 16:23:00 +0100\tmaster-replica-0\t4\tglobal_step/sec: 114.75\n",
      "INFO\t2019-03-22 16:23:00 +0100\tmaster-replica-0\t4\tloss = 15.649827, step = 3901 (0.871 sec)\n",
      "INFO\t2019-03-22 16:23:01 +0100\tmaster-replica-0\t4\tSaving checkpoints for 4000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:23:06 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553268171'/saved_model.pb\n",
      "INFO\t2019-03-22 16:23:13 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.25617\n",
      "INFO\t2019-03-22 16:23:13 +0100\tmaster-replica-0\t3\tloss = 13.643512, step = 3601 (44.323 sec)\n",
      "INFO\t2019-03-22 16:23:14 +0100\tmaster-replica-0\t3\tglobal_step/sec: 65.0172\n",
      "INFO\t2019-03-22 16:23:14 +0100\tmaster-replica-0\t3\tloss = 19.556637, step = 3701 (1.538 sec)\n",
      "INFO\t2019-03-22 16:23:15 +0100\tmaster-replica-0\t3\tglobal_step/sec: 73.844\n",
      "INFO\t2019-03-22 16:23:15 +0100\tmaster-replica-0\t3\tloss = 13.27293, step = 3801 (1.354 sec)\n",
      "INFO\t2019-03-22 16:23:17 +0100\tmaster-replica-0\t3\tglobal_step/sec: 76.4507\n",
      "INFO\t2019-03-22 16:23:17 +0100\tmaster-replica-0\t3\tloss = 12.913153, step = 3901 (1.307 sec)\n",
      "INFO\t2019-03-22 16:23:18 +0100\tmaster-replica-0\t3\tSaving checkpoints for 4000 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:23:18 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:23:19 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:23:19 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:23:19\n",
      "INFO\t2019-03-22 16:23:19 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:23:19 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:23:21\n",
      "INFO\t2019-03-22 16:23:21 +0100\tmaster-replica-0\t4\tSaving dict for global step 4000: accuracy = 0.9627, average_loss = 0.13595666, global_step = 4000, loss = 17.209703\n",
      "INFO\t2019-03-22 16:23:22 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 4000: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:23:25 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:23:26 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:23:26 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:23:35 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:23:35 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:23:35 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:23:35\n",
      "INFO\t2019-03-22 16:23:35 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:23:35 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:23:37 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:23:37 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:23:38\n",
      "INFO\t2019-03-22 16:23:38 +0100\tmaster-replica-0\t3\tSaving dict for global step 4000: accuracy = 0.9687, average_loss = 0.12446262, global_step = 4000, loss = 15.754763\n",
      "INFO\t2019-03-22 16:23:39 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 4000: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:23:39 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553268203'/saved_model.pb\n",
      "INFO\t2019-03-22 16:23:41 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4000\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:23:42 +0100\tmaster-replica-0\t3\tNo assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:23:46 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.17132\n",
      "INFO\t2019-03-22 16:23:46 +0100\tmaster-replica-0\t4\tloss = 20.837826, step = 4001 (46.056 sec)\n",
      "INFO\t2019-03-22 16:23:47 +0100\tmaster-replica-0\t4\tglobal_step/sec: 104.135\n",
      "INFO\t2019-03-22 16:23:47 +0100\tmaster-replica-0\t4\tloss = 34.581852, step = 4101 (0.961 sec)\n",
      "INFO\t2019-03-22 16:23:48 +0100\tmaster-replica-0\t4\tglobal_step/sec: 102.762\n",
      "INFO\t2019-03-22 16:23:48 +0100\tmaster-replica-0\t4\tloss = 30.548847, step = 4201 (0.973 sec)\n",
      "INFO\t2019-03-22 16:23:49 +0100\tmaster-replica-0\t4\tglobal_step/sec: 112.404\n",
      "INFO\t2019-03-22 16:23:49 +0100\tmaster-replica-0\t4\tloss = 12.6623, step = 4301 (0.889 sec)\n",
      "INFO\t2019-03-22 16:23:50 +0100\tmaster-replica-0\t4\tSaving checkpoints for 4400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:23:55 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553268220'/saved_model.pb\n",
      "INFO\t2019-03-22 16:24:02 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.19774\n",
      "INFO\t2019-03-22 16:24:02 +0100\tmaster-replica-0\t3\tloss = 17.921402, step = 4001 (45.502 sec)\n",
      "INFO\t2019-03-22 16:24:04 +0100\tmaster-replica-0\t3\tglobal_step/sec: 74.7883\n",
      "INFO\t2019-03-22 16:24:04 +0100\tmaster-replica-0\t3\tloss = 14.218153, step = 4101 (1.337 sec)\n",
      "INFO\t2019-03-22 16:24:05 +0100\tmaster-replica-0\t3\tglobal_step/sec: 75.0281\n",
      "INFO\t2019-03-22 16:24:05 +0100\tmaster-replica-0\t3\tloss = 17.307045, step = 4201 (1.333 sec)\n",
      "INFO\t2019-03-22 16:24:06 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:24:06 +0100\tmaster-replica-0\t3\tglobal_step/sec: 77.6347\n",
      "INFO\t2019-03-22 16:24:06 +0100\tmaster-replica-0\t3\tloss = 8.878013, step = 4301 (1.288 sec)\n",
      "INFO\t2019-03-22 16:24:06 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:24:06 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:24:06\n",
      "INFO\t2019-03-22 16:24:07 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:24:07 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:24:08 +0100\tmaster-replica-0\t3\tSaving checkpoints for 4400 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:24:08 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:24:08 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:24:09\n",
      "INFO\t2019-03-22 16:24:09 +0100\tmaster-replica-0\t4\tSaving dict for global step 4400: accuracy = 0.9662, average_loss = 0.1250491, global_step = 4400, loss = 15.8289995\n",
      "INFO\t2019-03-22 16:24:10 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 4400: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:24:12 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:24:13 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:24:13 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:24:13 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:24:24 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:24:24 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:24:24 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:24:24\n",
      "INFO\t2019-03-22 16:24:24 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:24:24 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:24:26 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553268250'/saved_model.pb\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:24:27\n",
      "INFO\t2019-03-22 16:24:27 +0100\tmaster-replica-0\t3\tSaving dict for global step 4400: accuracy = 0.9708, average_loss = 0.11190309, global_step = 4400, loss = 14.1649475\n",
      "INFO\t2019-03-22 16:24:28 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 4400: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:24:30 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4400\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:24:31 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:24:33 +0100\tmaster-replica-0\t4\tglobal_step/sec: 2.26361\n",
      "INFO\t2019-03-22 16:24:34 +0100\tmaster-replica-0\t4\tloss = 16.210594, step = 4401 (45.082 sec)\n",
      "INFO\t2019-03-22 16:24:35 +0100\tmaster-replica-0\t4\tglobal_step/sec: 51.0857\n",
      "INFO\t2019-03-22 16:24:35 +0100\tmaster-replica-0\t4\tloss = 14.491998, step = 4501 (1.053 sec)\n",
      "INFO\t2019-03-22 16:24:36 +0100\tmaster-replica-0\t4\tglobal_step/sec: 103.523\n",
      "INFO\t2019-03-22 16:24:36 +0100\tmaster-replica-0\t4\tloss = 7.142703, step = 4601 (0.966 sec)\n",
      "INFO\t2019-03-22 16:24:37 +0100\tmaster-replica-0\t4\tSaving checkpoints for 4688 into gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt.\n",
      "INFO\t2019-03-22 16:24:44 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553268269'/saved_model.pb\n",
      "INFO\t2019-03-22 16:24:51 +0100\tmaster-replica-0\t3\tglobal_step/sec: 2.22028\n",
      "INFO\t2019-03-22 16:24:52 +0100\tmaster-replica-0\t3\tloss = 14.402942, step = 4401 (45.894 sec)\n",
      "INFO\t2019-03-22 16:24:54 +0100\tmaster-replica-0\t3\tglobal_step/sec: 44.0277\n",
      "INFO\t2019-03-22 16:24:54 +0100\tmaster-replica-0\t3\tloss = 7.1172733, step = 4501 (1.416 sec)\n",
      "INFO\t2019-03-22 16:24:54 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:24:54 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:24:54 +0100\tmaster-replica-0\t4\tStarting evaluation at 2019-03-22-15:24:54\n",
      "INFO\t2019-03-22 16:24:54 +0100\tmaster-replica-0\t4\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:24:54 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:24:55 +0100\tmaster-replica-0\t3\tglobal_step/sec: 70.5818\n",
      "INFO\t2019-03-22 16:24:55 +0100\tmaster-replica-0\t3\tloss = 29.295494, step = 4601 (1.417 sec)\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tEvaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t3\tSaving checkpoints for 4688 into gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt.\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tFinished evaluation at 2019-03-22-15:24:56\n",
      "INFO\t2019-03-22 16:24:56 +0100\tmaster-replica-0\t4\tSaving dict for global step 4688: accuracy = 0.9658, average_loss = 0.13250943, global_step = 4688, loss = 16.773344\n",
      "INFO\t2019-03-22 16:24:57 +0100\tmaster-replica-0\t4\tSaving 'checkpoint_path' summary for global step 4688: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:25:00 +0100\tmaster-replica-0\t4\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:25:01 +0100\tmaster-replica-0\t4\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/4/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:25:01 +0100\tmaster-replica-0\t4\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:25:01 +0100\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-03-22 16:25:12 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:25:13 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:25:13 +0100\tmaster-replica-0\t3\tStarting evaluation at 2019-03-22-15:25:13\n",
      "INFO\t2019-03-22 16:25:13 +0100\tmaster-replica-0\t3\tGraph was finalized.\n",
      "INFO\t2019-03-22 16:25:13 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:25:14 +0100\tmaster-replica-0\t4\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4/export/exporter/temp-b'1553268298'/saved_model.pb\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tRunning local_init_op.\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tDone running local_init_op.\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tEvaluation [10/100]\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tEvaluation [20/100]\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tEvaluation [30/100]\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tEvaluation [40/100]\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tEvaluation [50/100]\n",
      "INFO\t2019-03-22 16:25:15 +0100\tmaster-replica-0\t3\tEvaluation [60/100]\n",
      "INFO\t2019-03-22 16:25:16 +0100\tmaster-replica-0\t3\tEvaluation [70/100]\n",
      "INFO\t2019-03-22 16:25:16 +0100\tmaster-replica-0\t3\tFinished evaluation at 2019-03-22-15:25:16\n",
      "INFO\t2019-03-22 16:25:16 +0100\tmaster-replica-0\t3\tSaving dict for global step 4688: accuracy = 0.967, average_loss = 0.13413288, global_step = 4688, loss = 16.978846\n",
      "INFO\t2019-03-22 16:25:16 +0100\tmaster-replica-0\t3\tSaving 'checkpoint_path' summary for global step 4688: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tCalling model_fn.\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tDone calling model_fn.\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tExport includes no default signature!\n",
      "INFO\t2019-03-22 16:25:19 +0100\tmaster-replica-0\t3\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190322_155703/3/model.ckpt-4688\n",
      "INFO\t2019-03-22 16:25:20 +0100\tmaster-replica-0\t3\tAssets added to graph.\n",
      "INFO\t2019-03-22 16:25:20 +0100\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tLoss for final step: 13.487709.\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tArguments:\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\t{'train_steps': 5000, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'eval_delay_secs': 1, 'train_batch_size': 165, 'hidden_units': '256 128 64', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703', 'min_eval_frequency': 5, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs'}\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tArguments:\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\t{'train_steps': 5000, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'eval_delay_secs': 1, 'train_batch_size': 165, 'hidden_units': [256, 128, 64], 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703', 'min_eval_frequency': 5, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs'}\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tSave output to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\t## start training and evaluation\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190322_155703/4\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tModule completed; cleaning up.\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tClean up finished.\n",
      "INFO\t2019-03-22 16:25:22 +0100\tmaster-replica-0\t4\tTask completed successfully.\n",
      "INFO\t2019-03-22 16:25:34 +0100\tmaster-replica-0\t3\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3/export/exporter/temp-b'1553268317'/saved_model.pb\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\tLoss for final step: 2.6607618.\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\tArguments:\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\t{'train_batch_size': 195, 'train_steps': 5000, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703', 'hidden_units': '512 256 128 64', 'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', 'min_eval_frequency': 5}\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\tArguments:\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\t{'train_batch_size': 195, 'train_steps': 5000, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703', 'hidden_units': [512, 256, 128, 64], 'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs', 'min_eval_frequency': 5}\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\tSave output to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\t## start training and evaluation\n",
      "INFO\t2019-03-22 16:25:41 +0100\tmaster-replica-0\t3\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190322_155703/3\n",
      "INFO\t2019-03-22 16:25:42 +0100\tmaster-replica-0\t3\tModule completed; cleaning up.\n",
      "INFO\t2019-03-22 16:25:42 +0100\tmaster-replica-0\t3\tClean up finished.\n",
      "INFO\t2019-03-22 16:25:42 +0100\tmaster-replica-0\t3\tTask completed successfully.\n",
      "INFO\t2019-03-22 16:28:31 +0100\tservice\t\tJob completed successfully.\n",
      "INFO\t2019-03-22 16:29:24 +0100\tservice\t\tJob completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs stream-logs %JOBNAME%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Get results from job using API\n",
    "\n",
    "See [client documentation on ml-engine](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library#putting_it_all_together) and [` ml.projects().jobs().get()`](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs/get) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using `requests-package` behind a proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://ml.googleapis.com/v1/projects/{project}/jobs/{jobname}'.format(project=PROJECT, jobname='mnist_190322_155703')\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace('\\r\\n', ''))\n",
    "}\n",
    "print(headers)\n",
    "json_response = requests.get(url=url, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://ml.googleapis.com/v1/projects/{project}/jobs'.format(project=PROJECT)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace('\\r\\n', ''))\n",
    "}\n",
    "json_response = requests.get(url=url, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using `googleapiclient.discorvery`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "import httplib2\n",
    "# Store your full project ID in a variable in the format the API needs.\n",
    "# Build a representation of the Cloud ML API.\n",
    "ml = discovery.build('ml', 'v1', http= httplib2.Http(disable_ssl_certificate_validation=True)) #, credentials=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ml.projects().jobs().list(parent='projects/{}'.format(PROJECT)).execute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "request = ml.projects().jobs().get(\n",
    "    name='projects/{project}/jobs/{jobname}'.format(\n",
    "        project=PROJECT, jobname='mnist_190322_155703'))\n",
    "request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createTime': '2019-03-22T14:57:15Z',\n",
      " 'endTime': '2019-03-22T15:29:36Z',\n",
      " 'etag': 'D7kQj0eIfWQ=',\n",
      " 'jobId': 'mnist_190322_155703',\n",
      " 'startTime': '2019-03-22T14:57:18Z',\n",
      " 'state': 'SUCCEEDED',\n",
      " 'trainingInput': {'args': ['--data_path',\n",
      "                            'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz',\n",
      "                            '--output_dir',\n",
      "                            'gs://ml-productive-pipeline-53122/mnist_190322_155703',\n",
      "                            '--train_steps',\n",
      "                            '5000',\n",
      "                            '--job_dir',\n",
      "                            'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs'],\n",
      "                   'hyperparameters': {'goal': 'MAXIMIZE',\n",
      "                                       'hyperparameterMetricTag': 'accuracy',\n",
      "                                       'maxParallelTrials': 2,\n",
      "                                       'maxTrials': 4,\n",
      "                                       'params': [{'maxValue': 512,\n",
      "                                                   'minValue': 64,\n",
      "                                                   'parameterName': 'train_batch_size',\n",
      "                                                   'scaleType': 'UNIT_LOG_SCALE',\n",
      "                                                   'type': 'INTEGER'},\n",
      "                                                  {'categoricalValues': ['128 '\n",
      "                                                                         '64 '\n",
      "                                                                         '32',\n",
      "                                                                         '256 '\n",
      "                                                                         '128 '\n",
      "                                                                         '64',\n",
      "                                                                         '512 '\n",
      "                                                                         '256 '\n",
      "                                                                         '128 '\n",
      "                                                                         '64'],\n",
      "                                                   'parameterName': 'hidden_units',\n",
      "                                                   'type': 'CATEGORICAL'}]},\n",
      "                   'packageUris': ['gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
      "                   'pythonModule': 'pkg_mnist_fnn.task',\n",
      "                   'pythonVersion': '3.5',\n",
      "                   'region': 'europe-west1',\n",
      "                   'runtimeVersion': '1.12'},\n",
      " 'trainingOutput': {'completedTrialCount': '4',\n",
      "                    'consumedMLUnits': 0.43,\n",
      "                    'isHyperparameterTuningJob': True,\n",
      "                    'trials': [{'finalMetric': {'objectiveValue': 0.9684000015258789,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '256 128 '\n",
      "                                                                    '64',\n",
      "                                                    'train_batch_size': '165'},\n",
      "                                'trialId': '2'},\n",
      "                               {'finalMetric': {'objectiveValue': 0.9670000076293945,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '512 256 '\n",
      "                                                                    '128 64',\n",
      "                                                    'train_batch_size': '195'},\n",
      "                                'trialId': '3'},\n",
      "                               {'finalMetric': {'objectiveValue': 0.9657999873161316,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '256 128 '\n",
      "                                                                    '64',\n",
      "                                                    'train_batch_size': '165'},\n",
      "                                'trialId': '4'},\n",
      "                               {'finalMetric': {'objectiveValue': 0.9401000142097473,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '128 64 32',\n",
      "                                                    'train_batch_size': '314'},\n",
      "                                'trialId': '1'}]}}\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "from pprint import pprint\n",
    "\n",
    "endpoint = 'projects/{project}/jobs/{jobname}'.format(project=PROJECT, jobname='mnist_190322_155703')\n",
    "print(\"API endpoint: {}\".format(endpoint))\n",
    "request = ml.projects().jobs().get(name=endpoint)\n",
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    pprint(response)\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Check Results in TensorBoard\n",
    "\n",
    "- metrics and variables are inspected from the logs, called checkpoints (`ckpt`)\n",
    "- Dashboard on localhost: `TensorBoard`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In Datalab Tensorboard is available using a special package. On your local machine, you can execute tensorflow using the command line.\n",
    "\n",
    "DATALAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(('{}/'+os.environ['PKG_NAME']).format(os.environ['PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If the above step (to stop TensorBoard) appears stalled, just move on to the next step. You don't need to wait for it to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Inspect Model trained on your machine:\n",
    "- `tensorboard --logdir trained/pkg_mnist_fnn/`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!tensorboard --logdir trained/pkg_mnist_fnn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "tensorboard $PWD/$OUTDIR_LOCAL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!echo \"tensorboard --logdir $PWD/src/$PKG_NAME/trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Or trained on GCP, where results are store in Google Cloud Storage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "#gcloud auth application-default login\n",
    "echo $OUTDIR\n",
    "tensorboard --logdir $OUTDIR"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%cmd\n",
    "echo %OUTDIR%\n",
    "tensorboard --logdir trained/pkg_mnist_fnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Excursus: Load data from the bucket\n",
    "\n",
    "- Binary Object has to be read by `BytesIO` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\google\\auth\\_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT) # use current gcloud PROJECT_ID\n",
    "bucket = storage_client.get_bucket(BUCKET)\n",
    "blob = bucket.blob(\"pkg_mnist_fnn/data/mnist.npz\")\n",
    "\n",
    "data = blob.download_as_string()\n",
    "data = BytesIO(data)\n",
    "data = np.load(data)\n",
    "with data as f:\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#ToDo# Does only work under linux-> version?\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "f = BytesIO(file_io.read_file_to_string(\n",
    "    filename=DATA, #'gs://BUCKET/PKG_NAME/data/mnist.npz', \n",
    "    binary_mode=True\n",
    "))\n",
    "data = np.load(f)\n",
    "with data as f:\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deploy model - from any previous step (DSP 2.5)\n",
    "\n",
    "- `tf.estimator.LatestExporter`is used to store a model for deployment in the cloud\n",
    "- See also:  `tf.estimator.export`, `tf.saved_model`\n",
    "\n",
    "[Link to Console](https://console.cloud.google.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Check that a model has been saved on your Bucket:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "#gcloud auth application-default login\n",
    "echo $OUTDIR\n",
    "gsutil ls ${OUTDIR}/export/exporter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%cmd\n",
    "#gcloud auth application-default login\n",
    "echo %OUTDIR%\n",
    "gsutil ls %OUTDIR%/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/export/exporter/',\n",
       " 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/export/exporter/1553251591/',\n",
       " \"gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/export/exporter/temp-b'1553251669'/\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = !gsutil ls %OUTDIR%/export/exporter/\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_LOCATION=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/export/exporter/1553251591/\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_LOCATION={models[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Identifier for deployed model:\n",
    "- `MODEL_NAME`\n",
    "- `MODEL_VERSION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"MNIST_MLENGINE\"\n",
    "MODEL_VERSION=\"v1\" \n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/$PKG_NAME/trained/export/exporter | tail -1)\n",
    "echo \"Run these commands one-by-one (the very first time, you'll create a model and then create a version)\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models   create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} \\\n",
    "     --origin ${MODEL_LOCATION} \\\n",
    "     --runtime-version $TFVERSION \\\n",
    "     --python-version 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "MODEL_NAME=\"MNIST_MLENGINE\"\n",
    "MODEL_VERSION=\"v1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Create: A model (Dataset) has different versions (Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gcloud ml-engine models   create %MODEL_NAME% --regions %REGION%\n",
    "gcloud ml-engine versions create %MODEL_VERSION% --model %MODEL_NAME% ^\n",
    "     --origin %MODEL_LOCATION% ^\n",
    "     --runtime-version %TFVERSION% ^\n",
    "     --python-version 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "gcloud ml-engine versions delete %MODEL_VERSION% --model %MODEL_NAME%\n",
    "gcloud ml-engine models delete %MODEL_NAME%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine versions create --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Using the Model saved by Python Module\n",
    "2. Using Model saved by `ml-engine local`\n",
    "3. Using Model trained online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tools get predictions:\n",
    "- Command Line Interfaces\n",
    "    - `gcloud ml-engine local predict`\n",
    "    - `gcloud ml-engine predict`\n",
    "- Python Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create an test-image in numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N=4\n",
    "testdatafile = \"data/mnist/json/ml_engine_testdatafile_N{}.json\".format(N)\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "with open(\"config.yaml\", \"w\", encoding = \"utf8\") as f:\n",
    "    config['testdatafile'] = testdatafile\n",
    "    yaml.dump(config, stream=f,  default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from data\\mnist\\raw\\mnist.npz\n",
      "Wrote to data/mnist/json/ml_engine_testdatafile_N4.json\n"
     ]
    }
   ],
   "source": [
    "# Create a file with 4 test images\n",
    "import numpy as np\n",
    "import json\n",
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(path='data/mnist/raw/mnist.npz')\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()\n",
    "\n",
    "#eol = os.linesep\n",
    "#print(eol)\n",
    "n_lines = len(y_test)\n",
    "with open(testdatafile, \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        _dict = {\"x\": image} #, \"y\": int(label)}\n",
    "        f.write(json.dumps(_dict)+ \"\\n\")\n",
    "print(\"Wrote to {}\".format(testdatafile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's look at our four examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata\n",
    "plot_mnist_testdata(TEST_DATA_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML-Engine: `ml-engine local predict`\n",
    "- Using Model saved\n",
    "  - Python module\n",
    "  - `ml-engine local`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### `ML-Engine local` using Python 3 ...\n",
    "you still have to remove manually some compiled python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flags.pyc', 'jobs_prep.pyc', 'jobs_util.pyc', 'local_predict.pyc', 'local_train.pyc', 'local_utils.pyc', 'log_utils.pyc', 'models_util.pyc', 'operations_util.pyc', 'predict_utilities.pyc', 'uploads.pyc', 'versions_util.pyc', '__init__.pyc']\n"
     ]
    }
   ],
   "source": [
    "#/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/\n",
    "folder = \"C:\\\\eplatform\\\\tools\\\\google-cloud-sdk\\\\lib\\\\googlecloudsdk\\\\command_lib\\\\ml_engine\\\\\"\n",
    "files = os.listdir(folder)\n",
    "files = [x for x in files if \".pyc\" in x]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for x in files:\n",
    "    assert \".pyc\" in x\n",
    "    path_ = os.path.join(folder, x)\n",
    "    os.remove(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flags.py', 'jobs_prep.py', 'jobs_util.py', 'local_predict.py', 'local_train.py', 'local_utils.py', 'log_utils.py', 'models_util.py', 'operations_util.py', 'predict_utilities.py', 'resources.yaml', 'uploads.py', 'versions_util.py', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "folder = \"C:\\\\eplatform\\\\tools\\\\google-cloud-sdk\\\\lib\\\\googlecloudsdk\\\\command_lib\\\\ml_engine\\\\\"\n",
    "files = os.listdir(folder)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to work with `Python 3`, delete the `*.pyc` files, see [post](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)\n",
    "\n",
    "Default Datalab\n",
    "```\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "Default UNIX:\n",
    "```\n",
    "sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "\n",
    "> Process running Datalab or Jupyter Notebook needs admin rights. This is not always given for locally run notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: model_dir=1555329649\n"
     ]
    }
   ],
   "source": [
    "model_dir = os.listdir(\"{}/export/exporter\".format(OUTDIR_local))[-1]\n",
    "%env model_dir=$model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "set MODEL_LOCATION=%OUTDIR_LOCAL%\\export\\exporter\\%model_dir%\\\n",
    "echo \"Selected Model:  %MODEL_LOCATION%\" \n",
    "gcloud ml-engine local predict ^\n",
    "    --model-dir=%MODEL_LOCATION% ^\n",
    "    --json-instances=%TEST_DATA_JSON% ^\n",
    "    --verbosity debug > data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "notepad data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $OUTDIR_LOCAL/export/exporter/ | tail -1)\n",
    "echo \"Selected Model:  $model_dir\" \n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/$OUTDIR_LOCAL/export/exporter/${model_dir} \\\n",
    "    --json-instances=$TEST_DATA_JSON \\\n",
    "    --verbosity debug > data/test_predictions\n",
    "cat data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "    gcloud ml-engine local predict - run prediction locally\n",
      "\n",
      "SYNOPSIS\n",
      "    gcloud ml-engine local predict --model-dir=MODEL_DIR\n",
      "        (--json-instances=JSON_INSTANCES | --text-instances=TEXT_INSTANCES)\n",
      "        [--framework=FRAMEWORK] [--signature-name=SIGNATURE_NAME]\n",
      "        [GCLOUD_WIDE_FLAG ...]\n",
      "\n",
      "DESCRIPTION\n",
      "    gcloud ml-engine local predict performs prediction locally with the given\n",
      "    instances. It requires the TensorFlow SDK be installed locally. The output\n",
      "    format mirrors gcloud ml-engine predict (online prediction)\n",
      "\n",
      "REQUIRED FLAGS\n",
      "     --model-dir=MODEL_DIR\n",
      "        Path to the model.\n",
      "\n",
      "     Exactly one of these must be specified:\n",
      "\n",
      "       --json-instances=JSON_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          JSON format; newline delimited.\n",
      "\n",
      "          An example of the JSON instances file:\n",
      "\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 3}\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 2}\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "       --text-instances=TEXT_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          UTF-8 encoded text format; newline delimited.\n",
      "\n",
      "          An example of the text instances file:\n",
      "\n",
      "              107,4.9,2.5,4.5,1.7\n",
      "              100,5.7,2.8,4.1,1.3\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "OPTIONAL FLAGS\n",
      "     --framework=FRAMEWORK\n",
      "        The ML framework used to train this version of the model. If not\n",
      "        specified, defaults to tensorflow. FRAMEWORK must be one of:\n",
      "        scikit-learn, tensorflow, xgboost.\n",
      "\n",
      "     --signature-name=SIGNATURE_NAME\n",
      "        The name of the signature defined in the SavedModel to use for this\n",
      "        job. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY in\n",
      "        https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants,\n",
      "        which is \"serving_default\". Only applies to TensorFlow models.\n",
      "\n",
      "GCLOUD WIDE FLAGS\n",
      "    These flags are available to all commands: --account, --configuration,\n",
      "    --flags-file, --flatten, --format, --help, --log-http, --project, --quiet,\n",
      "    --trace-token, --user-output-enabled, --verbosity. Run $ gcloud help for\n",
      "    details.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Prediction - Command Line\n",
    "\n",
    "- same output format as before,  check Console: [link](https://console.cloud.google.com/mlengine/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                     PROBABILITIES\n",
      "[7]        [u'7']   [-18.08372688293457, 11.735553741455078, 15.616212844848633, 14.03066349029541, -0.6317962408065796, -2.04111385345459, -11.818678855895996, 29.272483825683594, -2.0749940872192383, 16.079999923706055]  [2.7130536564103716e-21, 2.4199511727829304e-08, 1.172614929600968e-06, 2.4019286115617433e-07, 1.0297572663282503e-13, 2.515796104155931e-14, 1.4267008546064546e-18, 0.9999966621398926, 2.4319928666402535e-14, 1.8645566797204083e-06]\n",
      "[1]        [u'1']   [-2.413085460662842, 34.626976013183594, 18.28093719482422, 1.7010812759399414, 6.1150922775268555, -8.507043838500977, 16.06696128845215, 18.03011703491211, 14.762093544006348, -6.75105619430542]       [8.197952131719092e-17, 0.9999997615814209, 7.961693171409934e-08, 5.017242538449132e-15, 4.1442554683107646e-13, 1.8498389965009383e-19, 8.6993727776985e-09, 6.195489277160959e-08, 2.3593405007460433e-09, 1.07089935047685e-18]\n",
      "[6]        [u'6']   [6.8325605392456055, 6.946202754974365, 9.5951566696167, 9.523468971252441, 18.3110294342041, 21.751285552978516, 28.758548736572266, 7.328857898712158, 0.727865993976593, 1.2695865631103516]            [3.0009530971319975e-10, 3.362119749272807e-10, 4.753784033084685e-09, 4.42491598917627e-09, 2.899308856285643e-05, 0.0009044378530234098, 0.9990666508674622, 4.929442409817852e-10, 6.699205534928254e-13, 1.1515687492122395e-12]\n",
      "[8]        [u'8']   [0.6316245198249817, 5.587422847747803, 5.306960105895996, 7.102751731872559, 1.7602770328521729, 6.409003257751465, 1.5505683422088623, 1.456658959388733, 14.903203010559082, 3.5494651794433594]        [6.332705879685818e-07, 8.992182847578079e-05, 6.79300501360558e-05, 0.000409227010095492, 1.9577485090849223e-06, 0.00020449051226023585, 1.5873832808210864e-06, 1.4450987464442733e-06, 0.9992110729217529, 1.1716329026967287e-05]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=$TEST_DATA_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=%TEST_DATA_JSON%\n",
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                  PROBABILITIES\r\n",
      "[6]        [u'6']   [14.841353416442871, 11.691999435424805, 17.271425247192383, 12.454808235168457, 27.320730209350586, 33.3737678527832, 46.4919319152832, 11.619453430175781, 2.0705859661102295, -0.08118200302124023]  [1.796089488346076e-14, 7.701577192691577e-16, 2.0403012504326135e-13, 1.6514434083610011e-15, 4.721195434598258e-09, 2.0084121388208587e-06, 0.9999979734420776, 7.162657244561357e-16, 5.1056873511003206e-20, 5.9368125811994605e-21]\r\n",
      "[5]        [u'5']   [19.24078369140625, -3.418696641921997, -12.680668830871582, 32.72875213623047, 7.14021110534668, 54.7695426940918, 17.188615798950195, 10.948305130004883, 32.959842681884766, 27.2398738861084]       [3.715831630953149e-16, 5.360044843016428e-26, 5.090327634879915e-30, 2.677973676146195e-10, 2.0646349329450793e-21, 1.0, 4.77322223280785e-17, 9.304202493239468e-20, 3.3741753835414556e-10, 1.106666407818535e-12]\r\n",
      "[4]        [u'4']   [-1.6974650621414185, 1.659282922744751, 5.615025997161865, -9.103403091430664, 13.932087898254395, -8.618605613708496, 2.085800886154175, 5.352936267852783, -0.08024734258651733, 5.92873477935791]   [1.628669821229778e-07, 4.6735835894651245e-06, 0.00024412221682723612, 9.896338609705069e-11, 0.9992210865020752, 1.6070146602320534e-10, 7.15953137842007e-06, 0.0001878380571724847, 8.206951633837889e-07, 0.0003340792318340391]\r\n",
      "[8]        [u'8']   [0.4420117139816284, 2.301677703857422, 1.9346401691436768, 3.994138717651367, 1.1992884874343872, 4.05784273147583, 0.39578577876091003, 0.9556518197059631, 9.092337608337402, 2.8936572074890137]    [0.0001720485306577757, 0.0011048251762986183, 0.0007654046639800072, 0.006002332549542189, 0.00036688667023554444, 0.006397147662937641, 0.00016427633818238974, 0.0002875557984225452, 0.982742428779602, 0.0019970412831753492]\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>"
     ]
    }
   ],
   "source": [
    "%%cmd  \n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=%TEST_DATA_JSON%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5oAAADjCAYAAADkMGsfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHW9JREFUeJzt3XmQnFW9N/DfQcBSlgsEZQnxBTS4USgYMRaKWNErIBCRRVCLWIq4gIJalAilF8QStIQXEUECQYjel3BLwcQLqMh6EVEgRsIaXCIgMUBIaQhK0Jz3jzTeGPr0zPSc7n6S+XyqUpl5vvP085tmvgknvZyUcw4AAACoZb1BDwAAAMC6xUITAACAqiw0AQAAqMpCEwAAgKosNAEAAKjKQhMAAICqLDQBAACoykITAACAqiw0AQAAqGr90ZycUto7Ir4eEc+LiAtzzqcP8fV5NNeDtV3OOfXjOroJI6Ob0Ey6Cc00nG6mnLvrSUrpeRGxICLeHhEPR8RtEXF4zvmeDucoJWNaP/7C1E0YOd2EZtJNaKbhdHM0T53dPSJ+k3P+Xc55RUTMioipo7g9oA7dhGbSTWgm3YQeGM1Cc3xEPLTa5w+3jgGDpZvQTLoJzaSb0AOjeY1mu4dLn/M0gpTSURFx1CiuA4yMbkIz6SY0k25CD4xmoflwRExY7fPtIuKRNb8o5zw9IqZHeD479IluQjPpJjSTbkIPjOaps7dFxMSU0g4ppQ0j4rCImFNnLGAUdBOaSTehmXQTeqDrRzRzzn9PKR0TET+OVW8FfVHO+e5qkwFd0U1oJt2EZtJN6I2utzfp6mKeZsAY16/9wEZKNxnrdBOaSTehmXq9vQkAAAA8h4UmAAAAVVloAgAAUJWFJgAAAFVZaAIAAFBV19ubsPY544wzitmnP/3pYnbKKacUs/PPP7+YLVq0aHiDAQAA6xSPaAIAAFCVhSYAAABVWWgCAABQlYUmAAAAVVloAgAAUJWFJgAAAFWlnHP/LpZS/y62jhs3blwx+/a3v932+J577lk8Z5NNNilmnX5Grr766mK2//77F7OxKuecBj1DO7rJWKeb0Ey6Cc00nG56RBMAAICqLDQBAACoykITAACAqiw0AQAAqMpCEwAAgKosNAEAAKhq/UEPQHcmTpxYzPbdd9++zbHZZpv17VoAAMDawSOaAAAAVGWhCQAAQFUWmgAAAFRloQkAAEBVFpoAAABUNap3nU0pLYyIZRHxj4j4e855Uo2hWGXbbbctZkceeWTf5njqqaeK2YwZM/o2B8Onm3Sy6aabFrMpU6YUs6233rqYvfzlLy9mH/7wh4vZQw891Pb4XnvtVTznT3/6UzFrOt0cvY022qiYbbXVVsXs4IMPLmYzZ85se3zJkiXFc5555pli1iQ552J28803F7M3v/nNvRinsXRz3bHlllsWsw984APF7KCDDipm2223XTE7+eSTi9lY///kGtubvDXn/HiF2wHq0k1oJt2EZtJNqMhTZwEAAKhqtAvNHBE/SSndkVI6qsZAQBW6Cc2km9BMugmVjfaps3vknB9JKb04Iq5JKd2Xc75p9S9olVVhob90E5pJN6GZdBMqG9UjmjnnR1q/PxoRV0TE7m2+ZnrOeZIXVUP/6CY0k25CM+km1Nf1QjOltFFKaZNnP46If4+Iu2oNBnRHN6GZdBOaSTehN0bz1NmtIuKKlNKzt/P/cs4/qjIVERHx85//vJiNHz++b3N85CMfKWaXXnpp3+Zg2HRzjOi0Fcl+++1XzDptHbLLLruMZqQRmzhxYtvjc+fOLZ6z6667FrPFixePeqYe0s0K5syZU8w6/Wx32qpr8uTJbY9/6EMfKp6zdOnSYtZv06ZNK2YrVqwoZqeffnovxlkb6eZa5q1vfWsx6/Rz/frXv776LOedd14xe/e7313MDj300GK2fPnyUc3UFF0vNHPOv4uI11ScBahAN6GZdBOaSTehN2xvAgAAQFUWmgAAAFRloQkAAEBVFpoAAABUZaEJAABAVaPZ3oQKPvWpTxWz7bbbrm9znHXWWcXsqquu6tscsC7bYost2h7/7ne/Wzyn058DO++8czHLOQ9/sAEqbRHxjW98Y8TnMDa88pWv7Oq8a665pph12oKgKd72trcVs07bK3TaKujKK68c1UzQay972cvaHp89e3bxnI033riYXXfddcXsiiuuKGad/ozotNXKPvvsU8w69faII44oZmsTj2gCAABQlYUmAAAAVVloAgAAUJWFJgAAAFVZaAIAAFCVhSYAAABV2d5kwHbZZZdiVnt7glNPPbWYnXLKKVWvBWPVZpttVsx+9KMftT3+ute9rlfjtPW3v/2tmC1evLiYXXDBBV1dr9N5y5cvb3v8r3/9a1fXgpLLL7980CMMadttty1mp512WjHbcMMNi9kBBxwwqplgkNZbr/1jYimlrm7v6quvLmbf/OY3i9mcOXOK2fnnn1/M9t5772L2vve9r5ideOKJxezhhx8uZk3jEU0AAACqstAEAACgKgtNAAAAqrLQBAAAoCoLTQAAAKqy0AQAAKAq25v0wbHHHlvMjjjiiGLW7fYmTz/9dNvj9913X1e3BwzfF7/4xWJWexuTUtcjOr8V+xlnnFHMfvnLX45qJhikp556qpjdc889fZykO+ecc04x23XXXYvZ7bffXswee+yxUc0Eg7RgwYK2x+fPn188Z/LkydXneOihh4rZF77whWLWaXuTTlu0HHTQQcXs61//ejFrGo9oAgAAUJWFJgAAAFVZaAIAAFCVhSYAAABVWWgCAABQlYUmAAAAVQ25vUlK6aKI2C8iHs0579w6tkVEXBYR20fEwog4NOe8tHdjNt+4ceOK2Uc/+tE+ThLxwAMPtD1+2WWX9XUOeks3e2vLLbcsZhdccEEx23fffXsxTltvfOMbi9m8efP6Ngf/Sjd7q9OWAE8++WQxmzt3bi/GGbFPfvKTxWzq1KnFrNP8U6ZMGdVMY4VurjvuuOOOYtZpe5O3v/3txazT1l+dLFu2rKvzOtl0002r3+YgDOcRzYsjYs1NYE6IiGtzzhMj4trW50B/XRy6CU10cegmNNHFoZvQN0MuNHPON0XEE2scnhoRl7Q+viQi3lV5LmAIugnNpJvQTLoJ/dXtazS3yjkvioho/f7ieiMBo6Cb0Ey6Cc2km9AjQ75Gc7RSSkdFxFG9vg4wMroJzaSb0Ey6CSPT7SOai1NK20REtH5/tPSFOefpOedJOedJXV4LGD7dhGbSTWgm3YQe6XahOSciprU+nhYRs+uMA4ySbkIz6SY0k25Cjwxne5NLI2KviNgypfRwRPxHRJweEf+VUvpQRDwYEYf0csi1wWGHHVbMJk6c2MdJIr70pS/19XoMhm6O3gYbbFDMvvKVrxSzAw44oKvrPfLII22Pn3zyycVzfvjDHxazRx8t/sM7A6SbvZVzHvQIQ3rZy15WzD7xiU8Us07f2w033FDMli9fPqy5xjrdXHfceuutxezoo48uZg8++GD1WTpth9atxx9/vPptDsKQC82c8+GFyKZNMEC6Cc2km9BMugn91e1TZwEAAKAtC00AAACqstAEAACgKgtNAAAAqrLQBAAAoKoh33WW/zV58uRidvbZZ3d1m+utV17rr1y5spjdcsstxex73/veiOd43eteV8yuueaaYvZv//ZvI77WUDrdJ7/61a+K2Ve/+tViNmvWrFHNxLqp08/2+PHju7rNmTNnFrPTTz+97fH777+/q2sBzfTlL3+5mO2www7FbO7cucWs059XO+20UzFbsGBBMYO11cEHH9zVeeuv393SZ8MNNyxmJ5xwQle3+cwzzxSz2bPXje1cPaIJAABAVRaaAAAAVGWhCQAAQFUWmgAAAFRloQkAAEBVFpoAAABUZXuTSnLOXZ3XaQuTTrc5b968YvbCF76w7fHzzz+/eM473/nOYrbpppsWs26/70463Se77LJLMTv66KOLme1Nxq5OP9t77LFHMeu0zc6MGTOK2THHHFPMVqxYUcyA0Rs3blwx6/RnwZVXXjnia02bNq2YHXTQQcWs09+bnbYp+drXvlbMDjzwwGIG66Lp06cXs6lTpxazKVOmFLOTTjqpmO2///7F7A1veEMx+/vf/17M3vKWtxSzRx55pJitTTyiCQAAQFUWmgAAAFRloQkAAEBVFpoAAABUZaEJAABAVd51dgS23377QY/wT7Nnzy5mZ599dtvjhx9+ePGclFIx68U7y/bCJptsUsxK70S4ZMmSXo1DQ2yzzTbFrNM7y3Zyxx13FDPvLAu9dfvttxezTu8se+aZZxazu+++u+3xjTbaqHjOaaedVsy61envpC9/+cvF7Le//W31WaAJSjspLFu2rKvbmzBhQjE79dRTu7rNTu8Q+7nPfa6Y3XrrrV1db23iEU0AAACqstAEAACgKgtNAAAAqrLQBAAAoCoLTQAAAKqy0AQAAKCqNNTWFSmliyJiv4h4NOe8c+vYyRHx4Yh4rPVlJ+acrxryYik1fp+MyZMnF7M5c+YUsy222KKr63W7rcivf/3rYvaa17ymb3P0QrezPP3008Xs4IMPbnv86quvHv5gFeScy9/cCI21bnZr5513LmYXXnhhMdt9992rz3Lttde2PV7aWiEi4qyzzipmCxcuHO1ItOjm2mPSpEnF7Prrry9mpW0SeqHT31Wd+j516tRiNlb7rpvNssEGGxSzl7zkJcXss5/9bDF7/etfX8xe8IIXtD2+0047Fc/pZOXKlcWs09ZJ3//+94vZzJkzi9nixYuHN9haaDjdHM4jmhdHxN5tjv/fnPNrW7+GLCRQ3cWhm9BEF4duQhNdHLoJfTPkQjPnfFNEPNGHWYAR0E1oJt2EZtJN6K/RvEbzmJTSnSmli1JKm1ebCBgt3YRm0k1oJt2EHuh2oXleRLw0Il4bEYsi4ozSF6aUjkop3Z5SKj/xGahFN6GZdBOaSTehR7paaOacF+ec/5FzXhkRF0RE8V0zcs7Tc86Tcs7lV+8DVegmNJNuQjPpJvROVwvNlNI2q316YETcVWccYDR0E5pJN6GZdBN6Zzjbm1waEXtFxJYRsTgi/qP1+WsjIkfEwoj4SM550ZAXWwveCvqQQw4pZpdeemn16zVlW5GmzBHR/Sw///nPi9mb3/zmUc1US+W3aR9T3eyFffbZp5i9973v7Sqr7fe//30x6/Qz/+lPf7qYPfbYY8VsrNLNdcNuu+1WzE466aRi1mlbkZJOPfrEJz5RzL73ve+N+FpjmW72Rqdt+T7+8Y8Xs/3337+YddqmpLaHHnqomE2YMKGYfeMb3yhmxx577KhmGmuG0831h3Ejh7c5PKOriYBqdBOaSTehmXQT+ms07zoLAAAAz2GhCQAAQFUWmgAAAFRloQkAAEBVFpoAAABUNeS7zo41nbbW6JR1a731ymv9lStXVr9e0+eI6H6Wm266qRfjsA67+uqri9mNN95YzL7yla8UsyOPPLKYveMd72h7fKeddiqes8MOOxSzHXfcsZgtWLCgmJ166qnFDNZmc+fOLWaXXHJJMSttb7JoUXmXi1NOOaWY2cKEJpgyZUoxO+2004rZpEmTurrevffeW8w6bRF43nnnjfha55xzTjF7z3veU8zuvPPOEV+L7nlEEwAAgKosNAEAAKjKQhMAAICqLDQBAACoykITAACAqiw0AQAAqMr2Jmt48MEHi9njjz9ezMaNG9fV9Tpt15Fz7uo21+Y5IjrPsvvuuxez+fPn92IcxqinnnqqmN11113F7Ljjjitmz3/+89seP+CAA4rnzJo1q5j1YsslWJvtueeexeyiiy4a8e0dccQRxez6668f8e1BbePHjy9ml19+eTHbZJNNitnSpUuLWadtUc4888xiVnurvFe84hXF7Gc/+1kxmzlzZtU56MwjmgAAAFRloQkAAEBVFpoAAABUZaEJAABAVRaaAAAAVGWhCQAAQFW2N1nDrbfeWsw++MEPFrNOb5ve7dYn67KFCxcWs8suu6yYddrCZMWKFaMZCXruec97XtvjnbY36aTT1kPz5s3r6jZhbXbKKacUs80226yY/eEPf2h7/L777hv1TNBLe++9dzHrtIVJp+153vWudxWzZcuWDW+wAdpjjz2K2aabblrMlixZ0otxxjSPaAIAAFCVhSYAAABVWWgCAABQlYUmAAAAVVloAgAAUJWFJgAAAFUNub1JSmlCRMyMiK0jYmVETM85fz2ltEVEXBYR20fEwog4NOe8tHejDt6VV15ZzKZOnVrMPvaxjxWzvfbaq5htvfXWxay0TUK3Or1d9dKl3f1nnTlzZjH7zne+U8x+85vfdHW9sUY3R+/lL395Mbv//vu7us311y//sXrBBRe0PX7YYYd1da0//vGPxezmm2/u6jYZPd3srU5/b3bKOm2Bde6557Y9vmjRouGOxVpgXezmVVddVcyWL19ezBYsWFDMmrSFySc/+cm2x1/96lcXzznttNOKWbf/T0t3hvOI5t8j4jM551dGxOSIODql9KqIOCEirs05T4yIa1ufA/2jm9BMugnNpJvQR0MuNHPOi3LOc1sfL4uIeyNifERMjYhLWl92SUSUd3cFqtNNaCbdhGbSTeivIZ86u7qU0vYRsWtE/CIitso5L4pYVdyU0osL5xwVEUeNbkygE92EZtJNaCbdhN4b9kIzpbRxRHw/Io7LOf8lpTSs83LO0yNieus2cjdDAmW6Cc2km9BMugn9Max3nU0pbRCrCvmfOefLW4cXp5S2aeXbRMSjvRkRKNFNaCbdhGbSTeifIReaadU/88yIiHtzzmeuFs2JiGmtj6dFxOz64wElugnNpJvQTLoJ/ZVy7vzIf0rpTRHxPxExP1a9FXRExImx6jnt/xURL4mIByPikJzzE0PclqcZjMCRRx5ZzF71qlcVs9JbQc+eXf5z8+yzzy5mN954YzFjZHLOw3t+zjDo5v/6zGc+U8yOP/74YnbUUeWX2vz4xz8uZhtssEExu+2224rZTjvtVMy68eIXt30ZUURELFmypOq11nW62Sybb755MfvBD35QzN70pjcVs5/+9KfF7B3veMfwBqPvdLN7nX7md99992J28MEHF7Of/OQno5qpnU7bgpX+Lut0zh577FHM5s2bN/zB6Gg43RzyNZo555sjonRDU0Y6FFCHbkIz6SY0k25Cfw3rNZoAAAAwXBaaAAAAVGWhCQAAQFUWmgAAAFRloQkAAEBVQ25vUvVia8FbQUMv1Xyb9prWhm6+6EUvKmadthSZMGFCV9e7++67i9mrX/3qrm6z5Lrrritms2bNKmYzZsyoOsdYppvN0mkLk/3226+Yrdomsb277rprxNlxxx1XPOexxx4rZtSjm93rtIXXeeedV8yefvrpYnbGGWcUs05/X22//fbF7Fvf+lYxGz9+fNvju+22W/EcW5j0x3C66RFNAAAAqrLQBAAAoCoLTQAAAKqy0AQAAKAqC00AAACqstAEAACgKtubQB95m/bu7bjjjsXsgQce6OMknf3jH/8oZjNnzmx7/Pjjjy+es3Tp0lHPxNB0s/+23XbbYnbLLbcUs+22266Yddre5IknnihmhxxySNvjN9xwQ/Ec+kM3e+Oss84qZh//+MeL2frrr1/Mli9fXsw23njjYvbkk08Ws89//vNtj5977rnFc1asWFHMqMf2JgAAAPSdhSYAAABVWWgCAABQlYUmAAAAVVloAgAAUFX5raMAGuTPf/5zMbviiiuK2YEHHljMnnrqqWJ24YUXDm+wNZx//vnF7L777uvqNmFdtGTJkmK2bNmyrm7zqquuKmbTpk0rZp3ekRbWRccdd1wxmz9/fjF7//vfX8ze8pa3FLNZs2YVs1NPPbWY3XPPPcWM5vOIJgAAAFVZaAIAAFCVhSYAAABVWWgCAABQlYUmAAAAVVloAgAAUFXKOXf+gpQmRMTMiNg6IlZGxPSc89dTSidHxIcj4rHWl56Ycy6/r/iq2+p8MVjH5ZxTrdvSTahHN6GZdBOaaTjdHM5Cc5uI2CbnPDeltElE3BER74qIQyPiyZzz14Y7kFIy1lX+C1M3oRLdhGbSTWim4XRz/WHcyKKIWNT6eFlK6d6IGD/68YDR0E1oJt2EZtJN6K8RvUYzpbR9ROwaEb9oHTompXRnSumilNLmlWcDhkk3oZl0E5pJN6H3hr3QTCltHBHfj4jjcs5/iYjzIuKlEfHaWPWvQ2cUzjsqpXR7Sun2CvMCa9BNaCbdhGbSTeiPIV+jGRGRUtogIv47In6ccz6zTb59RPx3znnnIW7H89kZ02q+1iRCN6EW3YRm0k1opuF0c8hHNFNKKSJmRMS9qxey9YLqZx0YEXd1MyTQHd2EZtJNaCbdhP4azrvOviki/ici5seqt4KOiDgxIg6PVU8xyBGxMCI+0nqRdafb8q8/jGmV3z1PN6ES3YRm0k1opirbm9SklIx1tZ8CVItuMtbpJjSTbkIzVXnqLAAAAIyEhSYAAABVWWgCAABQlYUmAAAAVVloAgAAUJWFJgAAAFVZaAIAAFCVhSYAAABVWWgCAABQlYUmAAAAVVloAgAAUJWFJgAAAFWt3+frPR4Rf2h9vGXr8yZoyizmeK6mzFJjjv9TY5Ae0c3OzPFcTZlFNwejKbOY47maMotu9l9T5ohozixNmSOiObP0rZsp5zzK63QnpXR7znnSQC6+hqbMYo7nasosTZmjH5r0vTZlFnM8V1Nmacoc/dCk77Ups5jjuZoyS1Pm6IemfK9NmSOiObM0ZY6I5szSzzk8dRYAAICqLDQBAACoapALzekDvPaamjKLOZ6rKbM0ZY5+aNL32pRZzPFcTZmlKXP0Q5O+16bMYo7nasosTZmjH5ryvTZljojmzNKUOSKaM0vf5hjYazQBAABYN3nqLAAAAFUNZKGZUto7pXR/Suk3KaUTBjFDa46FKaX5KaV5KaXb+3zti1JKj6aU7lrt2BYppWtSSg+0ft98QHOcnFL6Y+t+mZdS2rcPc0xIKV2fUro3pXR3SunY1vFB3CelWfp+v/Sbbupmmzka0c2x3MsI3WxdWzf/dQ7dbADd1M02c+jmszP0+6mzKaXnRcSCiHh7RDwcEbdFxOE553v6OsiqWRZGxKScc9/3tEkp7RkRT0bEzJzzzq1jX42IJ3LOp7f+sNo85/zZAcxxckQ8mXP+Wi+vvcYc20TENjnnuSmlTSLijoh4V0R8IPp/n5RmOTT6fL/0k27+89q6+a9zNKKbY7WXEbq52rV181/n0M0B081/Xls3/3UO3WwZxCOau0fEb3LOv8s5r4iIWRExdQBzDFTO+aaIeGKNw1Mj4pLWx5fEqh+GQczRdznnRTnnua2Pl0XEvRExPgZzn5RmWdfpZuhmmzka0c0x3MsI3YwI3Wwzh24Onm6GbraZQzdbBrHQHB8RD632+cMxuD+QckT8JKV0R0rpqAHNsLqtcs6LIlb9cETEiwc4yzEppTtbT0Po+dMdVpdS2j4ido2IX8SA75M1ZokY4P3SB7pZppvRnG6OsV5G6GYnuhm6OUC6WaaboZuDWGimNscG9da3e+Scd4uIfSLi6NZD7kScFxEvjYjXRsSiiDijXxdOKW0cEd+PiONyzn/p13WHOcvA7pc+0c3mG/PdHIO9jNDNtYFu6uazdLNZdHOA3RzEQvPhiJiw2ufbRcQjA5gjcs6PtH5/NCKuiFVPgRikxa3nUz/7vOpHBzFEznlxzvkfOeeVEXFB9Ol+SSltEKuK8J8558tbhwdyn7SbZVD3Sx/pZpluNqCbY7SXEbrZiW7q5iDpZplu6uZAFpq3RcTElNIOKaUNI+KwiJjT7yFSShu1XhgbKaWNIuLfI+Kuzmf13JyImNb6eFpEzB7EEM+WoOXA6MP9klJKETEjIu7NOZ+5WtT3+6Q0yyDulz7TzTLdHHA3x3AvI3SzE93UzUHSzTLd1M2InHPff0XEvrHqXbp+GxEnDWiGHSPi161fd/d7joi4NFY9XP1MrPoXsQ9FxLiIuDYiHmj9vsWA5vhORMyPiDtjVSm26cMcb4pVTze5MyLmtX7tO6D7pDRL3++Xfv/STd1sM0cjujmWe9n6/nVTN9ecQzcb8Es3dbPNHLrZ+tX37U0AAABYtw3iqbMAAACswyw0AQAAqMpCEwAAgKosNAEAAKjKQhMAAICqLDQBAACoykITAACAqiw0AQAAqOr/AwKq84Pp1I/VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata\n",
    "plot_mnist_testdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Predictions - Batch \n",
    "\n",
    "- cp [example](https://cloud.google.com/ml-engine/docs/tensorflow/batch-predict)\n",
    "- `data_format`= `'text'` for JSON-Format\n",
    "- `output-path`: GS folder where results will be saved \n",
    "- `input-paths`: File-Location (can be folder with several files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gs://ml-productive-pipeline-53122/pkg_mnist_fnn', 'trained')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "JOBNAME_BATCH_PRED = 'BATCH_' + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "%env JOBNAME_BATCH_PRED {JOBNAME_BATCH_PRED}\n",
    "%env DATA_FORMAT text\n",
    "%env OUTPUT_PATH {'/'.join([os.path.split(OUTDIR)[0], \"batch_pred/\"])}\n",
    "%env TEST_DATA_GS {'/'.join([os.path.split(DATA)[0], os.path.split(TEST_DATA_JSON)[1]])}_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Copy files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!gsutil cp data/mnist/json/ml_engine_testdatafile_N4.json %TEST_DATA_GS%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Submit job using `gcloud` functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine jobs submit prediction %JOBNAME_BATCH_PRED%  --model=MNIST_MLENGINE --version=v1 --input-paths=%TEST_DATA_GS% --output-path %OUTPUT_PATH%  --region %REGION% --data-format %DATA_FORMAT%\n",
      "jobId: BATCH_190416_113516\r\n",
      "state: QUEUED\r\n",
      "\r\n",
      "(mnist) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [BATCH_190416_113516] submitted successfully.\r\n",
      "Your job is still active. You may view the status of your job with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs describe BATCH_190416_113516\r\n",
      "\r\n",
      "or continue streaming the logs with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs stream-logs BATCH_190416_113516\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud ml-engine jobs submit prediction %JOBNAME_BATCH_PRED%  --model=MNIST_MLENGINE --version=v1 --input-paths=%TEST_DATA_GS% --output-path %OUTPUT_PATH%  --region %REGION% --data-format %DATA_FORMAT%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!gcloud ml-engine jobs submit prediction $JOBNAME_BATCH_PRED  --model=MNIST_MLENGINE --version=v1 --input-paths=$TEST_DATA_GS --output-path $OUTPUT_PATH  --region $REGION --data-format $DATA_FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Retrieve results from batch and parse them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/prediction.errors_stats-00000-of-00001', 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/prediction.results-00000-of-00001', 'WARNING: Proxy configuration is present in both the https_proxy', 'environment variable and boto configuration, but configuration', 'differs. boto configuration proxy values will be used. Differences', 'detected:', 'Boto proxy user: \"CHDOLENINET\\\\C219746\" differs from https_proxy proxy user: \"C219746\"']\n"
     ]
    }
   ],
   "source": [
    "files = !gsutil ls %OUTPUT_PATH%\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\google\\auth\\_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get file pkg_mnist_fnn/batch_pred/prediction.results-00000-of-00001\n",
      "{'probabilities': [2.7130536564103716e-21, 2.4199511727829304e-08, 1.172614929600968e-06, 2.4019286115617433e-07, 1.0297572663282503e-13, 2.515796104155931e-14, 1.4267008546064546e-18, 0.9999966621398926, 2.4319928666402535e-14, 1.8645566797204083e-06], 'class_ids': [7], 'classes': ['7'], 'logits': [-18.08372688293457, 11.735553741455078, 15.616212844848633, 14.03066349029541, -0.6317962408065796, -2.04111385345459, -11.818678855895996, 29.272483825683594, -2.0749940872192383, 16.079999923706055]}\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import json\n",
    "mybucket= storage.Client(project=PROJECT).get_bucket('{}'.format(BUCKET))\n",
    "file = files[1].split(\"{}\".format(BUCKET + \"/\"))[1]\n",
    "print(\"Get file {}\".format(file))\n",
    "blob= mybucket.blob(file)\n",
    "result = blob.download_as_string()\n",
    "\n",
    "result = [json.loads(x) for x in (result.decode().split(\"\\n\"))[:-1]]\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get predictions using the [Python-Client-Library, see Tutorial](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library). \n",
    "\n",
    "- [API-Reference](https://cloud.google.com/ml-engine/reference/rest/)\n",
    "\n",
    "-  service account authentification:  [link](https://cloud.google.com/iam/docs/creating-managing-service-accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MNIST_MLENGINE' \n",
    "VERSION = 'v1'\n",
    "print(PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Load data** into python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "instances = []\n",
    "with open(TEST_DATA_JSON, \"r\") as f:\n",
    "    data = f.readlines()\n",
    "instances = [json.loads(x) for x in data]   # for discovery-client\n",
    "data = [image['x'] for  image in instances] # for requests-package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Using `requests`-package behind a proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.Gl3tBk02KCdsQ8i-kHIvIZp4qqHBxGDtpw0y7fSHzshTV58HQgTJziCFrinf3rAGMryyFjIULtXn9AJy8JsL5JasUM8ZtD5z05F2rizhGc1iRCMg4SN7JNJGSh67Yfw'}\n",
      "{'predictions': [{'class_ids': [6],\n",
      "                  'classes': ['6'],\n",
      "                  'logits': [14.841353416442871,\n",
      "                             11.691999435424805,\n",
      "                             17.271425247192383,\n",
      "                             12.454808235168457,\n",
      "                             27.320730209350586,\n",
      "                             33.3737678527832,\n",
      "                             46.4919319152832,\n",
      "                             11.619453430175781,\n",
      "                             2.0705859661102295,\n",
      "                             -0.08118200302124023],\n",
      "                  'probabilities': [1.796089488346076e-14,\n",
      "                                    7.701577192691577e-16,\n",
      "                                    2.0403012504326135e-13,\n",
      "                                    1.6514434083610011e-15,\n",
      "                                    4.721195434598258e-09,\n",
      "                                    2.0084121388208587e-06,\n",
      "                                    0.9999979734420776,\n",
      "                                    7.162657244561357e-16,\n",
      "                                    5.1056873511003206e-20,\n",
      "                                    5.9368125811994605e-21]},\n",
      "                 {'class_ids': [5],\n",
      "                  'classes': ['5'],\n",
      "                  'logits': [19.24078369140625,\n",
      "                             -3.418696641921997,\n",
      "                             -12.680668830871582,\n",
      "                             32.72875213623047,\n",
      "                             7.14021110534668,\n",
      "                             54.7695426940918,\n",
      "                             17.188615798950195,\n",
      "                             10.948305130004883,\n",
      "                             32.959842681884766,\n",
      "                             27.2398738861084],\n",
      "                  'probabilities': [3.715831630953149e-16,\n",
      "                                    5.360044843016428e-26,\n",
      "                                    5.090327634879915e-30,\n",
      "                                    2.677973676146195e-10,\n",
      "                                    2.0646349329450793e-21,\n",
      "                                    1.0,\n",
      "                                    4.77322223280785e-17,\n",
      "                                    9.304202493239468e-20,\n",
      "                                    3.3741753835414556e-10,\n",
      "                                    1.106666407818535e-12]},\n",
      "                 {'class_ids': [4],\n",
      "                  'classes': ['4'],\n",
      "                  'logits': [-1.6974650621414185,\n",
      "                             1.659282922744751,\n",
      "                             5.615025997161865,\n",
      "                             -9.103403091430664,\n",
      "                             13.932087898254395,\n",
      "                             -8.618605613708496,\n",
      "                             2.085800886154175,\n",
      "                             5.352936267852783,\n",
      "                             -0.08024734258651733,\n",
      "                             5.92873477935791],\n",
      "                  'probabilities': [1.628669821229778e-07,\n",
      "                                    4.6735835894651245e-06,\n",
      "                                    0.00024412221682723612,\n",
      "                                    9.896338609705069e-11,\n",
      "                                    0.9992210865020752,\n",
      "                                    1.6070146602320534e-10,\n",
      "                                    7.15953137842007e-06,\n",
      "                                    0.0001878380571724847,\n",
      "                                    8.206951633837889e-07,\n",
      "                                    0.0003340792318340391]},\n",
      "                 {'class_ids': [8],\n",
      "                  'classes': ['8'],\n",
      "                  'logits': [0.4420117139816284,\n",
      "                             2.301677703857422,\n",
      "                             1.9346401691436768,\n",
      "                             3.994138717651367,\n",
      "                             1.1992884874343872,\n",
      "                             4.05784273147583,\n",
      "                             0.39578577876091003,\n",
      "                             0.9556518197059631,\n",
      "                             9.092337608337402,\n",
      "                             2.8936572074890137],\n",
      "                  'probabilities': [0.0001720485306577757,\n",
      "                                    0.0011048251762986183,\n",
      "                                    0.0007654046639800072,\n",
      "                                    0.006002332549542189,\n",
      "                                    0.00036688667023554444,\n",
      "                                    0.006397147662937641,\n",
      "                                    0.00016427633818238974,\n",
      "                                    0.0002875557984225452,\n",
      "                                    0.982742428779602,\n",
      "                                    0.0019970412831753492]}]}\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "from pprint import pprint\n",
    "url = 'https://ml.googleapis.com/v1/projects/{project}/models/{model}/versions/{version}:predict'.format(project=PROJECT,\n",
    "                                                                                                         model=MODEL_NAME,\n",
    "                                                                                                         version=VERSION)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace('\\r\\n', ''))\n",
    "}\n",
    "request_data = {\"instances\":\n",
    "    data\n",
    "}\n",
    "print(headers)\n",
    "json_response = requests.post(url=url, data=json.dumps(request_data), headers=headers)\n",
    "pprint(json.loads(json_response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `googleapiclient.discovery` \n",
    "- fails behind proxy due to SSL verification (which could not be deactivated)\n",
    "#### Authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "#import json\n",
    "#import google.auth\n",
    "#cred, project = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "api = discovery.build(serviceName='ml', version='v1',\n",
    "                      #http= httplib2.Http(disable_ssl_certificate_validation=True),\n",
    "                      discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest',\n",
    "                      #credentials=cred,  # SDK credentials\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```cmd\n",
    "UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. **If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error**. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
    "warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Get predictions for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "project_id = 'projects/{project}/models/{model}/versions/{version}'.format(project=PROJECT, model=MODEL_NAME, version=VERSION)\n",
    "print(\"Endpoint to use: {}\\n\".format(project_id))\n",
    "request_data = {\"instances\":\n",
    "    instances\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "pprint(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, pred in enumerate(request['predictions']):\n",
    "    print(\"Predicted class: {}, True Class:\\t{}\".format(\n",
    "        pred['classes'][0], \n",
    "        y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pdoc discovery.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```\n",
    "Signature: discovery.build(serviceName, version, http=None, discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', developerKey=None, model=None, requestBuilder=<class 'googleapiclient.http.HttpRequest'>, credentials=None, cache_discovery=True, cache=None)\n",
    "Docstring:\n",
    "Construct a Resource for interacting with an API.\n",
    "\n",
    "Construct a Resource object for interacting with an API. The serviceName and\n",
    "version are the names from the Discovery service.\n",
    "\n",
    "Args:\n",
    "serviceName: string, name of the service.\n",
    "version: string, the version of the service.\n",
    "http: httplib2.Http, An instance of httplib2.Http or something that acts\n",
    "like it that HTTP requests will be made through.\n",
    "discoveryServiceUrl: string, a URI Template that points to the location of\n",
    "the discovery service. It should have two parameters {api} and\n",
    "{apiVersion} that when filled in produce an absolute URI to the discovery\n",
    "document for that service.\n",
    "developerKey: string, key obtained from\n",
    "https://code.google.com/apis/console.\n",
    "model: googleapiclient.Model, converts to and from the wire format.\n",
    "requestBuilder: googleapiclient.http.HttpRequest, encapsulator for an HTTP\n",
    "request.\n",
    "credentials: oauth2client.Credentials or\n",
    "google.auth.credentials.Credentials, credentials to be used for\n",
    "authentication.\n",
    "cache_discovery: Boolean, whether or not to cache the discovery doc.\n",
    "cache: googleapiclient.discovery_cache.base.CacheBase, an optional\n",
    "cache object for the discovery documents.\n",
    "\n",
    "Returns:\n",
    "A Resource object with methods for interacting with the service.\n",
    "File: /usr/local/envs/py3env/lib/python3.5/site-packages/googleapiclient/discovery.py\n",
    "Type: function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gcp_training_options-gcp_services.png](Images/gcp_training_options-gcp_services.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outlook\n",
    "- Add different models types\n",
    "    - different layers of abstraction in tensorflow\n",
    "    - sklearn\n",
    "- Show how to use `ml-engine` in SQL in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notes on **Jupyter Slides**\n",
    "- Activate: View -> Cell Toolbar -> Slideshow\n",
    "- [nbextensions](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html)\n",
    "   - [split cells vertically](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/splitcell/readme.html)\n",
    "   - Code folding\n",
    "   - Table of Contents\n",
    "- [RISE](https://damianavila.github.io/RISE/installation.html) for interactive presentations\n",
    "  - using conda: `conda install -c conda-forge rise`\n",
    "  - activte scrolling in Notebook-Metadata, see [link](https://damianavila.github.io/RISE/customize.html#config-right-scroll) \n",
    "  - adapt width and height of your slides to your machine and needs. [link](https://damianavila.github.io/RISE/customize.html#change-the-width-and-height-of-slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (mnist)",
   "language": "python",
   "name": "mnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "livereveal": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "598.438px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
