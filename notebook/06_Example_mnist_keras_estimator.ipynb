{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification example with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages on Google  Cloud Datalab (locally use conda env)\n",
    "### Select in the Python3 Kernel:\n",
    "In the menu bar the of 'Kernel', select   \n",
    "**python3**\n",
    "### Install needed packages\n",
    "copy the command below in a Google Cloud Datalab cell  \n",
    "**!pip install tensorflow==1.12**\n",
    "### Restart the Kernel \n",
    "this is to take into account the new installed packages. Click in the menu bar on:  \n",
    "**Reset Session**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gzip\n",
    "import sys\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mnist data, split between train and test sets\n",
    "# on GCP\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# with AXA network\n",
    "def load_data(path):\n",
    "    f = gzip.open(path, 'rb')\n",
    "    if sys.version_info < (3,):\n",
    "        data = cPickle.load(f)\n",
    "    else:\n",
    "        data = cPickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    return data\n",
    "(x_train, y_train), (x_test, y_test) = load_data(path='../data/mnist.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data shape (training)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data shape (train)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype, x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0, 255, 0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train), np.min(x_train), np.max(x_test), np.min(x_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and reorganize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast uint8 -> float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renormalize the data 255 grey variation\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data 28 x 28 -> 784\n",
    "x_train = x_train.reshape(len(x_train), x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(len(x_test), x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train), np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_input=x_train.shape[1]\n",
    "dim_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(x_train[0:5], y_train[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % np.argmax(label), fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "learning_rate = 0.5\n",
    "\n",
    "# number of epoch to train our model\n",
    "EPOCHS = 1\n",
    "\n",
    "# size of our mini batch\n",
    "#BATCH_SIZE = len(x_train)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# shuffle buffer size\n",
    "SHUFFLE_BUFFER_SIZE = 10 * BATCH_SIZE\n",
    "\n",
    "# prefetch buffer size\n",
    "PREFETCH_BUFFER_SIZE = 1 #tf.contrib.data.AUTOTUNE\n",
    "\n",
    "# number of paralell calls\n",
    "NUM_PARALELL_CALL = 4\n",
    "\n",
    "# hidden layer 1\n",
    "n1=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "    \n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel') # just for jupyter notebook and avoir : \"UnrecognizedFlagError: Unknown command line flag 'f'\"\n",
    "tf.app.flags.DEFINE_string('model_dir', '../results/Models/Mnist/ckpt/', 'Dir to save a model and checkpoints')\n",
    "tf.app.flags.DEFINE_string('saved_dir', '../results/Models/Mnist/pb/', 'Dir to save a model for TF serving')\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size', SHUFFLE_BUFFER_SIZE , 'Shuffle buffer size')\n",
    "tf.app.flags.DEFINE_integer('prefetch_buffer_size', PREFETCH_BUFFER_SIZE, 'Prefetch buffer size')\n",
    "tf.app.flags.DEFINE_integer('batch_size', BATCH_SIZE, 'Batch size')\n",
    "tf.app.flags.DEFINE_integer('num_parallel_calls', NUM_PARALELL_CALL, 'Number of paralell calls')\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/tarrade/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/ipykernel_launcher.py:\n",
      "  --batch_size: Batch size\n",
      "    (default: '128')\n",
      "    (an integer)\n",
      "  --f: kernel\n",
      "    (default: '')\n",
      "  --model_dir: Dir to save a model and checkpoints\n",
      "    (default: '../results/Models/Mnist/ckpt/')\n",
      "  --num_parallel_calls: Number of paralell calls\n",
      "    (default: '4')\n",
      "    (an integer)\n",
      "  --prefetch_buffer_size: Prefetch buffer size\n",
      "    (default: '1')\n",
      "    (an integer)\n",
      "  --saved_dir: Dir to save a model for TF serving\n",
      "    (default: '../results/Models/Mnist/pb/')\n",
      "  --shuffle_buffer_size: Shuffle buffer size\n",
      "    (default: '1280')\n",
      "    (an integer)\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n"
     ]
    }
   ],
   "source": [
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.data.Dataset\n",
    "https://www.tensorflow.org/guide/performance/datasets  \n",
    "To summarize, one good order for the different transformations is:\n",
    "- create the dataset\n",
    "- shuffle (with a big enough buffer size)\n",
    "- repeat\n",
    "- map with the actual work (preprocessing, augmentation…) using multiple parallel calls\n",
    "- batch\n",
    "- prefetch\n",
    "\n",
    "ModeKeys:  \n",
    "https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys  \n",
    "- EVAL\n",
    "- PREDICT\n",
    "- TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dataset_fn(x_data, y_data, batch_size=128, mode=tf.estimator.ModeKeys.TRAIN):\n",
    "    \n",
    "    # 1) convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "    \n",
    "    # 2) shuffle (with a big enough buffer size)    :        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None # loop indefinitely\n",
    "        dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size, seed=2)# depends on sample size\n",
    "    else:\n",
    "        num_epochs = 1 # end-of-input after this\n",
    "        \n",
    "    # caching data\n",
    "    #dataset = dataset.cache()\n",
    "    \n",
    "    # 3) automatically refill the data queue when empty\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    \n",
    "    # 4) map\n",
    "    #dataset = dataset.map(map_func=parse_fn, num_parallel_calls=FLAGS.num_parallel_calls)\n",
    "\n",
    "    # 5) create batches of data\n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    \n",
    "    # 6) prefetch data for faster consumption, based on your system and environment, allows the tf.data runtime to automatically tune the prefetch buffer sizes\n",
    "    dataset = dataset.prefetch(FLAGS.prefetch_buffer_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = input_dataset_fn(x_train, \n",
    "                                    y_train, \n",
    "                                    mode=tf.estimator.ModeKeys.TRAIN, \n",
    "                                    batch_size=FLAGS.batch_size)\n",
    "testing_dataset = input_dataset_fn(x_test, \n",
    "                                   y_test,\n",
    "                                   mode=tf.estimator.ModeKeys.EVAL, \n",
    "                                   batch_size=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exploration dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = training_dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_element\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration n: 0 execution time: 18.565196000000014 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 1 execution time: 0.009054999999989377 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 2 execution time: 0.0018800000000283035 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 3 execution time: 0.00483299999996234 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 4 execution time: 0.002751999999986765 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 5 execution time: 0.005135999999993146 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 6 execution time: 0.004634999999893807 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 7 execution time: 0.00405799999998635 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 8 execution time: 0.004253000000062457 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 9 execution time: 0.004346000000055028 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 10 execution time: 0.0038380000000870496 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 11 execution time: 0.003303999999957341 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 12 execution time: 0.00428599999997914 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 13 execution time: 0.004626000000030217 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 14 execution time: 0.003981999999950858 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 15 execution time: 0.004628999999908956 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 16 execution time: 0.004741999999964719 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 17 execution time: 0.004378999999971711 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 18 execution time: 0.004677000000015141 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 19 execution time: 0.003295999999977539 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 20 execution time: 0.005262000000016087 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 21 execution time: 0.003746999999975742 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 22 execution time: 0.003647000000000844 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 23 execution time: 0.0028000000000929504 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 24 execution time: 0.004499000000009801 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 25 execution time: 0.0044429999999238134 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 26 execution time: 0.004908999999997832 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 27 execution time: 0.0041639999999461 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 28 execution time: 0.004230000000006839 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 29 execution time: 0.004524000000060369 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 30 execution time: 0.004213999999933549 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 31 execution time: 0.0031880000000228392 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 32 execution time: 0.004322999999999411 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 33 execution time: 0.003755999999953019 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 34 execution time: 0.004059999999981301 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 35 execution time: 0.004174999999918327 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 36 execution time: 0.003937000000064472 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 37 execution time: 0.003997999999910462 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 38 execution time: 0.00359600000001592 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 39 execution time: 0.004817000000002736 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 40 execution time: 0.0039420000000518485 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 41 execution time: 0.004033999999933258 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 42 execution time: 0.003863999999907719 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 43 execution time: 0.0026709999999638967 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 44 execution time: 0.0039029999999229403 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 45 execution time: 0.0026910000000270884 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 46 execution time: 0.003929999999968459 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 47 execution time: 0.004136000000016793 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 48 execution time: 0.0032979999999724896 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 49 execution time: 0.0027079999999841675 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 50 execution time: 0.004405000000019754 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 51 execution time: 0.0038829999999734355 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 52 execution time: 0.003450000000043474 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 53 execution time: 0.0032479999999850406 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 54 execution time: 0.004004000000009 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 55 execution time: 0.0042089999999461725 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 56 execution time: 0.002626999999961299 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 57 execution time: 0.003099000000020169 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 58 execution time: 0.0040840000000343935 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 59 execution time: 0.0040919999999005086 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 60 execution time: 0.009001000000012027 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 61 execution time: 0.0020090000000436703 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 62 execution time: 0.004503999999997177 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 63 execution time: 0.0036849999999049032 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 64 execution time: 0.00405799999998635 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 65 execution time: 0.0034860000000662694 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 66 execution time: 0.004224000000021988 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 67 execution time: 0.0038710000000037326 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 68 execution time: 0.004167000000052212 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 69 execution time: 0.004301000000054955 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 70 execution time: 0.004279999999994288 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 71 execution time: 0.00428599999997914 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 72 execution time: 0.004299000000060005 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 73 execution time: 0.0032129999999597203 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 74 execution time: 0.004085999999915657 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 75 execution time: 0.004205999999953747 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 76 execution time: 0.002676999999948748 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 77 execution time: 0.003945000000044274 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 78 execution time: 0.004239999999981592 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 79 execution time: 0.002442999999971107 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 80 execution time: 0.004458999999997104 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 81 execution time: 0.00438900000006015 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 82 execution time: 0.004189999999994143 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 83 execution time: 0.004007999999998901 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 84 execution time: 0.0027169999999614447 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 85 execution time: 0.0061329999999770735 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 86 execution time: 0.005642999999963649 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 87 execution time: 0.006691000000046188 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 88 execution time: 0.0040559999999914 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 89 execution time: 0.004312000000027183 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 90 execution time: 0.005905999999981759 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 91 execution time: 0.004811000000017884 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 92 execution time: 0.004566000000068016 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 93 execution time: 0.00391300000001138 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 94 execution time: 0.0036329999999225038 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 95 execution time: 0.0039050000000315777 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 96 execution time: 0.0038829999999734355 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 97 execution time: 0.003842999999960739 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 98 execution time: 0.0038869999999633364 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 99 execution time: 0.004155999999966298 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 100 execution time: 0.004105999999978849 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 101 execution time: 0.0063549999999850115 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 102 execution time: 0.004712000000040462 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 103 execution time: 0.00392900000008467 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 104 execution time: 0.004361999999900945 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 105 execution time: 0.004110999999966225 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 106 execution time: 0.003946999999925538 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 107 execution time: 0.0032799999999042484 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 108 execution time: 0.004273000000011962 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 109 execution time: 0.004060999999978776 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 110 execution time: 0.004365000000007058 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 111 execution time: 0.005125999999904707 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 112 execution time: 0.004234999999994216 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 113 execution time: 0.004189999999994143 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 114 execution time: 0.0034560000000283253 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 115 execution time: 0.004184000000009291 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 116 execution time: 0.004237999999986641 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 117 execution time: 0.0039789999999584325 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 118 execution time: 0.004328999999984262 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 119 execution time: 0.004026999999950931 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 120 execution time: 0.0039789999999584325 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 121 execution time: 0.004051000000004024 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 122 execution time: 0.00389400000005935 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 123 execution time: 0.004050000000006548 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 124 execution time: 0.0040720000000646905 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration n: 125 execution time: 0.004672000000027765 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 126 execution time: 0.0034780000000864675 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 127 execution time: 0.0038829999999734355 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 128 execution time: 0.0035820000000512664 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 129 execution time: 0.0038430000000744258 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 130 execution time: 0.003999000000021624 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 131 execution time: 0.0038700000000062573 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 132 execution time: 0.004262000000039734 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 133 execution time: 0.00410999999996875 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 134 execution time: 0.004836000000068452 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 135 execution time: 0.006573999999886837 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 136 execution time: 0.0062709999999697175 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 137 execution time: 0.0039010000000416767 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 138 execution time: 0.0039709999999786305 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 139 execution time: 0.0027959999999893625 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 140 execution time: 0.0023240000000441796 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 141 execution time: 0.0043180000000120344 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 142 execution time: 0.007864999999924294 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 143 execution time: 0.004697999999962121 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 144 execution time: 0.006509000000050946 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 145 execution time: 0.004710000000045511 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 146 execution time: 0.004029000000059568 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 147 execution time: 0.004145999999991545 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 148 execution time: 0.004080999999928281 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 149 execution time: 0.0039539999999078645 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 150 execution time: 0.003918999999996231 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 151 execution time: 0.002751999999986765 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 152 execution time: 0.003918999999996231 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 153 execution time: 0.005094999999982974 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 154 execution time: 0.0027959999999893625 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 155 execution time: 0.003710000000069158 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 156 execution time: 0.0038920000000643995 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 157 execution time: 0.004398999999921216 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 158 execution time: 0.004169000000047163 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 159 execution time: 0.003962999999998829 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 160 execution time: 0.003394999999954962 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 161 execution time: 0.004120000000057189 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 162 execution time: 0.004063999999971202 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 163 execution time: 0.0046820000000025175 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 164 execution time: 0.00398100000006707 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 165 execution time: 0.003467999999998028 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 166 execution time: 0.0028210000000399305 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 167 execution time: 0.003912000000013904 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 168 execution time: 0.003007000000025073 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 169 execution time: 0.0038619999999127685 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 170 execution time: 0.004001000000016575 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 171 execution time: 0.004040999999915584 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 172 execution time: 0.004143999999996595 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 173 execution time: 0.003748000000086904 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 174 execution time: 0.004048999999895386 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 175 execution time: 0.0039040000000341024 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 176 execution time: 0.00405799999998635 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 177 execution time: 0.0044020000000273285 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 178 execution time: 0.004077999999935855 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 179 execution time: 0.0025699999999915235 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 180 execution time: 0.004255000000057407 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 181 execution time: 0.003926999999976033 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 182 execution time: 0.002456000000051972 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 183 execution time: 0.00430899999992107 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 184 execution time: 0.004101999999988948 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 185 execution time: 0.004059999999981301 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 186 execution time: 0.002838999999994485 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 187 execution time: 0.004215000000044711 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 188 execution time: 0.004601999999977124 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 189 execution time: 0.004180999999903179 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 190 execution time: 0.003967999999986205 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 191 execution time: 0.004284999999981665 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 192 execution time: 0.004633000000012544 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 193 execution time: 0.004423999999971784 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 194 execution time: 0.0042560000000548825 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 195 execution time: 0.003994000000034248 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 196 execution time: 0.005328999999960615 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 197 execution time: 0.005242000000066582 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 198 execution time: 0.004699999999957072 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 199 execution time: 0.0042640000000346845 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 200 execution time: 0.004583000000025095 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 201 execution time: 0.0050079999999752545 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 202 execution time: 0.005690999999956148 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 203 execution time: 0.004788000000075954 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 204 execution time: 0.004123999999933403 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 205 execution time: 0.004164999999943575 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 206 execution time: 0.0040709999999535285 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 207 execution time: 0.004085000000031869 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 208 execution time: 0.0028250000000298314 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 209 execution time: 0.004164999999943575 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 210 execution time: 0.004948000000013053 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 211 execution time: 0.004439000000047599 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 212 execution time: 0.004336999999964064 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 213 execution time: 0.0038670000000138316 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 214 execution time: 0.004166000000054737 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 215 execution time: 0.0026410000000396394 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 216 execution time: 0.0039749999999685315 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 217 execution time: 0.006114999999908832 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 218 execution time: 0.004042999999910535 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 219 execution time: 0.0038580000000365544 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 220 execution time: 0.003394999999954962 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 221 execution time: 0.003988999999933185 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 222 execution time: 0.004050000000006548 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 223 execution time: 0.002780999999913547 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 224 execution time: 0.004107999999973799 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 225 execution time: 0.0023770000000240543 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 226 execution time: 0.004510000000095715 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 227 execution time: 0.003994000000034248 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 228 execution time: 0.004042999999910535 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 229 execution time: 0.004027999999948406 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 230 execution time: 0.004175000000032014 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 231 execution time: 0.004200000000082582 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 232 execution time: 0.004279999999994288 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 233 execution time: 0.003187000000025364 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 234 execution time: 0.004092000000014195 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 235 execution time: 0.00421100000005481 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 236 execution time: 0.0030050000000301225 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 237 execution time: 0.0039709999999786305 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 238 execution time: 0.003908000000024003 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 239 execution time: 0.00317100000006576 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 240 execution time: 0.004336999999964064 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 241 execution time: 0.0038329999999859865 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 242 execution time: 0.004041000000029271 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 243 execution time: 0.0030249999999796273 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 244 execution time: 0.0046360000000049695 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 245 execution time: 0.003977000000077169 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 246 execution time: 0.003086000000052991 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 247 execution time: 0.0038510000000542277 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 248 execution time: 0.003959999999892716 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 249 execution time: 0.002818999999931293 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 250 execution time: 0.003943999999933112 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 251 execution time: 0.0024500000000671207 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration n: 252 execution time: 0.004599999999982174 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 253 execution time: 0.004543000000012398 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 254 execution time: 0.003969999999981155 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 255 execution time: 0.004096000000004096 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 256 execution time: 0.004114999999956126 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 257 execution time: 0.003939999999943211 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 258 execution time: 0.005499999999983629 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 259 execution time: 0.0055690000000367945 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 260 execution time: 0.006074000000012347 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 261 execution time: 0.004400000000032378 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 262 execution time: 0.005085000000008222 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 263 execution time: 0.0041680000000496875 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 264 execution time: 0.00513100000000577 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 265 execution time: 0.005244999999945321 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 266 execution time: 0.004492000000027474 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 267 execution time: 0.0028119999999489664 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 268 execution time: 0.003851999999938016 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 269 execution time: 0.0038819999999759602 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 270 execution time: 0.004047000000014123 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 271 execution time: 0.0038779999999860593 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 272 execution time: 0.0025729999999839492 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 273 execution time: 0.004149000000097658 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 274 execution time: 0.0051590000000487635 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 275 execution time: 0.003898000000049251 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 276 execution time: 0.004045000000019172 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 277 execution time: 0.004131000000029417 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 278 execution time: 0.004005000000006476 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 279 execution time: 0.004072999999948479 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 280 execution time: 0.003241000000002714 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 281 execution time: 0.004026999999950931 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 282 execution time: 0.004365000000007058 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 283 execution time: 0.0060619999999289575 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 284 execution time: 0.006212000000004991 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 285 execution time: 0.005117999999924905 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 286 execution time: 0.004400999999916166 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 287 execution time: 0.003907000000026528 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 288 execution time: 0.004085999999915657 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 289 execution time: 0.003916000000003805 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 290 execution time: 0.003959000000008928 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 291 execution time: 0.003284000000007836 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 292 execution time: 0.00421799999992345 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 293 execution time: 0.003165999999964697 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 294 execution time: 0.004047000000014123 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 295 execution time: 0.002743000000009488 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 296 execution time: 0.0024159999999255888 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 297 execution time: 0.003083000000060565 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 298 execution time: 0.003939000000059423 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 299 execution time: 0.003805999999940468 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 300 execution time: 0.003899000000046726 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 301 execution time: 0.003957000000013977 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 302 execution time: 0.00423399999999674 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 303 execution time: 0.004099999999993997 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 304 execution time: 0.003994000000034248 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 305 execution time: 0.003190999999901578 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 306 execution time: 0.004666000000042914 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 307 execution time: 0.0038359999999784122 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 308 execution time: 0.0025239999999939755 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 309 execution time: 0.0041300000000319415 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 310 execution time: 0.004008999999996377 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 311 execution time: 0.003997000000026674 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 312 execution time: 0.0030669999999872744 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 313 execution time: 0.0039709999999786305 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 314 execution time: 0.004407000000014705 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 315 execution time: 0.0046820000000025175 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 316 execution time: 0.004297000000065054 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 317 execution time: 0.004343999999946391 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 318 execution time: 0.004202999999961321 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 319 execution time: 0.00439399999993384 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 320 execution time: 0.0020520000000487926 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 321 execution time: 0.0039999999999054126 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 322 execution time: 0.006580999999982851 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 323 execution time: 0.00597800000002735 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 324 execution time: 0.004454000000009728 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 325 execution time: 0.0029339999999820066 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 326 execution time: 0.0031099999999923966 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 327 execution time: 0.004773000000000138 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 328 execution time: 0.005536000000006425 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 329 execution time: 0.0033929999999600113 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 330 execution time: 0.002751999999986765 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 331 execution time: 0.003998999999907937 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 332 execution time: 0.004066000000079839 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 333 execution time: 0.0027250000000549335 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 334 execution time: 0.0040559999999914 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 335 execution time: 0.003306999999949767 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 336 execution time: 0.003982999999948333 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 337 execution time: 0.0026249999999663487 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 338 execution time: 0.004069000000072265 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 339 execution time: 0.0024859999999762294 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 340 execution time: 0.003953000000024076 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 341 execution time: 0.003942999999935637 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 342 execution time: 0.0029540000000451982 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 343 execution time: 0.004112000000077387 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 344 execution time: 0.002895000000080472 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 345 execution time: 0.0051419999999779975 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 346 execution time: 0.004032999999935782 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 347 execution time: 0.003998000000024149 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 348 execution time: 0.004207000000064909 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 349 execution time: 0.003946999999925538 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 350 execution time: 0.003531000000066342 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 351 execution time: 0.004100999999991473 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 352 execution time: 0.002372000000036678 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 353 execution time: 0.003957000000013977 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 354 execution time: 0.003961000000003878 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 355 execution time: 0.003945000000044274 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 356 execution time: 0.0041760000000294895 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 357 execution time: 0.004080999999928281 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 358 execution time: 0.0051289999998971325 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 359 execution time: 0.0042199999999184 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 360 execution time: 0.0039340000000720465 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 361 execution time: 0.003012000000012449 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 362 execution time: 0.004154000000085034 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 363 execution time: 0.0025910000000521904 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 364 execution time: 0.004097999999999047 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 365 execution time: 0.003922999999986132 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 366 execution time: 0.003946999999925538 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 367 execution time: 0.004979000000048472 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 368 execution time: 0.004103999999983898 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 369 execution time: 0.0030890000000454165 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 370 execution time: 0.0041509999999789216 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 371 execution time: 0.0040559999999914 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 372 execution time: 0.004028000000062093 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 373 execution time: 0.004401000000029853 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 374 execution time: 0.004115000000069813 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 375 execution time: 0.005241000000069107 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 376 execution time: 0.004128999999920779 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 377 execution time: 0.004525999999941632 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 378 execution time: 0.0029260000000022046 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration n: 379 execution time: 0.0044440000000349755 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 380 execution time: 0.004541000000017448 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 381 execution time: 0.004008999999996377 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 382 execution time: 0.004067999999961103 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 383 execution time: 0.004362000000014632 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 384 execution time: 0.004237999999986641 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 385 execution time: 0.004960999999980231 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 386 execution time: 0.006662000000005719 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 387 execution time: 0.004202999999961321 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 388 execution time: 0.004194999999981519 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 389 execution time: 0.0044520000000147775 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 390 execution time: 0.0045320000000401706 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 391 execution time: 0.005438000000026477 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 392 execution time: 0.004886000000055901 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 393 execution time: 0.0037109999999529464 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 394 execution time: 0.004040000000031796 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 395 execution time: 0.003931999999963409 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 396 execution time: 0.004013999999983753 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 397 execution time: 0.003777000000013686 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 398 execution time: 0.004004000000009 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 399 execution time: 0.003982000000064545 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 400 execution time: 0.0031559999999899446 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 401 execution time: 0.0041260000000420405 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 402 execution time: 0.003992999999923086 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 403 execution time: 0.0025320000000874643 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 404 execution time: 0.0039000000000442014 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 405 execution time: 0.003982999999948333 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 406 execution time: 0.0027919999999994616 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 407 execution time: 0.0027999999999792635 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 408 execution time: 0.003930999999965934 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 409 execution time: 0.003991000000041822 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 410 execution time: 0.004053999999996449 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 411 execution time: 0.004097000000001572 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 412 execution time: 0.004000000000019099 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 413 execution time: 0.004060999999978776 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 414 execution time: 0.00403500000004442 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 415 execution time: 0.0030060000000275977 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 416 execution time: 0.004239999999981592 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 417 execution time: 0.004050000000006548 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 418 execution time: 0.0039709999999786305 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 419 execution time: 0.0029129999999213396 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 420 execution time: 0.0038339999999834617 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "iteration n: 421 execution time: 0.004000000000019099 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 422 execution time: 0.0038879999999608117 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 423 execution time: 0.004347000000052503 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 424 execution time: 0.004340000000070177 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 425 execution time: 0.0038069999999379434 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 426 execution time: 0.0042140000000472355 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 427 execution time: 0.0040169999999761785 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 428 execution time: 0.00382600000000366 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 429 execution time: 0.004003000000011525 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 430 execution time: 0.0038499999999430656 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 431 execution time: 0.004417999999986932 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 432 execution time: 0.004123999999933403 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 433 execution time: 0.0038960000000543005 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 434 execution time: 0.003962000000001353 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 435 execution time: 0.0038749999999936335 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 436 execution time: 0.003917999999998756 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 437 execution time: 0.0041180000000622385 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 438 execution time: 0.004175000000032014 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 439 execution time: 0.003951999999912914 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 440 execution time: 0.0028949999999667853 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 441 execution time: 0.004197999999973945 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 442 execution time: 0.004167000000052212 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 443 execution time: 0.004645999999979722 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 444 execution time: 0.004187999999999192 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 445 execution time: 0.004782999999974891 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 446 execution time: 0.005314999999995962 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 447 execution time: 0.0030299999999670035 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 448 execution time: 0.004695999999967171 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 449 execution time: 0.004080999999928281 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 450 execution time: 0.00562400000001162 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 451 execution time: 0.0053810000000567015 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 452 execution time: 0.0041549999999688225 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 453 execution time: 0.004835999999954765 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 454 execution time: 0.004110999999966225 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 455 execution time: 0.004889000000048327 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 456 execution time: 0.004647999999974672 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "iteration n: 457 execution time: 0.00534699999991517 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 458 execution time: 0.002468000000021675 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 459 execution time: 0.0023069999999734137 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 460 execution time: 0.0022299999999404463 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 461 execution time: 0.002823000000034881 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 462 execution time: 0.002555000000029395 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 463 execution time: 0.0012909999999237698 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 464 execution time: 0.002233000000046559 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "iteration n: 465 execution time: 0.0022490000000061627 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 0 \n",
      "\n",
      "iteration n: 466 execution time: 0.002275000000054206 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 467 execution time: 0.0023939999999811334 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 468 execution time: 0.02272800000002917 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 469 execution time: 0.004327999999986787 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 4 \n",
      "\n",
      "number of iteration reached\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "n_iter=470\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time.clock()\n",
    "            x,y = sess.run([features, labels])\n",
    "            print('iteration n:', n, 'execution time:', time.clock() - start_time, 'seconds')\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print('first label of the batch',np.argmax(y[0]),'\\n')\n",
    "            n+=1\n",
    "            if n>=n_iter:\n",
    "                print('number of iteration reached')\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('tf.errors.OutOfRangeError')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = testing_dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_element\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.578711999999996 seconds\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "tf.errors.OutOfRangeError\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time.clock()\n",
    "            x,y = sess.run([features, labels])\n",
    "            print(time.clock() - start_time, 'seconds')\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print('first label of the batch',np.argmax(y[0]),'\\n')\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('tf.errors.OutOfRangeError')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Call back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UDFPrint(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        _, __, x_train, y_train = self.test_data\n",
    "        loss_train, acc_train = self.model.evaluate(x_train, y_train, verbose=0)\n",
    "        print('Reached epoch {0:3d} cost J = {1:.5f}'.format(epoch, loss_train))\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x_test, y_test, x_train, y_train = self.test_data\n",
    "        loss_train, acc_train = self.model.evaluate(x_train, y_train, verbose=0)\n",
    "        loss_test, acc_test = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(' accurary on the training set {0:.4f}'.format(acc_train))\n",
    "        print(' accurary on the testing set {0:.4f}'.format(acc_test))\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        #print('  ---> starting minibatch', batch)\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        #print('  ---> ending minibatch', batch)\n",
    "        return\n",
    "return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    " \n",
    "    # hidden layer\n",
    "    model.add(tf.keras.layers.Dense(dim_input, \n",
    "                    input_dim=dim_input, \n",
    "                    kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                    bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                    activation='relu'))\n",
    "    # last layer\n",
    "    model.add(tf.keras.layers.Dense(num_classes, \n",
    "                    kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                    bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                    activation='softmax'))\n",
    "    \n",
    "    # weight initialisation\n",
    "    # He: keras.initializers.he_normal(seed=None)\n",
    "    # Xavier: keras.initializers.glorot_uniform(seed=None)\n",
    "    # Radom Normal: keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    # Truncated Normal: keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    \n",
    "    # optimiser\n",
    "    optimiser=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9)\n",
    "    # GD/SGC: keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    # Adam: keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    # RMSProp: keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    # Momentum: keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimiser, \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using numpy array  \n",
    "- batch_size \n",
    "  determines the number of samples in each mini batch. Its maximum is the number of all samples, which makes gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but iterations are slower. Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around. batch_size allows to adjust between the two extremes: accurate gradient direction and fast iteration. Also, the maximum value for batch_size may be limited if your model + data set does not fit into the available (GPU) memory.\n",
    "- steps_per_epoch \n",
    "  the number of batch iterations before a training epoch is considered finished. If you have a training set of fixed size you can ignore it but it may be useful if you have a huge data set or if you are generating random data augmentations on the fly, i.e. if your training set has a (generated) infinite size. If you have the time to go through your whole training data set I recommend to skip this parameter.\n",
    "- validation_steps \n",
    "  similar to steps_per_epoch but on the validation data set instead on the training data. If you have the time to go through your whole validation data set I recommend to skip this parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Reached epoch   0 cost J = 2.47134\n",
      "Epoch 1/1\n",
      " accurary on the training set 0.3599\n",
      " accurary on the testing set 0.3614\n",
      " - 22s - loss: 2.4713 - acc: 0.0710 - val_loss: 3.5724 - val_acc: 0.3614\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model.set_weights(initial_weights)\n",
    "\n",
    "# Fit the model\n",
    "hist=model.fit(x_train, \n",
    "               y_train, \n",
    "               validation_data=(x_test, y_test),\n",
    "               callbacks=[UDFPrint((x_test, y_test, x_train, y_train))],\n",
    "               epochs=EPOCHS, \n",
    "               batch_size=BATCH_SIZE,\n",
    "               verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [3.572427272796631], 'val_acc': [0.3614000082015991], 'loss': [2.4713327884674072], 'acc': [0.07098333537578583]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.572427568054199\n",
      "Test accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5285739298502605\n",
      "Train accuracy: 0.3599\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, \n",
    "                       y_train, \n",
    "                       verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 56s - loss: 2.4713 - acc: 0.0710\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model.set_weights(initial_weights)\n",
    "\n",
    "# Fit the model (using data.Dataset)\n",
    "hist=model.fit(training_dataset.make_one_shot_iterator(),\n",
    "               steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
    "               validation_data=testing_dataset.make_one_shot_iterator(),\n",
    "               validation_steps=len(x_test) // BATCH_SIZE,\n",
    "               #callbacks=[UDFPrint((x_test, y_test, x_train, y_train))],\n",
    "               epochs=EPOCHS,\n",
    "               verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [2.4713337421417236], 'acc': [0.07098333537578583]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.5751110137939452\n",
      "Test accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5311397709528607\n",
      "Train accuracy: 0.35986666666666667\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, \n",
    "                       y_train, \n",
    "                       verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ../results/Models/Mnist/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../results/Models/Mnist/ckpt\\eval\\events.out.tfevents.1548149889.C054093 - Access is denied.\n",
      "../results/Models/Mnist/ckpt\\events.out.tfevents.1548149619.C054093 - Access is denied.\n"
     ]
    }
   ],
   "source": [
    "!rmdir /S /Q \"../results/Models/Mnist/ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.train.SessionRunHook):\n",
    "    def begin(self):\n",
    "        self.times = []\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        self.iter_time_start = time.time()\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        self.times.append(time.time() - self.iter_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    }
   ],
   "source": [
    "# the tf.distribute.Strategy API is an easy way to distribute your training across multiple devices/machines\n",
    "NUM_GPUS = 2\n",
    "#strategy=None\n",
    "strategy = tf.contrib.distribute.OneDeviceStrategy('device:CPU:0')\n",
    "#strategy = tf.contrib.distribute.OneDeviceStrategy('device:GPU:0')\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=NUM_GPUS)\n",
    "\n",
    "# config tf.estimator to use a give strategy\n",
    "training_config = tf.estimator.RunConfig(train_distribute=strategy,\n",
    "                                         model_dir=FLAGS.model_dir,\n",
    "                                         save_summary_steps=20,\n",
    "                                         save_checkpoints_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../results/Models/Mnist/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 20, '_save_checkpoints_steps': 20, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x0000017A8552C5C0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000017A8552C518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "#model.set_weights(initial_weights)\n",
    "\n",
    "# transfor keras model to estimator model\n",
    "estimator_train_model = tf.keras.estimator.model_to_estimator(keras_model=model,\n",
    "                                                              config=training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../results/Models/Mnist/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "eval\n",
      "events.out.tfevents.1548149619.C054093\n",
      "graph.pbtxt\n",
      "keras\n",
      "model.ckpt-0.data-00000-of-00001\n",
      "model.ckpt-0.index\n",
      "model.ckpt-0.meta\n",
      "model.ckpt-10.data-00000-of-00001\n",
      "model.ckpt-10.index\n",
      "model.ckpt-10.meta\n"
     ]
    }
   ],
   "source": [
    "!dir /B \"../results/Models/Mnist/ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train(\n",
    "    input_fn,\n",
    "    hooks=None,\n",
    "    steps=None,\n",
    "    max_steps=None,\n",
    "    saving_listeners=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_input_fn():\n",
    "    return input_dataset_fn(x_train, y_train, is_training=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='../results/Models/Mnist/ckpt/keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('../results/Models/Mnist/ckpt/keras\\\\keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.33768, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.3454697.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x17a855e9f28>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model (using estimator.train and data.Dataset)\n",
    "#estimator_train_model.train(input_fn=lambda:input_dataset_fn(x_train, y_train, is_training=True, batch_size=BATCH_SIZE),\n",
    "#                            max_steps=1,\n",
    "#                            hooks=[time_hist])\n",
    "estimator_train_model.train(input_fn=get_train_input_fn,\n",
    "                            #max_steps=1,\n",
    "                            steps=10,\n",
    "                            hooks=[time_hist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the accuracy of our model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluate(\n",
    "    input_fn,\n",
    "    steps=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-22-09:40:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../results/Models/Mnist/ckpt/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-22-09:41:15\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.77631664, global_step = 10, loss = 2.0273774\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ../results/Models/Mnist/ckpt/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:input_dataset_fn(x_train, y_train, is_training=False, batch_size=BATCH_SIZE),\n",
    "                                     steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0273774\n",
      "Train accuracy: 0.77631664\n",
      "Train global steps: 10\n"
     ]
    }
   ],
   "source": [
    "print('Train loss:', score['loss'])\n",
    "print('Train accuracy:', score['accuracy'])\n",
    "print('Train global steps:', score['global_step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-22-09:48:42\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../results/Models/Mnist/ckpt/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-22-09:48:46\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.0, global_step = 10, loss = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ../results/Models/Mnist/ckpt/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:input_dataset_fn(x_test, y_test, is_training=False, batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n",
      "Test global steps: 10\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score['loss'])\n",
    "print('Test accuracy:', score['accuracy'])\n",
    "print('Test global steps:', score['global_step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions on our trained model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict(\n",
    "    input_fn,\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    yield_single_examples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=x_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-c7bbc89542fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator_train_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0minput_dataset_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         features, input_hooks = self._get_features_from_input_fn(\n\u001b[1;32m--> 575\u001b[1;33m             input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[0;32m    576\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m    577\u001b[0m             features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1048\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_features_from_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[1;34m\"\"\"Extracts the `features` from return values of `input_fn`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_input_fn_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features_in_predict_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1160\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-c7bbc89542fd>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator_train_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0minput_dataset_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-65-8294beecd5a7>\u001b[0m in \u001b[0;36minput_dataset_fn\u001b[1;34m(x_data, y_data, is_training, batch_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minput_dataset_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Convert the inputs to a Dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tensors)\u001b[0m\n\u001b[0;32m   1563\u001b[0m           if sparse_tensor_lib.is_sparse(t) else ops.convert_to_tensor(\n\u001b[0;32m   1564\u001b[0m               t, name=\"component_%d\" % i)\n\u001b[1;32m-> 1565\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m       ])\n\u001b[0;32m   1567\u001b[0m       \u001b[0mflat_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1563\u001b[0m           if sparse_tensor_lib.is_sparse(t) else ops.convert_to_tensor(\n\u001b[0;32m   1564\u001b[0m               t, name=\"component_%d\" % i)\n\u001b[1;32m-> 1565\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m       ])\n\u001b[0;32m   1567\u001b[0m       \u001b[0mflat_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    227\u001b[0m                                          as_ref=False):\n\u001b[0;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m--> 208\u001b[1;33m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    428\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"None values not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[1;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;31m# provided if possible.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "predictions=list(estimator_train_model.predict(input_fn=lambda:input_dataset_fn(examples, is_training=False, batch_size=BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-5b0abe07db8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprediction_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpredicted_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Actual label:'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted label: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i in range(len(examples)):\n",
    "    prediction_array = predictions[i].values()[0]\n",
    "    predicted_label = text_labels[np.argmax(prediction_array)]\n",
    "    print('Actual label:' + test_tags.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_gcp_dl]",
   "language": "python",
   "name": "conda-env-env_gcp_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
