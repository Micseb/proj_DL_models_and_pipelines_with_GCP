{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling ML using Cloud ML Engine\n",
    "\n",
    "- to run the notebook underlying this presentation, go to [github.com/tarrade/proj_DL_models_and_pipelines_with_GCP](https://github.com/tarrade/proj_DL_models_and_pipelines_with_GCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "2. Data Science Workflow\n",
    "3. Developing code\n",
    "4. Hands-ON Tutorial: Running MNIST on ML-Engine\n",
    "5. Setup Runtime for Notebook\n",
    "6. Load Data from BQ\n",
    "7. Package Model\n",
    "8. Train using ML-Engine\n",
    "9. Deployment\n",
    "10. Predictions\n",
    "11. Recap\n",
    "12. Appendix: Jupyter Slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shortcut: Run first cells and jump to any part in the notebook\n",
    "\n",
    "> Will only work after initial setup (see below) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\t/home/jupyter/proj_DL_models_and_pipelines_with_GCP/notebook\n",
      "Changed to New working directory:\t/home/jupyter/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fragment to initalize working with this notebook on the CLOUD\n",
    "# check working directory\n",
    "from utils import chdir_\n",
    "pwd = chdir_()\n",
    "## Import Tensorflow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ModuleNotFoundError:\n",
    "    raise ModuleNotFoundError(\"Install Tensorflow\")\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket': 'presentation-38388',\n",
      " 'pkg-name': 'pkg_mnist_fnn',\n",
      " 'project-id': 'presentation-38388',\n",
      " 'region': 'europe-west1',\n",
      " 'testdatafile': 'data/mnist/json/ml_engine_testdatafile_N4.json',\n",
      " 'tf-version': 1.13}\n"
     ]
    }
   ],
   "source": [
    "## import config:\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## setup env-variables \n",
    "import os\n",
    "import platform\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "TEST_DATA_JSON = config['testdatafile']\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION \n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = PKG_NAME\n",
    "os.environ['TEST_DATA_JSON'] = TEST_DATA_JSON\n",
    "# os.environ['ENV_NAME'] = config['env-name']\n",
    "if platform.system() == 'Windows':\n",
    "    from script.config_client import filepath_ssl_cert\n",
    "    print('You run Windows -_-\\n\\n''This means you are most probably on a Company Laptop and therefore behind a proxy.\\n'\n",
    "         'Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables')\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = filepath_ssl_cert # 'win-filepath\\to\\axa'\n",
    "    assert os.path.isfile(os.environ['REQUESTS_CA_BUNDLE']), \"SSL-File not found\"\n",
    "    assert os.environ.get(key='HTTPS_PROXY') != None, \"Set a proxy\"\n",
    "    #os.environ['HTTPS_PROXY'] = 'https://C219746:Alles-Ist-Besser2019@sc-wvs-ch-win-pr-01-vip1.ch.doleni.net:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTDIR=gs://presentation-38388/pkg_mnist_fnn/trained\n",
      "env: DATA=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "# Set new OUTPUT and DATA directory on GS\n",
    "OUTDIR = '/'.join(['gs:/', BUCKET, PKG_NAME, 'trained'])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR $OUTDIR\n",
    "%env DATA $DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHON_LOCAL=/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "local_python = sys.executable\n",
    "%env PYTHON_LOCAL $local_python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n",
      "Updated property [ml_engine/local_python].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION\n",
    "gcloud config set ml_engine/local_python $PYTHON_LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Workflow (DSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Goal is to standardise the development of models\n",
    "     - Checklist of necessary technical steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Vision: Achieve an first end-to-end model in production within a *productincrement* of 10 weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Scale out: Scale without having to rewrite your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Science Pipeline (DSP) - Checklist\n",
    "\n",
    "- further [documentation](https://confluence.axa.com/confluence/pages/viewpage.action?pageId=112334644)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Data Science Process](Images/data_science_circle_steps.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [Scaling Michelangelo](https://eng.uber.com/scaling-michelangelo/) - Data Science Process at Uber\n",
    "![Data Science Process at Uber](Images/uber_michelangelo_at_scale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![Data Science Process](Images/data_science_circle.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|   Step 1: Preparation                   |      Step 2: Data exploration and model building                   |    Step 3: Model deployment                    \n",
    "|   :------------------                   |      :-------------------------------------------                  |   :-----------------------------------------  \n",
    "| 1.1  Define business and project goal   | 2.1  Define and setup ML project infrastructure                    | 3.1  Model industralization                             \n",
    "| 1.2  Quick data exploration             | 2.2  Data exploration and visualizaiton                            | 3.2  Gather and analyze insightbalancing ...)     \n",
    "| 1.3  ML models strategy                 | 2.3  Build and evaluate a model                                    | -\n",
    "|         -                              | 2.4  Interpretability of ML model                                  | -\n",
    "|        -                                | 2.5  Productionize and deploy the ML models                        | -                                          \n",
    "> steps 1 and 2 can be done *only* locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Developing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using your own laptop:\n",
    "- Cloud SDK on your laptop (CLI)\n",
    "- your IDE (e.g. PyCharme)\n",
    "- Juypter Notebook\n",
    "- your conda env\n",
    "- `gcloud ml-engine local` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Simple Cloud setup using\n",
    "- [Google Console](https://console.cloud.google.com/) -Compute Engine with 5 GB storage\n",
    "- Cloud Editor\n",
    "- datalab, [Deep Learning VM](https://cloud.google.com/deep-learning-vm/)\n",
    "- env ([runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)) by google\n",
    "- `gcloud ml-engine` (`local`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "|Cloud SDK on Laptop | Google Console |\n",
    "|---------------------|----------------|\n",
    "| your machine | Tiny Compute Engine with 5 GB storage |\n",
    "| Your IDE | Code Editor|\n",
    "| Jupyter Notebook | Datalab, [Deep Learning VM](https://cloud.google.com/deep-learning-vm/) |\n",
    "| your conda env | env ([runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)) by google |\n",
    "| `gcloud ml-engine local` | `gcloud ml-engine`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![laptop-icon-24](Images/laptop-icon-24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Call your python script (module) in your conda env\n",
    "2. Use `gcloud ml-engine local train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AI Platform Notebooks: Deep Learning VM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Deep Learning VM](Images/deep-learning-overview_2x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Preconfigured (Deep Learning) VMs for ML prottyping\n",
    "    - only CPUs possible\n",
    "- you use a preconfigured runtime compatible to ML Engine runtimes for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A cluster of machines using ML-Engine service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![CloudMachineLearning.png](Images/CloudMachineLearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- runs a script \"autonomously\" on the cloud and stops afterwards\n",
    "- offers to run different type of clusters \n",
    "- invoked by `gcloud ml-engine train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> develop on your laptop if you are comfortable with setting up your environements\n",
    "\n",
    "> otherwise develop on a preconfigured Notebook instance without too many compute attached to it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">Migrate to ML-Engine Cluster on GCP to \n",
    ">   - distribute learning on several machines\n",
    ">   - serve model 24/7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-ON Tutorial: Running MNIST on ML-Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Images/gcp_training_options-Modelling.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- deep dive into step 2 and 3 of proposed Data Science process\n",
    "- data exploration is omitted since a curated dataset is used\n",
    "- Some title reference to previously described Data Science Process, e.g. DSP 2.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adapted from [Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/cloudmle/cloudmle.ipynb) of Google Coursera Course [Serverless Machine Learning with Tensorflow on Google Cloud Platform](https://www.coursera.org/learn/serverless-machine-learning-gcp/). The current code respository is [github/tarrade/tarrade/proj_DL_models_and_pipelines_with_GCP/](https://github.com/tarrade/proj_DL_models_and_pipelines_with_GCP/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://ml4a.github.io/images/figures/mnist-input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- black and white images are numeric vectors (Feat 1- 784)\n",
    "- ten labels (Figures 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- recognise hand-written digits (e.g. on a postal card) \n",
    "- standardise inputs to 0 - 1 range (e.g. using BEAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GCP services used in Tutorial\n",
    "We will look today at following GCP Services-\n",
    "- [BigQuery](https://console.cloud.google.com/bigquery) (BQ)\n",
    "- [Cloudstorage](https://console.cloud.google.com/storage) (Buckets)\n",
    "- [ML Engine](https://console.cloud.google.com/mlengine/)\n",
    "- If time allows: Dataflow using Apache Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\t/home/jupyter/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata \n",
    "plot_mnist_testdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "ToDo: export in readable yaml format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSP 2.1: Setup\n",
    "\n",
    "1. ML Engine Runtimes\n",
    "2. Repository Structure\n",
    "3. Configuration Variables\n",
    "    - Environment variables to set\n",
    "    - How to add them to your runtime\n",
    "4. Setup `gcloud` runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">Create conda environment\n",
    ">  ```\n",
    ">  conda env create -f environment.yml -n env_gcp_dl\n",
    ">  conda activate env_gcp_dl\n",
    ">  jupyter notebook \n",
    ">  ```\n",
    "> Starts notebook-server with all packages in your current path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Change working directory**\n",
    "\n",
    "- In order to import from `src` functionality later in this notebook, it is necessary to change to the root directory of the notebooks directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "center",
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\t/home/jupyter/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "# check working directory\n",
    "import os\n",
    "WORKINGDIR = os.path.normpath(os.getcwd())\n",
    "print(\"Current Working direcotory:\\t{}\".format(WORKINGDIR))\n",
    "folders = WORKINGDIR.split(os.sep)\n",
    "if folders.pop() in ['notebook', 'src', 'talks']:\n",
    "  WORKINGDIR = os.sep.join(folders)\n",
    "  print(\"Changed to New working directory:\\t{dir}\".format(dir=WORKINGDIR))\n",
    "  os.chdir(WORKINGDIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML Engine Runtimes\n",
    "Default ML-Engine Runtimes depend on the Tensorflow Version\n",
    "- [list of runtimes](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)\n",
    "- Current Version: `1.13`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#!conda install tensorflow=1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Tensorflow: 1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: 1.13.1: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TF_VERSION=$(python3 -c 'import tensorflow as tf; print(tf.__version__)')\n",
    "if $TF_VERSION != \"1.13.1\"\n",
    "then\n",
    "    echo \"Install Tensorflow using pip: pip install tensorflow==1.13\"\n",
    "fi\n",
    "    echo \"Found Tensorflow: $TF_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- current version of gcp datalab\n",
    "- will be different on Windows machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Repository structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.04.2019  10:22    <DIR>          .\n",
      "17.04.2019  10:22    <DIR>          ..\n",
      "11.01.2019  11:46    <DIR>          .vscode\n",
      "15.04.2019  22:13               149 config.yaml\n",
      "15.04.2019  21:55               127 config_from_python.yaml\n",
      "12.04.2019  16:37               224 config2.yaml\n",
      "06.03.2019  17:23    <DIR>          data\n",
      "27.02.2019  10:15    <DIR>          doc\n",
      "17.04.2019  10:57    <DIR>          notebook\n",
      "11.01.2019  12:08    <DIR>          results\n",
      "15.04.2019  10:02    <DIR>          script\n",
      "12.04.2019  16:13    <DIR>          src\n",
      "15.04.2019  14:00    <DIR>          trained\n"
     ]
    }
   ],
   "source": [
    "ls | grep \"DIR\\|yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key Directories containing information\n",
    "```\n",
    ".\n",
    "+-- data\n",
    "+-- src\n",
    "|  +-- models\n",
    "|  +-- packages\n",
    "config.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the next step the contents of [`config.yaml`](config.yaml) will be important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GCP Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `PROJECT_ID`: unique ID that identifies your project, e.g. **ml-productive-pipeline-12345**\n",
    "- `BUCKET`: BLOB-store ID. Each project has per default an bucket named by the `PROJECT_ID`\n",
    "- `REGION`: Which data center to use\n",
    "\n",
    "> All Cloud-ML-Engine Services are only available in [`europe-west1`](https://cloud.google.com/ml-engine/docs/tensorflow/regions)\n",
    "\n",
    "- all products per Region in europe: [link](https://cloud.google.com/about/locations/?region=europe#region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# #Create config manually and save as yaml:\n",
    "config = {}\n",
    "config['project-id'] = 'presentation-38388'  # # REPLACE WITH YOUR PROJECT ID\n",
    "config['region'] = 'europe-west1' # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "config['bucket'] = 'presentation-38388'  # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "config['pkg-name'] = 'pkg_mnist_fnn'\n",
    "config['tf-version'] = '1.13'\n",
    "config['env-name'] = 'env_gcp_dl'\n",
    "with open(\"config.yaml\", 'w', encoding= 'utf8') as f:\n",
    "      yaml.dump(config, stream=f,  default_flow_style=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**ML-Engine Environment Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Additional Environment Variables needed for ML-Engine\n",
    "- `PKG_NAME`: Package Name which will contain your model\n",
    "- `TF_VERSION`: Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket': 'presentation-38388',\n",
      " 'env-name': 'env_gcp_dl',\n",
      " 'pkg-name': 'pkg_mnist_fnn',\n",
      " 'project-id': 'presentation-38388',\n",
      " 'region': 'europe-west1',\n",
      " 'tf-version': '1.13'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Environment variables for project and bucket\n",
    "\n",
    "Note that:\n",
    "1. Your project id is the *unique* string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads:  \n",
    "     \n",
    "     - Project ID: ml-productive-pipeline-12345\n",
    "     \n",
    "2. Cloud training often involves saving and restoring model files. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available). A common pattern is to prefix the bucket name by the project id, so that it is unique. Also, for cost reasons, you might want to use a single region bucket.\n",
    "\n",
    "\n",
    "Add all detail in to [config.yaml](../config.yaml) file in main directory. Missing in public repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adding Environment Variables to your runtime\n",
    "- add variables **persistently**  to the runtime of your kernel from jupyter (or datalab)\n",
    "- use `os.environ` dictionary\n",
    "- behind a proxy, configure globally\n",
    "  - `REQUESTS_CA_BUNDLE`: optional, filepath to your SLL-certificate (works for `request`-package)\n",
    "  - `HTTPS_PROXY`: optional, link to your proxy, possibly includign authentification or ports\n",
    "- possiblity to set `environment variables` for user permanently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You run Windows -_-\n",
      "\n",
      "This means you are most probably on a Company Laptop and therefore behind a proxy.\n",
      "Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables\n"
     ]
    }
   ],
   "source": [
    "## setup env-variables \n",
    "import os\n",
    "import platform\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "#TEST_DATA_JSON = config['testdatafile'] # added later\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = PKG_NAME\n",
    "#os.environ['TEST_DATA_JSON'] = TEST_DATA_JSON\n",
    "# os.environ['ENV_NAME'] = config['env-name']\n",
    "if platform.system() == 'Windows':\n",
    "    from script.config_client import filepath_ssl_cert\n",
    "    print('You run Windows -_-\\n\\n''This means you are most probably on a Company Laptop and therefore behind a proxy.\\n'\n",
    "         'Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables')\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = filepath_ssl_cert # 'win-filepath\\to\\axa'\n",
    "    assert os.path.isfile(os.environ['REQUESTS_CA_BUNDLE']), \"SSL-File not found\"\n",
    "    assert os.environ.get(key='HTTPS_PROXY') != None, \"Set a proxy\"\n",
    "    #os.environ['HTTPS_PROXY'] = 'https://C219746:Alles-Ist-Besser2019@sc-wvs-ch-win-pr-01-vip1.ch.doleni.net:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Access Environment Variables**\n",
    "- Now, you can access the environement variable in the terminal where your jupyter, datalab or ipython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow Version: 1.13\n"
     ]
    }
   ],
   "source": [
    "!echo \"Using Tensorflow Version: $TFVERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setup gcloud runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHON_LOCAL=/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "local_python = sys.executable\n",
    "%env PYTHON_LOCAL $local_python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n",
      "Updated property [ml_engine/local_python].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION\n",
    "## ensure we predict locally with our current Python environment\n",
    "gcloud config set ml_engine/local_python $PYTHON_LOCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Access Control \n",
    "\n",
    "- sign in and let clients pick up credentials from GCloud SDK (this stores a json with your credentials on your machine)\n",
    "    ```\n",
    "    gcloud auth application-default login\n",
    "    ```\n",
    "\n",
    "- Service Accounts ([Creating and Managing Service Accounts](https://cloud.google.com/iam/docs/creating-managing-service-accounts))\n",
    "  - need be assigned read/write permission to `BUCKET`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Load Data: Bigquery Client (DSP 2.2 )\n",
    "\n",
    "There are several python clients available, see list. Here we use `bigquery` to load some data.\n",
    "\n",
    "Picks up  PROXY_HTTPS, REQUESTS_CA_BUNDLE, PROJECT_ID from environment\n",
    "\n",
    "- set all relevant variables as user environment variables\n",
    "    1. search \"env\" in windows search bar (press windows button)\n",
    "    2. select \"Edit environment variables for your account\"\n",
    "    3. select \"new\" and add the PROXY_HTTPS, REQUESTS_CA_BUNDLE, PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Download from public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Current project in use: presentation-38388\n",
      "\n",
      "  state gender  year      name  number\n",
      "0    TX      F  1910      Mary     895\n",
      "1    TX      F  1910      Ruby     314\n",
      "2    TX      F  1910     Annie     277\n",
      "3    TX      F  1910    Willie     260\n",
      "4    TX      F  1910      Ruth     252\n",
      "5    TX      F  1910    Gladys     240\n",
      "6    TX      F  1910     Maria     223\n",
      "7    TX      F  1910   Frances     197\n",
      "8    TX      F  1910  Margaret     194\n",
      "9    TX      F  1910     Helen     189\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.environ['PROJECT']\n",
    "print(\"# Current project in use: {}\\n\".format(PROJECT_ID))\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "    WHERE state = 'TX'\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "df = client.query(sql).to_dataframe()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Download from project table\n",
    "- use `test` Dataset with table `DATA` of project (has to be created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_776</th>\n",
       "      <th>feat_777</th>\n",
       "      <th>feat_778</th>\n",
       "      <th>feat_779</th>\n",
       "      <th>feat_780</th>\n",
       "      <th>feat_781</th>\n",
       "      <th>feat_782</th>\n",
       "      <th>feat_783</th>\n",
       "      <th>feat_784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0   51       0       0       0       0       0       0       0       0   \n",
       "1   68       0       0       0       0       0       0       0       0   \n",
       "2   75       0       0       0       0       0       0       0       0   \n",
       "3  118       0       0       0       0       0       0       0       0   \n",
       "4  121       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_9  ...  feat_776  feat_777  feat_778  feat_779  feat_780  feat_781  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   feat_782  feat_783  feat_784  label  \n",
       "0         0         0         0      0  \n",
       "1         0         0         0      0  \n",
       "2         0         0         0      0  \n",
       "3         0         0         0      0  \n",
       "4         0         0         0      0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `{project}.test.DATA`\n",
    "    LIMIT 15\n",
    "\"\"\".format(project=PROJECT)\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6903</td>\n",
       "      <td>7877</td>\n",
       "      <td>6990</td>\n",
       "      <td>7141</td>\n",
       "      <td>6824</td>\n",
       "      <td>6313</td>\n",
       "      <td>6876</td>\n",
       "      <td>7293</td>\n",
       "      <td>6825</td>\n",
       "      <td>6958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9\n",
       "count  6903  7877  6990  7141  6824  6313  6876  7293  6825  6958"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT COUNT(label) as count\n",
    "    FROM `{project}.test.DATA`\n",
    "    GROUP BY label\n",
    "\"\"\".format(project=PROJECT)\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Downloading the entire table to pandas\n",
    "- BQ Query Default limit of128MB maximum reponse size, see [quotas](https://cloud.google.com/bigquery/quotas), does not allow to download entire Table\n",
    "- [`bigquery_storage`](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas#install_the_client_libraries) client has to be used to download large datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!pip install --upgrade google-cloud-bigquery[pandas]\n",
    "!pip install --upgrade google-cloud-bigquery-storage[fastavro,pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials: <google.oauth2.credentials.Credentials object at 0x00000123CCEBA668>\n",
      "PROJECT: presentation-38388\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage_v1beta1\n",
    "\n",
    "# Explicitly create a credentials object. This allows you to use the same\n",
    "# credentials for both the BigQuery and BigQuery Storage clients, avoiding\n",
    "# unnecessary API calls to fetch duplicate authentication tokens.\n",
    "credentials, _ = google.auth.default(\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "print(\"Credentials: {}\".format(credentials))\n",
    "print(\"PROJECT: {}\".format(PROJECT))\n",
    "\n",
    "# Make clients.\n",
    "client = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=PROJECT\n",
    ")\n",
    "bqstorageclient = bigquery_storage_v1beta1.BigQueryStorageClient(\n",
    "    credentials=credentials\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Download to pandas dataframe\n",
    "- can take very long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Download a table.\n",
    "table = bigquery.TableReference.from_string(\n",
    "    \"{project}.test.DATA\".format(project=PROJECT)\n",
    ")\n",
    "rows = client.list_rows(\n",
    "    table,\n",
    "    #selected_fields=[ \n",
    "    #    bigquery.SchemaField(\"label\", \"INTEGER\")\n",
    "    #],\n",
    ")\n",
    "df = rows.to_dataframe(bqstorage_client=bqstorageclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_776</th>\n",
       "      <th>feat_777</th>\n",
       "      <th>feat_778</th>\n",
       "      <th>feat_779</th>\n",
       "      <th>feat_780</th>\n",
       "      <th>feat_781</th>\n",
       "      <th>feat_782</th>\n",
       "      <th>feat_783</th>\n",
       "      <th>feat_784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0   51       0       0       0       0       0       0       0       0   \n",
       "1   68       0       0       0       0       0       0       0       0   \n",
       "2   75       0       0       0       0       0       0       0       0   \n",
       "3  118       0       0       0       0       0       0       0       0   \n",
       "4  121       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_9  ...  feat_776  feat_777  feat_778  feat_779  feat_780  feat_781  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   feat_782  feat_783  feat_784  label  \n",
       "0         0         0         0      0  \n",
       "1         0         0         0      0  \n",
       "2         0         0         0      0  \n",
       "3         0         0         0      0  \n",
       "4         0         0         0      0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(file='data/mnist/raw/mnist_all', allow_pickle=True, arr=df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model: Packaging model (DSP 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Take your code and put into a standard Python package structure, see  [Recommended package structure](https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer#project-structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key-Idea: \n",
    " - define entry point which can be called\n",
    " - write all tasks as a function (callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    "Why a package?\n",
    " - can be called from other scripts `import model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `model.py`\n",
    "\n",
    "load most recent version, if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load src/pkg_mnist_fnn/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/pkg_mnist_fnn/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/pkg_mnist_fnn/model.py\n",
    "# First try to start Cloud ML uing MNIST example.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from .utils import load_data\n",
    "##########################################################################\n",
    "#Factor into config:\n",
    "IMAGE_SHAPE = (28,28)\n",
    "N_PIXEL = 28 * 28\n",
    "NUM_LABELS = 10\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "##########################################################################\n",
    "def parse_images(x):\n",
    "    return x.reshape(len(x), -1).astype('float32')\n",
    "\n",
    "\n",
    "def parse_labels(y):\n",
    "    return y.astype('int32')\n",
    "\n",
    "\n",
    "def numpy_input_fn(images: np.ndarray,\n",
    "                   labels: np.ndarray,\n",
    "                   mode=tf.estimator.ModeKeys.EVAL,\n",
    "                   epochs=EPOCHS,\n",
    "                   batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Return depending on the `mode`-key an Interator which can be use to\n",
    "    feed into the Estimator-Model. \n",
    "\n",
    "    Alternative if a `tf.data.Dataset` named `dataset` would be created:\n",
    "    `dataset.make_one_shot_iterator().get_next()`\n",
    "    \"\"\"\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        _epochs = epochs\n",
    "        _shuffle = True\n",
    "        _num_threads = 1 # This leads to doubling the number of epochs\n",
    "    else:\n",
    "        _epochs = 1\n",
    "        _shuffle = False\n",
    "        _num_threads = 1\n",
    "\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        {'x': images},\n",
    "        y=labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=_epochs,                             \n",
    "        shuffle=_shuffle, # Boolean, if True shuffles the queue. Avoid shuffle at prediction time.\n",
    "        queue_capacity=1000, # Integer, number of threads used for reading \n",
    "        # and enqueueing. To have predicted order of reading and enqueueing,\n",
    "        # such as in prediction and evaluation mode, num_threads should be 1.\n",
    "        num_threads=_num_threads\n",
    "    )\n",
    "\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\n",
    "    }\n",
    "    features = feature_placeholders\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "         features=features, \n",
    "         receiver_tensors=feature_placeholders,\n",
    "         receiver_tensors_alternatives=None\n",
    "         )\n",
    "\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "    \"\"\"\n",
    "    Utility function for distributed training on ML-Engine\n",
    "    www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \n",
    "    \"\"\"\n",
    "    ##########################################\n",
    "    # Load Data in Memoery\n",
    "    # ToDo: replace numpy-arrays\n",
    "    print('## load data, specified path to try: {}'.format(args['data_path']))\n",
    "    (x_train, y_train), (x_test, y_test) = load_data(\n",
    "        path=args['data_path'])\n",
    "    \n",
    "    x_train = parse_images(x_train)\n",
    "    x_test = parse_images(x_test)\n",
    "\n",
    "    y_train = parse_labels(y_train)\n",
    "    y_test = parse_labels(y_test)\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "        hidden_units= args['hidden_units'],  #[256, 128, 64],\n",
    "        feature_columns=[tf.feature_column.numeric_column(\n",
    "            'x', shape=[N_PIXEL, ])],\n",
    "        model_dir=args['output_dir'],\n",
    "        n_classes=NUM_LABELS,\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=args['learning_rate']),\n",
    "        # activation_fn=,\n",
    "        dropout=0.2,\n",
    "        batch_norm=False,\n",
    "        loss_reduction='weighted_sum',\n",
    "        warm_start_from=None,\n",
    "        config=tf.estimator.RunConfig(# save_summary_steps=200,\n",
    "                                      save_checkpoints_steps=400,\n",
    "                                      keep_checkpoint_max=5, \n",
    "                                      keep_checkpoint_every_n_hours=1,\n",
    "                                      #log_step_count_steps=100,\n",
    "                                      train_distribute=None,\n",
    "                                      )\n",
    "    )\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN, \n",
    "            batch_size = args['train_batch_size']),    \n",
    "        max_steps=args['train_steps'],\n",
    "        # hooks = None\n",
    "    )\n",
    "    # use `LatestExporter` for regular model exports:\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\n",
    "        # steps=100,\n",
    "        start_delay_secs=args['eval_delay_secs'],\n",
    "        throttle_secs=args['min_eval_frequency'],\n",
    "        exporters=exporter\n",
    "    )\n",
    "    print(\n",
    "        \"## start training and evaluation\\n\"\n",
    "        \"### save model, ckpts, etc. to: {}\".format(args['output_dir'])\n",
    "    \n",
    "    )\n",
    "\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Imports, Helper Functions\n",
    "```python\n",
    "# First try to start Cloud ML uing MNIST example.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from .utils import load_data\n",
    "##########################################################################\n",
    "#Factor into config:\n",
    "IMAGE_SHAPE = (28,28)\n",
    "N_PIXEL = 28 * 28\n",
    "NUM_LABELS = 10\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "##########################################################################\n",
    "def parse_images(x):\n",
    "    return x.reshape(len(x), -1).astype('float32')\n",
    "\n",
    "\n",
    "def parse_labels(y):\n",
    "    return y.astype('int32')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Input-Function used when Model is trained\n",
    "```python\n",
    "def numpy_input_fn(images: np.ndarray,\n",
    "                   labels: np.ndarray,\n",
    "                   mode=tf.estimator.ModeKeys.EVAL,\n",
    "                   epochs=EPOCHS,\n",
    "                   batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Return depending on the `mode`-key an Interator which can be use to\n",
    "    feed into the Estimator-Model. \n",
    "\n",
    "    Alternative if a `tf.data.Dataset` named `dataset` would be created:\n",
    "    `dataset.make_one_shot_iterator().get_next()`\n",
    "    \"\"\"\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        _epochs = epochs\n",
    "        _shuffle = True\n",
    "        _num_threads = 1 # This leads to doubling the number of epochs\n",
    "    else:\n",
    "        _epochs = 1\n",
    "        _shuffle = False\n",
    "        _num_threads = 1\n",
    "\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        {'x': images},\n",
    "        y=labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=_epochs,                             \n",
    "        shuffle=_shuffle, # Boolean, if True shuffles the queue. Avoid shuffle at prediction time.\n",
    "        queue_capacity=1000, # Integer, number of threads used for reading \n",
    "        # and enqueueing. To have predicted order of reading and enqueueing,\n",
    "        # such as in prediction and evaluation mode, num_threads should be 1.\n",
    "        num_threads=_num_threads\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Input-Function used when Model is served\n",
    "```python\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\n",
    "    }\n",
    "    features = feature_placeholders\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "         features=features, \n",
    "         receiver_tensors=feature_placeholders,\n",
    "         receiver_tensors_alternatives=None\n",
    "         )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Entrypoint (main function)\n",
    "```python\n",
    "def train_and_evaluate(args):\n",
    "    \"\"\"\n",
    "    Utility function for distributed training on ML-Engine\n",
    "    www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \n",
    "    \"\"\"\n",
    "    ##########################################\n",
    "    # Load Data in Memoery\n",
    "    # ToDo: replace numpy-arrays\n",
    "    print('## load data, specified path to try: {}'.format(args['data_path']))\n",
    "    (x_train, y_train), (x_test, y_test) = load_data(\n",
    "        path=args['data_path'])\n",
    "    \n",
    "    x_train = parse_images(x_train)\n",
    "    x_test = parse_images(x_test)\n",
    "\n",
    "    y_train = parse_labels(y_train)\n",
    "    y_test = parse_labels(y_test)\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "        hidden_units= args['hidden_units'],  #[256, 128, 64],\n",
    "        feature_columns=[tf.feature_column.numeric_column(\n",
    "            'x', shape=[N_PIXEL, ])],\n",
    "        model_dir=args['output_dir'],\n",
    "        n_classes=NUM_LABELS,\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=args['learning_rate']),\n",
    "        # activation_fn=,\n",
    "        dropout=0.2,\n",
    "        batch_norm=False,\n",
    "        loss_reduction='weighted_sum',\n",
    "        warm_start_from=None,\n",
    "        config=tf.estimator.RunConfig(# save_summary_steps=200,\n",
    "                                      save_checkpoints_steps=400,\n",
    "                                      keep_checkpoint_max=5, \n",
    "                                      keep_checkpoint_every_n_hours=1,\n",
    "                                      #log_step_count_steps=100,\n",
    "                                      train_distribute=None,\n",
    "                                      )\n",
    "    )\n",
    "    ## to cont.\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "    ## to cont.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN, \n",
    "            batch_size = args['train_batch_size']),    \n",
    "        max_steps=args['train_steps'],\n",
    "        # hooks = None\n",
    "    )\n",
    "    # use `LatestExporter` for regular model exports:\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\n",
    "        # steps=100,\n",
    "        start_delay_secs=args['eval_delay_secs'],\n",
    "        throttle_secs=args['min_eval_frequency'],\n",
    "        exporters=exporter\n",
    "    )\n",
    "    print(\"## start training and evaluation\\n\"\n",
    "          \"### save model, ckpts, etc. to: {}\".format(args['output_dir']))\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `task.py`\n",
    "\n",
    "write contents to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/pkg_mnist_fnn/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/pkg_mnist_fnn/task.py\n",
    "# Parse arguments and call main function\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import shutil\n",
    "from pprint import pprint \n",
    "\n",
    "from .model import train_and_evaluate\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--data_path',\n",
    "        help='GCS or local path to training data',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help='GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_batch_size',\n",
    "        help='Batch size for training steps',\n",
    "        type=int,\n",
    "        default='128'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_steps',\n",
    "        help='Steps to run the training job for',\n",
    "        type=int,\n",
    "        default='200'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--learning_rate',\n",
    "        help='Learning Rate used for Adam',\n",
    "        type=float,\n",
    "        default='0.001'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--hidden_units',\n",
    "        help = 'Hidden layer sizes to use for DNN feature columns -- provide space-separated layers',\n",
    "        type = str,\n",
    "        default = \"256 128 64\"\n",
    "    )   \n",
    "    parser.add_argument(\n",
    "        '--job_dir',\n",
    "        help='this model ignores this field, but it is required by gcloud',\n",
    "        default='junk'\n",
    "    )\n",
    "    # Eval arguments\n",
    "    parser.add_argument(\n",
    "        '--eval_delay_secs',\n",
    "        help='How long to wait before running first evaluation',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min_eval_frequency',\n",
    "        help='Seconds between evaluations',\n",
    "        default=5,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args().__dict__\n",
    "    pprint(\"Arguments:\\n{}\".format(args)) \n",
    "    args['hidden_units'] = [int(x) for x in args['hidden_units'].split(' ')]\n",
    "    pprint(\"Arguments:\\n{}\".format(args)) \n",
    "    \n",
    "    output_dir = args['output_dir']\n",
    "    # Append trial_id to path if we are doing hptuning\n",
    "    # This code can be removed if you are not using hyperparameter tuning\n",
    "    args['output_dir'] = os.path.join(\n",
    "        output_dir,\n",
    "        json.loads(\n",
    "            os.environ.get('TF_CONFIG', '{}')\n",
    "        ).get('task', {}).get('trial', '')\n",
    "    )\n",
    "    print(\"Save output to: {}\".format(args['output_dir']))\n",
    "    # #######################################\n",
    "    # # Train and Evaluate (use TensorBoard to visualize)\n",
    "    train_and_evaluate(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "# Parse arguments and call main function\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import shutil\n",
    "from pprint import pprint \n",
    "\n",
    "from .model import train_and_evaluate\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--data_path',\n",
    "        help='GCS or local path to training data',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help='GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_batch_size',\n",
    "        help='Batch size for training steps',\n",
    "        type=int,\n",
    "        default='128'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_steps',\n",
    "        help='Steps to run the training job for',\n",
    "        type=int,\n",
    "        default='200'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--learning_rate',\n",
    "        help='Learning Rate used for Adam',\n",
    "        type=float,\n",
    "        default='0.001'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--hidden_units',\n",
    "        help = 'Hidden layer sizes to use for DNN feature columns -- provide space-separated layers',\n",
    "        type = str,\n",
    "        default = \"256 128 64\"\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "    parser.add_argument(\n",
    "        '--job_dir',\n",
    "        help='this model ignores this field, but it is required by gcloud',\n",
    "        default='junk'\n",
    "    )\n",
    "    # Eval arguments\n",
    "    parser.add_argument(\n",
    "        '--eval_delay_secs',\n",
    "        help='How long to wait before running first evaluation',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min_eval_frequency',\n",
    "        help='Seconds between evaluations',\n",
    "        default=5,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args().__dict__\n",
    "    pprint(\"Arguments:\\n{}\".format(args)) \n",
    "    args['hidden_units'] = [int(x) for x in args['hidden_units'].split(' ')]\n",
    "    pprint(\"Arguments:\\n{}\".format(args)) \n",
    "    \n",
    "    output_dir = args['output_dir']\n",
    "    # Append trial_id to path if we are doing hptuning\n",
    "    # This code can be removed if you are not using hyperparameter tuning\n",
    "    args['output_dir'] = os.path.join(\n",
    "        output_dir,\n",
    "        json.loads(\n",
    "            os.environ.get('TF_CONFIG', '{}')\n",
    "        ).get('task', {}).get('trial', '')\n",
    "    )\n",
    "    print(\"Save output to: {}\".format(args['output_dir']))\n",
    "    # #######################################\n",
    "    # # Train and Evaluate (use TensorBoard to visualize)\n",
    "    train_and_evaluate(args)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train using ML-Engine on (DSP 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modeling and ML-Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gcp_training_options-overview.png](Images/gcp_training_options-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Environment Variables with absolut paths to relevant folders: \n",
    "    - `PKG_NAME`: Self-Contained Package to be exported into `site-packages` in `venv`\n",
    "    - `DATA`, `OUTDIR`: Datafolder and where to store store checkpoints (logs,  weights, graph)\n",
    "    - `PWD`: where your project folder lies\n",
    "    - `JOBNAME`: ID for ML-Engine\n",
    "    - `BUCKET`: ID of Bucket\n",
    "    - `TIER`: Type of Cluster\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adding Code snippets\n",
    "\n",
    "![gcp_training_options-overview.png](Images/gcp_training_options-overview-code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Schematic Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![GCP for Data Scientists](Images/gcp_scheme_parts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Contents ML-Engine Section\n",
    "\n",
    "- Training\n",
    "    - local (on your machine)\n",
    "    - on cluster (submitting a job)\n",
    "- Hyperparameter search (on cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training on your local maschine with your *python env*\n",
    "\n",
    "- Set local folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Data Directory:\t /home/jupyter/proj_DL_models_and_pipelines_with_GCP/data/mnist/raw/mnist.npz\n",
      "Local Output Dir:\t /home/jupyter/proj_DL_models_and_pipelines_with_GCP/trained/pkg_mnist_fnn\n"
     ]
    }
   ],
   "source": [
    "data_local = os.path.join(os.getcwd(),'data', 'mnist', 'raw', 'mnist.npz')\n",
    "OUTDIR_local = os.path.join(os.getcwd(),'trained', PKG_NAME)\n",
    "os.environ['OUTDIR_LOCAL'] = OUTDIR_local\n",
    "os.environ['DATA_LOCAL'] = data_local\n",
    "\n",
    "print(\"Local Data Directory:\\t {}\".format(os.environ['DATA_LOCAL']))\n",
    "print(\"Local Output Dir:\\t {}\".format(os.environ['OUTDIR_LOCAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)\n",
    "os.listdir(OUTDIR_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Running the Python `module` without gcp ml-engine\n",
    "\n",
    "- Entry point is defined in `task.py`\n",
    "  - parses command line arguments \n",
    "- conda env has to be active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 -m src.${PKG_NAME}.task \\\n",
    "   --data_path=$DATA_LOCAL \\\n",
    "   --output_dir=$OUTDIR_LOCAL \\\n",
    "   --train_steps=1000 \\\n",
    "   --job_dir=tmp\n",
    "echo \"Saved Model, ckpts, exported model to: $OUTDIR_LOCAL\"\n",
    "ls $OUTDIR_LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556197339  1556197344\t1556197350  1556197354\n"
     ]
    }
   ],
   "source": [
    "# Exported models \n",
    "!ls $OUTDIR_LOCAL/export/exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Call hidden units parameter\n",
    "- change model architecture\n",
    "- here previous model is deleted -> later several model will be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 -m src.${PKG_NAME}.task \\\n",
    "   --data_path    $DATA_LOCAL \\\n",
    "   --output_dir   $OUTDIR_LOCAL \\\n",
    "   --train_steps  1000 \\\n",
    "   --job_dir      tmp  \\\n",
    "   --train_batch_size   128 \\\n",
    "   --learning_rate 0.01 \\\n",
    "   --hidden_units \"256 128 64\"\n",
    "echo \"Saved Model, ckpts, exported model to: $OUTDIR_LOCAL\"\n",
    "ls $OUTDIR_LOCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1556197339'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some previous versions might exist, take latest:\n",
    "os.listdir(os.path.normpath(\"{}/export/exporter\".format(OUTDIR_local)))[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**And we would be ready to deploy**\n",
    "\n",
    "... but of course not without looking at performance metrics or predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training using `gcloud ml-engine local train`\n",
    "\n",
    "- continue training using `ml-engine local`\n",
    "- needs full-paths for out-dir: Add `$PWD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=${PKG_NAME}.task \\\n",
    "   --package-path=src/${PKG_NAME} \\\n",
    "   -- \\\n",
    "   --data_path=$DATA_LOCAL \\\n",
    "   --output_dir=$OUTDIR_LOCAL \\\n",
    "   --train_steps=5500 \\\n",
    "   --job_dir=./tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine local train  --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training Cloud using `gcloud ml-engine train`\n",
    "\n",
    "- a copy of the data is in [Google Storage](https://console.cloud.google.com/storage) (buckets)\n",
    "- `gcloud ml-engine` output is saved to `OUTDIR`in Google Storage \n",
    "  - checkpoints (logs)\n",
    "  - model graph and weights\n",
    "- data is copied to Google Storage (see [console](https://console.cloud.google.com/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs using 10000 steps: 21.3\n",
      "For ten epochs specify 4688 steps\n"
     ]
    }
   ],
   "source": [
    "# 10 epochs in global steps using 128 Images per Mini-Batch:\n",
    "steps = 10000\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "n_train = 60000\n",
    "print(\"Number of epochs after {} steps: {:.1f}\".format(steps, steps * batch_size / n_train))\n",
    "steps = int(60000 / batch_size * epochs) + 1\n",
    "print(\"For ten epochs specify {} steps\".format(steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Check: Does this account for parallel processes in input fct?\n",
    "- If global steps is done on two processes, the number doubles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME=mnist_190417_133814\n",
      "env: OUTDIR=gs://presentation-38388/mnist_190417_133814\n",
      "env: DATA=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "#Set JOBNAME\n",
    "import datetime\n",
    "JOBNAME = 'mnist_' + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "%env JOBNAME {JOBNAME}\n",
    "# Set new OUTPUT and DATA directory in GS\n",
    "OUTDIR = '/'.join(['gs:/', BUCKET, JOBNAME])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR $OUTDIR\n",
    "%env DATA $DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTDIR on GS: gs://presentation-38388/pkg_mnist_fnn/trained\n",
      "DATA on GS: gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "print(\"OUTDIR on GS: {}\".format(OUTDIR))\n",
    "print(\"DATA on GS: {}\".format(DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/proj_DL_models_and_pipelines_with_GCP/data/mnist/raw/mnist.npz [Content-Type=application/octet-stream]...\n",
      "-\n",
      "Operation completed over 1 objects/11.0 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp ${PWD}/data/mnist/raw/mnist.npz ${DATA}\n",
    "gsutil ls ${DATA}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ml-engine on cluster\n",
    "- set `JOBNAME` and decide which [tier](https://cloud.google.com/ml-engine/docs/tensorflow/machine-types#scale_tiers) to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TIER=BASIC\n"
     ]
    }
   ],
   "source": [
    "%env TIER BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://presentation-38388/mnist_190417_133814 gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz europe-west1 mnist_190417_133814\n",
      "jobId: mnist_190417_133814\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [mnist_190417_133814] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_190417_133814\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190417_133814\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $OUTDIR $DATA $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=$PKG_NAME.task \\\n",
    "   --package-path=${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=$TIER \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --data_path=$DATA \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000 \\\n",
    "   --job_dir=$OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fetch logs from ml-engine job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $JOBNAME\n",
    "gcloud ml-engine jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs stream-logs $JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Don't be concerned if the notebook appears stalled (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud. \n",
    "\n",
    "**Use the Cloud Console link to monitor the job and do NOT proceed until the job is done.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Check out results in the logs, see [example](https://cloud.google.com/solutions/machine-learning/recommendation-system-tensorflow-train-cloud-ml-engine#results_of_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML-Engine with Hyperparameter search\n",
    "- Bayesian approach to find optimal hyperparameters, see \n",
    "    > Golovin et.al (2017): Google Vizier: A Service for Black-Box Optimization\n",
    "- consecutive search, here\n",
    "    - 2 trials in parallel\n",
    "    - a total of 30 trials\n",
    "- see `hyperp_config.yaml`:\n",
    "    - `train_batch_size`\n",
    "    - `hidden_units`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Configure Search in  `hyperp_config.yaml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperp_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperp_config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    hyperparameterMetricTag: accuracy\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 4\n",
    "    params:\n",
    "      - parameterName: train_batch_size\n",
    "        type: INTEGER\n",
    "        minValue: 64\n",
    "        maxValue: 512\n",
    "        scaleType: UNIT_LINEAR_SCALE\n",
    "      - parameterName: hidden_units\n",
    "        type: CATEGORICAL\n",
    "        categoricalValues: [\"256 128 64\", \"128 64 32\", \"512 256 128 64\", \"256 128 64 32\"]\n",
    "      - parameterName: learning_rate\n",
    "        type: DOUBLE\n",
    "        minValue: 0.0001\n",
    "        maxValue: 0.1\n",
    "        scaleType: UNIT_LOG_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load hyperp_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Create unique jobname: `JOBNAME_HYPER`\n",
    "\n",
    "- decide which [`TIER`](https://cloud.google.com/ml-engine/docs/tensorflow/machine-types#scale_tiers) to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME_HYPER=mnist_190425_150337_hyper\n",
      "env: OUTDIR_HYPER=gs://presentation-38388/mnist_190425_150337_hyper\n",
      "env: DATA=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n",
      "env: TIER=STANDARD_1\n"
     ]
    }
   ],
   "source": [
    "# Set JOBNAME environment variable\n",
    "import datetime\n",
    "JOBNAME_HYPER = \"mnist_{}_hyper\".format(datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\"))\n",
    "%env JOBNAME_HYPER {JOBNAME_HYPER}\n",
    "# Set new OUTPUT and DATA directory in GS\n",
    "OUTDIR_HYPER = '/'.join(['gs:/', BUCKET, JOBNAME_HYPER])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR_HYPER $OUTDIR_HYPER\n",
    "%env DATA $DATA\n",
    "%env TIER STANDARD_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Start Bayesian Hyperparameter Search:\n",
    "\n",
    "- add `config` parameter with `hyperp_config.yaml` as argument:\n",
    "- one can add other parameter to `hyperp_config.yaml`, see [docs on submitting](https://cloud.google.com/ml-engine/docs/tensorflow/training-jobs#formatting_your_configuration_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://presentation-38388/mnist_190425_150337_hyper gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz europe-west1 mnist_190425_150337_hyper\n",
      "jobId: mnist_190425_150337_hyper\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [mnist_190425_150337_hyper] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_190425_150337_hyper\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190425_150337_hyper\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $OUTDIR_HYPER $DATA $REGION $JOBNAME_HYPER\n",
    "gcloud ml-engine jobs submit training $JOBNAME_HYPER \\\n",
    "   --region $REGION \\\n",
    "   --module-name $PKG_NAME.task \\\n",
    "   --package-path ${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket gs://$BUCKET \\\n",
    "   --scale-tier $TIER \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version $TFVERSION \\\n",
    "   --config hyperp_config.yaml \\\n",
    "   -- \\\n",
    "   --data_path $DATA \\\n",
    "   --output_dir $OUTDIR_HYPER \\\n",
    "   --train_steps 5000 \\\n",
    "   --job_dir $OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-04-25T15:03:47Z'\n",
      "etag: 6_cy6g23jgA=\n",
      "jobId: mnist_190425_150337_hyper\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path\n",
      "  - gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n",
      "  - --output_dir\n",
      "  - gs://presentation-38388/mnist_190425_150337_hyper\n",
      "  - --train_steps\n",
      "  - '5000'\n",
      "  - --job_dir\n",
      "  - gs://presentation-38388/pkg_mnist_fnn/trained/jobs\n",
      "  hyperparameters:\n",
      "    goal: MAXIMIZE\n",
      "    hyperparameterMetricTag: accuracy\n",
      "    maxParallelTrials: 2\n",
      "    maxTrials: 30\n",
      "    params:\n",
      "    - maxValue: 512.0\n",
      "      minValue: 64.0\n",
      "      parameterName: train_batch_size\n",
      "      scaleType: UNIT_LINEAR_SCALE\n",
      "      type: INTEGER\n",
      "    - categoricalValues:\n",
      "      - 256 128 64\n",
      "      - 128 64 32\n",
      "      - 512 256 128 64\n",
      "      - 256 128 64 32\n",
      "      parameterName: hidden_units\n",
      "      type: CATEGORICAL\n",
      "    - maxValue: 0.1\n",
      "      minValue: 0.0001\n",
      "      parameterName: learning_rate\n",
      "      scaleType: UNIT_LOG_SCALE\n",
      "      type: DOUBLE\n",
      "  packageUris:\n",
      "  - gs://presentation-38388/mnist_190425_150337_hyper/01276f5b79b62e6e8dc09a4878d3c8518497a2a43fbcf1232015be879a9e61ad/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "  pythonModule: pkg_mnist_fnn.task\n",
      "  pythonVersion: '3.5'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.13'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput:\n",
      "  isHyperparameterTuningJob: true\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/mnist_190425_150337_hyper?project=presentation-38388\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fmnist_190425_150337_hyper&project=presentation-38388\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs describe $JOBNAME_HYPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Get results from job using API\n",
    "\n",
    "See [client documentation on ml-engine](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library#putting_it_all_together) and [` ml.projects().jobs().get()`](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs/get) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using `requests-package` behind a proxy with gcloud SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://ml.googleapis.com/v1/projects/{project}/jobs'.format(project=PROJECT)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace(os.linesep, ''))\n",
    "}\n",
    "json_response = requests.get(url=url, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.c.El32BoeeOKkai2y6zPQ5AmSYJDrdsYDuDa5w80z1aMGO8eQxqCbofJkjpdtOLH4ZuHi5ie4TLr7JeaWe52YAAC2Fo1CrFF3pFmFnDu__5qT-30C43FWw6t0Jyr3Defo'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'createTime': '2019-04-25T15:03:47Z',\n",
       " 'etag': 'mxCpp31s8ks=',\n",
       " 'jobId': 'mnist_190425_150337_hyper',\n",
       " 'startTime': '2019-04-25T15:03:50Z',\n",
       " 'state': 'RUNNING',\n",
       " 'trainingInput': {'args': ['--data_path',\n",
       "   'gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz',\n",
       "   '--output_dir',\n",
       "   'gs://presentation-38388/mnist_190425_150337_hyper',\n",
       "   '--train_steps',\n",
       "   '5000',\n",
       "   '--job_dir',\n",
       "   'gs://presentation-38388/pkg_mnist_fnn/trained/jobs'],\n",
       "  'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "   'hyperparameterMetricTag': 'accuracy',\n",
       "   'maxParallelTrials': 2,\n",
       "   'maxTrials': 30,\n",
       "   'params': [{'maxValue': 512,\n",
       "     'minValue': 64,\n",
       "     'parameterName': 'train_batch_size',\n",
       "     'scaleType': 'UNIT_LINEAR_SCALE',\n",
       "     'type': 'INTEGER'},\n",
       "    {'categoricalValues': ['256 128 64',\n",
       "      '128 64 32',\n",
       "      '512 256 128 64',\n",
       "      '256 128 64 32'],\n",
       "     'parameterName': 'hidden_units',\n",
       "     'type': 'CATEGORICAL'},\n",
       "    {'maxValue': 0.1,\n",
       "     'minValue': 0.0001,\n",
       "     'parameterName': 'learning_rate',\n",
       "     'scaleType': 'UNIT_LOG_SCALE',\n",
       "     'type': 'DOUBLE'}]},\n",
       "  'packageUris': ['gs://presentation-38388/mnist_190425_150337_hyper/01276f5b79b62e6e8dc09a4878d3c8518497a2a43fbcf1232015be879a9e61ad/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
       "  'pythonModule': 'pkg_mnist_fnn.task',\n",
       "  'pythonVersion': '3.5',\n",
       "  'region': 'europe-west1',\n",
       "  'runtimeVersion': '1.13',\n",
       "  'scaleTier': 'STANDARD_1'},\n",
       " 'trainingOutput': {'isHyperparameterTuningJob': True}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobname = os.environ['JOBNAME_HYPER']\n",
    "url = 'https://ml.googleapis.com/v1/projects/{project}/jobs/{jobname}'.format(project=PROJECT, jobname=jobname)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace(os.linesep, ''))\n",
    "}\n",
    "print(headers)\n",
    "json_response = requests.get(url=url, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using `googleapiclient.discorvery`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "ml = discovery.build('ml', 'v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ml.projects().jobs().list(parent='projects/{}'.format(PROJECT)).execute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "jobname = os.environ['JOBNAME'] \n",
    "request = ml.projects().jobs().get(\n",
    "    name='projects/{project}/jobs/{jobname}'.format(\n",
    "        project=PROJECT, jobname=jobname))\n",
    "request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "from pprint import pprint\n",
    "\n",
    "def get_job_results(jobname, project=PROJECT):\n",
    "    \"\"\"\n",
    "    Builds a discovery client with GCMLE endpoint.\n",
    "    \n",
    "    jobname: str\n",
    "        Jobname used to run GCMLE task\n",
    "    project: str\n",
    "        Project-Name\n",
    "    \n",
    "    Return\n",
    "    responste: dict\n",
    "        Dictionary containing information to create job and its results\n",
    "    \"\"\"\n",
    "    ml = discovery.build('ml', 'v1')\n",
    "    endpoint = 'projects/{project}/jobs/{jobname}'.format(project=project, jobname=jobname)\n",
    "    print(\"API endpoint: {}\".format(endpoint))\n",
    "    request = ml.projects().jobs().get(name=endpoint)\n",
    "    # Make the call.\n",
    "    try:\n",
    "        response_dict = request.execute()\n",
    "        pprint(response_dict)\n",
    "    except errors.HttpError as err:\n",
    "        print('There was an error creating the model. Check the details:')\n",
    "        print(err._get_reason())\n",
    "    return response_dict\n",
    "#get_job_results(os.environ['JOBNAME_HYPER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details = get_job_results(jobname=os.environ['JOBNAME_HYPER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['endTime', 'trainingInput', 'startTime', 'etag', 'createTime', 'state', 'jobId', 'trainingOutput'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_details.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Excursus: Check Results in TensorBoard\n",
    "\n",
    "- metrics and variables are inspected from the logs, called checkpoints (`ckpt`)\n",
    "- Dashboard on localhost: `TensorBoard`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Inspect Model trained on your machine by starting a local tensorboard server:\n",
    "- `tensorboard --logdir trained/pkg_mnist_fnn/`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!tensorboard --logdir trained/pkg_mnist_fnn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "tensorboard $PWD/$OUTDIR_LOCAL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!echo \"tensorboard --logdir $PWD/src/$PKG_NAME/trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Or trained on GCP, where results are store in Google Cloud Storage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "#gcloud auth application-default login\n",
    "echo $OUTDIR\n",
    "tensorboard --logdir $OUTDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Screenshot of Tensorboard\n",
    "![screenshot Tensorboard](Images/tensorboard_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Excursus: Load data from the bucket\n",
    "\n",
    "- Binary Object has to be read by `BytesIO` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT) # use current gcloud PROJECT_ID\n",
    "bucket = storage_client.get_bucket(BUCKET)\n",
    "blob = bucket.blob(\"pkg_mnist_fnn/data/mnist.npz\")\n",
    "\n",
    "data = blob.download_as_string()\n",
    "data = BytesIO(data)\n",
    "data = np.load(data)\n",
    "with data as f:\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#ToDo# Does only work under linux-> version?\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "f = BytesIO(file_io.read_file_to_string(\n",
    "    filename=DATA, #'gs://BUCKET/PKG_NAME/data/mnist.npz', \n",
    "    binary_mode=True\n",
    "))\n",
    "data = np.load(f)\n",
    "with data as f:\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deploy model - from any previous step (DSP 2.5)\n",
    "\n",
    "- `tf.estimator.LatestExporter`is used to store a model for deployment in the cloud\n",
    "- See also:  `tf.estimator.export`, `tf.saved_model`\n",
    "\n",
    "[Link to Console](https://console.cloud.google.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Check that a model has been saved on your Bucket:\n",
    "\n",
    "get best model found in from Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#%env JOBNAME_HYPER mnist_190417_132255_hyper  # uncomment and set in case you take an old job\n",
    "job_details = get_job_results(os.environ[\"JOBNAME_HYPER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with best performance on chosen metrics\n",
      "{'finalMetric': {'objectiveValue': 0.9745000004768372, 'trainingStep': '5006'}, 'trialId': '14', 'hyperparameters': {'train_batch_size': '225', 'hidden_units': '512 256 128 64'}}\n"
     ]
    }
   ],
   "source": [
    "best_run = job_details['trainingOutput']['trials'][0]\n",
    "print(\"Run with best performance on chosen metrics:\\n{}\".format(best_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRIAL_ID=14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gs://presentation-38388/mnist_190417_132255_hyper/14/export/exporter/',\n",
       " 'gs://presentation-38388/mnist_190417_132255_hyper/14/export/exporter/1555502257/',\n",
       " 'gs://presentation-38388/mnist_190417_132255_hyper/14/export/exporter/1555502277/',\n",
       " 'gs://presentation-38388/mnist_190417_132255_hyper/14/export/exporter/1555502295/']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env TRIAL_ID {best_run['trialId']}\n",
    "models = !gsutil ls gs://$PROJECT/$JOBNAME_HYPER/$TRIAL_ID/export/exporter/\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use best  model from Hyper-Parameter Tuning Job (Query is shown before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_LOCATION=gs://presentation-38388/mnist_190417_132255_hyper/14/export/exporter/1555502295/\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_LOCATION={models[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Identifier for deployed model:\n",
    "- `MODEL_NAME`\n",
    "- `MODEL_VERSION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=MNIST_MLENGINE\n",
      "env: MODEL_VERSION=v1\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME MNIST_MLENGINE\n",
    "%env MODEL_VERSION v1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine models   create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} \\\n",
    "     --origin ${MODEL_LOCATION} \\\n",
    "     --runtime-version $TFVERSION \\\n",
    "     --python-version 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Create: A model (Dataset) has different versions (Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine versions create --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Using the Model saved by Python Module\n",
    "2. Using Model saved by `ml-engine local`\n",
    "3. Using Model trained online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tools get predictions:\n",
    "- Command Line Interfaces\n",
    "    - `gcloud ml-engine local predict`\n",
    "    - `gcloud ml-engine predict`\n",
    "- Python Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create an test-image in numpy format\n",
    "1. Add filename to config-file\n",
    "2. Create file containing `N` examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TEST_DATA_JSON=data/mnist/json/ml_engine_testdatafile_N4.json\n"
     ]
    }
   ],
   "source": [
    "N=4\n",
    "testdatafile = \"data/mnist/json/ml_engine_testdatafile_N{}.json\".format(N)\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "with open(\"config.yaml\", \"w\", encoding = \"utf8\") as f:\n",
    "    config['testdatafile'] = testdatafile\n",
    "    yaml.dump(config, stream=f,  default_flow_style=False)\n",
    "TEST_DATA_JSON = testdatafile\n",
    "%env TEST_DATA_JSON $testdatafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from data\\mnist\\raw\\mnist.npz\n",
      "Wrote to data/mnist/json/ml_engine_testdatafile_N4.json\n"
     ]
    }
   ],
   "source": [
    "# Create a file with 4 test images\n",
    "import numpy as np\n",
    "import json\n",
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(path='data/mnist/raw/mnist.npz')\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()\n",
    "\n",
    "#eol = os.linesep\n",
    "#print(eol)\n",
    "n_lines = len(y_test)\n",
    "with open(testdatafile, \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        _dict = {\"x\": image} #, \"y\": int(label)}\n",
    "        f.write(json.dumps(_dict)+ \"\\n\")\n",
    "print(\"Wrote to {}\".format(testdatafile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's look at our four examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\t/home/jupyter/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata\n",
    "plot_mnist_testdata(TEST_DATA_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML-Engine: `ml-engine local predict`\n",
    "- Using Model saved\n",
    "  - Python module\n",
    "  - `ml-engine local`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### `ML-Engine local` using Python 3 ...\n",
    "you still have to remove manually some compiled python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uploads.pyc', 'predict_utilities.pyc', '__init__.pyc', 'flags.pyc', 'local_train.pyc', 'jobs_util.pyc', 'local_utils.pyc', 'models_util.pyc', 'local_predict.pyc', 'versions_util.pyc', 'operations_util.pyc', 'log_utils.pyc', 'jobs_prep.pyc']\n"
     ]
    }
   ],
   "source": [
    "#/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/\n",
    "folder = \"C:\\\\eplatform\\\\tools\\\\google-cloud-sdk\\\\lib\\\\googlecloudsdk\\\\command_lib\\\\ml_engine\\\\\"\n",
    "folder = \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/\"\n",
    "files = os.listdir(folder)\n",
    "files = [x for x in files if \".pyc\" in x]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for x in files:\n",
    "    assert \".pyc\" in x\n",
    "    path_ = os.path.join(folder, x)\n",
    "    os.remove(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "folder = \"C:\\\\eplatform\\\\tools\\\\google-cloud-sdk\\\\lib\\\\googlecloudsdk\\\\command_lib\\\\ml_engine\\\\\"\n",
    "files = os.listdir(folder)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to work with `Python 3`, delete the `*.pyc` files, see [post](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)\n",
    "\n",
    "Default Datalab\n",
    "```\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "Default UNIX:\n",
    "```\n",
    "sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "\n",
    "> Process running Datalab or Jupyter Notebook needs admin rights. This is not always given for locally run notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: model_dir=1555329649\n"
     ]
    }
   ],
   "source": [
    "model_dir = os.listdir(\"{}/export/exporter\".format(OUTDIR_local))[-1]\n",
    "%env model_dir=$model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $OUTDIR_LOCAL/export/exporter/ | tail -1)\n",
    "echo \"Selected Model:  $model_dir\" \n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/$OUTDIR_LOCAL/export/exporter/${model_dir} \\\n",
    "    --json-instances=$TEST_DATA_JSON \\\n",
    "    --verbosity debug > data/test_predictions\n",
    "cat data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Prediction - Command Line\n",
    "\n",
    "- same output format as before,  check Console: [link](https://console.cloud.google.com/mlengine/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=$TEST_DATA_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata\n",
    "plot_mnist_testdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Predictions - Batch \n",
    "\n",
    "- cp [example](https://cloud.google.com/ml-engine/docs/tensorflow/batch-predict)\n",
    "- `data_format`= `'text'` for JSON-Format\n",
    "- `output-path`: GS folder where results will be saved \n",
    "- `input-paths`: File-Location (can be folder with several files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gs://ml-productive-pipeline-53122/pkg_mnist_fnn', 'trained')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME_BATCH_PRED=BATCH_190417_142639\n",
      "env: DATA_FORMAT=text\n",
      "env: OUTPUT_PATH=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/\n",
      "env: TEST_DATA_GS=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/ml_engine_testdatafile_N4.json_\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "JOBNAME_BATCH_PRED = 'BATCH_' + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "%env JOBNAME_BATCH_PRED {JOBNAME_BATCH_PRED}\n",
    "%env DATA_FORMAT text\n",
    "%env OUTPUT_PATH {'/'.join([os.path.split(OUTDIR)[0], \"batch_pred/\"])}\n",
    "%env TEST_DATA_GS {'/'.join([os.path.split(DATA)[0], os.path.split(TEST_DATA_JSON)[1]])}_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Copy files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!gsutil cp data/mnist/json/ml_engine_testdatafile_N4.json $TEST_DATA_GS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Submit job using `gcloud` functionality"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!gcloud ml-engine jobs submit prediction $JOBNAME_BATCH_PRED  --model=MNIST_MLENGINE --version=v1 --input-paths=$TEST_DATA_GS --output-path $OUTPUT_PATH  --region $REGION --data-format $DATA_FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Retrieve results from batch and parse them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/prediction.errors_stats-00000-of-00001', 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/prediction.results-00000-of-00001']\n"
     ]
    }
   ],
   "source": [
    "files = !gsutil ls $OUTPUT_PATH\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\google\\auth\\_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get file pkg_mnist_fnn/batch_pred/prediction.results-00000-of-00001\n",
      "{'probabilities': [1.796089488346076e-14, 7.701577192691577e-16, 2.0403012504326135e-13, 1.6514434083610011e-15, 4.721195434598258e-09, 2.0084121388208587e-06, 0.9999979734420776, 7.162657244561357e-16, 5.1056873511003206e-20, 5.9368125811994605e-21], 'class_ids': [6], 'classes': ['6'], 'logits': [14.841353416442871, 11.691999435424805, 17.271425247192383, 12.454808235168457, 27.320730209350586, 33.3737678527832, 46.4919319152832, 11.619453430175781, 2.0705859661102295, -0.08118200302124023]}\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import json\n",
    "mybucket= storage.Client(project=PROJECT).get_bucket('{}'.format(BUCKET))\n",
    "file = files[1].split(\"{}\".format(BUCKET + \"/\"))[1]\n",
    "print(\"Get file {}\".format(file))\n",
    "blob= mybucket.blob(file)\n",
    "result = blob.download_as_string()\n",
    "\n",
    "result = [json.loads(x) for x in (result.decode().split(\"\\n\"))[:-1]]\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get predictions using the [Python-Client-Library, see Tutorial](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library). \n",
    "\n",
    "- [API-Reference](https://cloud.google.com/ml-engine/reference/rest/)\n",
    "\n",
    "-  service account authentification:  [link](https://cloud.google.com/iam/docs/creating-managing-service-accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presentation-38388\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MNIST_MLENGINE' \n",
    "VERSION = 'v1'\n",
    "print(PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Load data** into python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "instances = []\n",
    "with open(TEST_DATA_JSON, \"r\") as f:\n",
    "    data = f.readlines()\n",
    "instances = [json.loads(x) for x in data]   # for discovery-client\n",
    "data = [image['x'] for  image in instances] # for requests-package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Using `requests`-package behind a proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import os\n",
    "from pprint import pprint\n",
    "url = 'https://ml.googleapis.com/v1/projects/{project}/models/{model}/versions/{version}:predict'.format(project=PROJECT,\n",
    "                                                                                                         model=MODEL_NAME,\n",
    "                                                                                                         version=VERSION)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace(os.linesep, ''))\n",
    "}\n",
    "request_data = {\"instances\":\n",
    "    data\n",
    "}\n",
    "print(headers)\n",
    "json_response = requests.post(url=url, data=json.dumps(request_data), headers=headers)\n",
    "pprint(json.loads(json_response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `googleapiclient.discovery` \n",
    "- fails behind proxy due to SSL verification (which could not be deactivated)\n",
    "#### Authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "#import json\n",
    "#import google.auth\n",
    "#cred, project = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "api = discovery.build(serviceName='ml', version='v1',\n",
    "                      #http= httplib2.Http(disable_ssl_certificate_validation=True),\n",
    "                      discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest',\n",
    "                      #credentials=cred,  # SDK credentials\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```cmd\n",
    "UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. **If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error**. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
    "warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Get predictions for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint to use: projects/presentation-38388/models/MNIST_MLENGINE/versions/v1\n",
      "\n",
      "{'predictions': [{'class_ids': [6],\n",
      "                  'classes': ['6'],\n",
      "                  'logits': [32.44482421875,\n",
      "                             7.6028923988342285,\n",
      "                             16.28093719482422,\n",
      "                             -2.589340925216675,\n",
      "                             19.7176513671875,\n",
      "                             33.132835388183594,\n",
      "                             54.8175163269043,\n",
      "                             -16.305957794189453,\n",
      "                             30.172603607177734,\n",
      "                             2.825314998626709],\n",
      "                  'probabilities': [1.9216012114853243e-10,\n",
      "                                    3.1257194429495154e-21,\n",
      "                                    1.835592692285606e-17,\n",
      "                                    1.1708977367129134e-25,\n",
      "                                    5.705875983523024e-16,\n",
      "                                    3.8235142829634583e-10,\n",
      "                                    1.0,\n",
      "                                    1.292610381137368e-31,\n",
      "                                    1.9808446549696157e-11,\n",
      "                                    2.6307116483040313e-23]},\n",
      "                 {'class_ids': [5],\n",
      "                  'classes': ['5'],\n",
      "                  'logits': [14.927939414978027,\n",
      "                             -6.778494834899902,\n",
      "                             4.141507625579834,\n",
      "                             43.068546295166016,\n",
      "                             0.6196087598800659,\n",
      "                             75.10890197753906,\n",
      "                             25.721439361572266,\n",
      "                             8.24479866027832,\n",
      "                             38.82402038574219,\n",
      "                             41.834747314453125],\n",
      "                  'probabilities': [7.307022890579883e-27,\n",
      "                                    2.733726225615854e-36,\n",
      "                                    1.5109610428901798e-31,\n",
      "                                    1.2163269455761454e-14,\n",
      "                                    4.4638523698552944e-33,\n",
      "                                    1.0,\n",
      "                                    3.558750210182355e-22,\n",
      "                                    9.147197500019716e-30,\n",
      "                                    1.7445207355007832e-16,\n",
      "                                    3.5417526489465567e-15]},\n",
      "                 {'class_ids': [4],\n",
      "                  'classes': ['4'],\n",
      "                  'logits': [-0.7249101400375366,\n",
      "                             2.583855390548706,\n",
      "                             4.913121700286865,\n",
      "                             -9.491820335388184,\n",
      "                             25.9003849029541,\n",
      "                             0.00831960141658783,\n",
      "                             3.283358573913574,\n",
      "                             3.945178270339966,\n",
      "                             4.081246376037598,\n",
      "                             12.56712818145752],\n",
      "                  'probabilities': [2.733885383701673e-12,\n",
      "                                    7.477542196543396e-11,\n",
      "                                    7.679746283351108e-10,\n",
      "                                    4.259515874713879e-16,\n",
      "                                    0.9999983310699463,\n",
      "                                    5.691389200201957e-12,\n",
      "                                    1.5050438673114286e-10,\n",
      "                                    2.917255603751556e-10,\n",
      "                                    3.3424754630750897e-10,\n",
      "                                    1.6197182048927061e-06]},\n",
      "                 {'class_ids': [8],\n",
      "                  'classes': ['8'],\n",
      "                  'logits': [3.750030040740967,\n",
      "                             3.5640804767608643,\n",
      "                             4.654750823974609,\n",
      "                             7.09721040725708,\n",
      "                             0.9614541530609131,\n",
      "                             5.461730480194092,\n",
      "                             -2.7106735706329346,\n",
      "                             -0.33642110228538513,\n",
      "                             12.137345314025879,\n",
      "                             4.547438621520996],\n",
      "                  'probabilities': [0.00022565328981727362,\n",
      "                                    0.00018736346100922674,\n",
      "                                    0.0005576441180892289,\n",
      "                                    0.006413628812879324,\n",
      "                                    1.387966131005669e-05,\n",
      "                                    0.0012497523566707969,\n",
      "                                    3.5285319199829246e-07,\n",
      "                                    3.7906943362031598e-06,\n",
      "                                    0.9908470511436462,\n",
      "                                    0.000500901136547327]}]}\n"
     ]
    }
   ],
   "source": [
    "project_id = 'projects/{project}/models/{model}/versions/{version}'.format(project=PROJECT, model=MODEL_NAME, version=VERSION)\n",
    "print(\"Endpoint to use: {}\\n\".format(project_id))\n",
    "request_data = {\"instances\":\n",
    "    instances\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "pprint(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, pred in enumerate(request['predictions']):\n",
    "    print(\"Predicted class: {}, True Class:\\t{}\".format(\n",
    "        pred['classes'][0], \n",
    "        y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pdoc discovery.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```\n",
    "Signature: discovery.build(serviceName, version, http=None, discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', developerKey=None, model=None, requestBuilder=<class 'googleapiclient.http.HttpRequest'>, credentials=None, cache_discovery=True, cache=None)\n",
    "Docstring:\n",
    "Construct a Resource for interacting with an API.\n",
    "\n",
    "Construct a Resource object for interacting with an API. The serviceName and\n",
    "version are the names from the Discovery service.\n",
    "\n",
    "Args:\n",
    "serviceName: string, name of the service.\n",
    "version: string, the version of the service.\n",
    "http: httplib2.Http, An instance of httplib2.Http or something that acts\n",
    "like it that HTTP requests will be made through.\n",
    "discoveryServiceUrl: string, a URI Template that points to the location of\n",
    "the discovery service. It should have two parameters {api} and\n",
    "{apiVersion} that when filled in produce an absolute URI to the discovery\n",
    "document for that service.\n",
    "developerKey: string, key obtained from\n",
    "https://code.google.com/apis/console.\n",
    "model: googleapiclient.Model, converts to and from the wire format.\n",
    "requestBuilder: googleapiclient.http.HttpRequest, encapsulator for an HTTP\n",
    "request.\n",
    "credentials: oauth2client.Credentials or\n",
    "google.auth.credentials.Credentials, credentials to be used for\n",
    "authentication.\n",
    "cache_discovery: Boolean, whether or not to cache the discovery doc.\n",
    "cache: googleapiclient.discovery_cache.base.CacheBase, an optional\n",
    "cache object for the discovery documents.\n",
    "\n",
    "Returns:\n",
    "A Resource object with methods for interacting with the service.\n",
    "File: /usr/local/envs/py3env/lib/python3.5/site-packages/googleapiclient/discovery.py\n",
    "Type: function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gcp_training_options-gcp_services.png](Images/gcp_training_options-gcp_services.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outlook\n",
    "- Add different models types\n",
    "    - different layers of abstraction in tensorflow\n",
    "    - sklearn\n",
    "- Show how to use `ml-engine` in SQL in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notes on **Jupyter Slides**\n",
    "- Activate: View -> Cell Toolbar -> Slideshow\n",
    "- [nbextensions](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html)\n",
    "   - [split cells vertically](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/splitcell/readme.html)\n",
    "   - Code folding\n",
    "   - Table of Contents\n",
    "- [RISE](https://damianavila.github.io/RISE/installation.html) for interactive presentations\n",
    "  - using conda: `conda install -c conda-forge rise`\n",
    "  - activte scrolling in Notebook-Metadata, see [link](https://damianavila.github.io/RISE/customize.html#config-right-scroll) \n",
    "  - adapt width and height of your slides to your machine and needs. [link](https://damianavila.github.io/RISE/customize.html#change-the-width-and-height-of-slides)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "livereveal": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "598.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
